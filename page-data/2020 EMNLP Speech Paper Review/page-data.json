{
    "componentChunkName": "component---src-templates-post-tsx",
    "path": "/2020 EMNLP Speech Paper Review/",
    "result": {"data":{"logo":null,"markdownRemark":{"html":"<h1>EMNLP Paper Review: Speech</h1>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2010.08518\">Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al)</a></li>\n<li><a href=\"https://arxiv.org/abs/1911.02750\">Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework (Mingbo Ma et al)</a></li>\n</ul>\n<h2>Adaptive Feature Selection for End-to-End Speech Translation</h2>\n<ul>\n<li>EMNLP 2020</li>\n<li>Biao Zhang, Ivan Titov, Barry Haddow, Rico Sennrich</li>\n</ul>\n<h3>Summary</h3>\n<ul>\n<li>End-to-End Speech Translation (E2E ST)를 다룬 논문</li>\n<li>Speech Translation\n<ul>\n<li>Cascade: 음성 (source) → 음성인식 모델 → 텍스트 (source) → 번역 모델 → 텍스트 (target)</li>\n<li>E2E: 음성 (source) → 음성번역 모델 → 텍스트 (target)</li>\n</ul>\n</li>\n<li>Cascade 방식은 음성인식에서의 오류가 기계번역으로 전파가 되는 단점이 있음</li>\n<li>E2E 번역이 최근 많이 연구되고 있으나, Cascade 방식의 성능을 따라잡지 못하고 있음</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/42150335/101368190-32294400-38ea-11eb-924b-5b0a2e25d2e6.png\" alt=\"image\"></p>\n<ul>\n<li>E2E ST가 어려운 주된 이유로, 음성마다 단어 발화 길이가 다르며, 노이즈 혹은 중간중간 끊기는 등 일관적이지 않다는 특징 때문이라고 주장</li>\n<li>그래서 인코딩 된 피쳐를 선택적으로 사용해야 된다고 주장 (Adaptive Feature Selection)</li>\n<li>AFS는 인코더 아웃풋에서 필요없는 프레임은 제거하는 역할을 함 (L<sub>0</sub>Drop - Zhang et al., 2020)</li>\n<li>결과적으로 본 논문은 아래와 같은 파이프라인을 제안함</li>\n</ul>\n<img src=\"https://user-images.githubusercontent.com/42150335/101366218-073df080-38e8-11eb-8699-dd6ebc2d70dc.png\" width=\"300\">  \n<ul>\n<li>Training Pipeline\n<ol>\n<li>ASR 모델 학습 (Hybrid Cross Entropy + CTC)</li>\n<li>AFS 모델을 추가해서 ASR 모델 파인튜닝</li>\n<li>ASR &#x26; AFS 모델은 Freeze한 채로 ST Encoder, ST Decoder 학습</li>\n</ol>\n</li>\n<li>Result on MuST-C En-De</li>\n</ul>\n<img src=\"https://user-images.githubusercontent.com/42150335/101370007-4a9a5e00-38ec-11eb-8f41-7f6de1b9d583.png\" width=\"500\">\n<ul>\n<li>AFS는 모델을 더 빠르게 하면서도 성능을 높였음</li>\n<li>성능은 Cascade보다는 살짝 낮음</li>\n</ul>\n<hr>\n<h2>Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework</h2>\n<ul>\n<li>EMNLP 2020</li>\n<li>Mingbo Ma, Baigong Zheng, Kaibo Liu, Renjie Zheng, Hairong Liu, Kainan Peng, Kenneth Church, Liang Huang  (Baidu Research)</li>\n<li><a href=\"https://inctts.github.io/\">Demo Page</a></li>\n</ul>\n<h3>Summary</h3>\n<ul>\n<li>동시번역을 위한 빠른 음성합성 기법 제안</li>\n<li>새로 학습할 필요없이 Inference 단에서 수정하여 사용할 수 있는 파이프라인 제안 (Tacotron2 사용)</li>\n<li>기존 TTS 시스템</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/42150335/101376816-6bff4800-38f4-11eb-9dca-1592c05c6759.png\" alt=\"image\"></p>\n<p>Text2Phoneme → Phoneme2Spectrogram → Spectrogram2Wave 단계를 거침</p>\n<ul>\n<li>위와 같은 Full-sentence TTS는 문장 길이가 길어질수록 latency가 길어지는 고질적인 문제점을 가지고 있음</li>\n<li>이러한 문제점 해결을 위해 아래 파이프라인을 제안</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/42150335/101377884-bf25ca80-38f5-11eb-8098-6f0b206d01f6.png\" alt=\"image\"></p>\n<ul>\n<li>Full-sentence TTS가 아닌, Incremental TTS 방식 제안</li>\n<li>먼저 만들어진 오디오를 재생하는 동안 뒷단의 오디오를 만들어나가는 방식</li>\n<li>이와 같은 파이프라인이 가능하려면 특정 단위로 쪼개야함 (E.g. Word)</li>\n<li>하지만 Word 단위로 TTS를 진행한 후, 오디오를 이어붙이게 되면 굉장히 부자연스러운 음성이 합성됨</li>\n<li>이를 극복하기 위해 lookahead-k Policy 제안\n<ul>\n<li>t번째 target을 만들때 t+k개의 입력 소스를 통해 생성 (첫 k+1 스텝까지는 wait)</li>\n</ul>\n</li>\n<li>결과적으로 음질이 크게 떨어지지 않으면서도 latency를 줄임 (문장이 길수록 효과가 큼)</li>\n</ul>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"EMNLP Paper Review: Speech"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/2010.08518"},"children":[{"type":"text","value":"Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al)"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/1911.02750"},"children":[{"type":"text","value":"Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework (Mingbo Ma et al)"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Adaptive Feature Selection for End-to-End Speech Translation"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"EMNLP 2020"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Biao Zhang, Ivan Titov, Barry Haddow, Rico Sennrich"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Summary"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"End-to-End Speech Translation (E2E ST)를 다룬 논문"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Speech Translation\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Cascade: 음성 (source) → 음성인식 모델 → 텍스트 (source) → 번역 모델 → 텍스트 (target)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"E2E: 음성 (source) → 음성번역 모델 → 텍스트 (target)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Cascade 방식은 음성인식에서의 오류가 기계번역으로 전파가 되는 단점이 있음"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"E2E 번역이 최근 많이 연구되고 있으나, Cascade 방식의 성능을 따라잡지 못하고 있음"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101368190-32294400-38ea-11eb-924b-5b0a2e25d2e6.png","alt":"image"},"children":[]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"E2E ST가 어려운 주된 이유로, 음성마다 단어 발화 길이가 다르며, 노이즈 혹은 중간중간 끊기는 등 일관적이지 않다는 특징 때문이라고 주장"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"그래서 인코딩 된 피쳐를 선택적으로 사용해야 된다고 주장 (Adaptive Feature Selection)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"AFS는 인코더 아웃풋에서 필요없는 프레임은 제거하는 역할을 함 (L"},{"type":"element","tagName":"sub","properties":{},"children":[{"type":"text","value":"0"}]},{"type":"text","value":"Drop - Zhang et al., 2020)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"결과적으로 본 논문은 아래와 같은 파이프라인을 제안함"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101366218-073df080-38e8-11eb-8699-dd6ebc2d70dc.png","width":300},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Training Pipeline\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ASR 모델 학습 (Hybrid Cross Entropy + CTC)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"AFS 모델을 추가해서 ASR 모델 파인튜닝"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ASR & AFS 모델은 Freeze한 채로 ST Encoder, ST Decoder 학습"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Result on MuST-C En-De"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101370007-4a9a5e00-38ec-11eb-8f41-7f6de1b9d583.png","width":500},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"AFS는 모델을 더 빠르게 하면서도 성능을 높였음"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"성능은 Cascade보다는 살짝 낮음"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"hr","properties":{},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"EMNLP 2020"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Mingbo Ma, Baigong Zheng, Kaibo Liu, Renjie Zheng, Hairong Liu, Kainan Peng, Kenneth Church, Liang Huang  (Baidu Research)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://inctts.github.io/"},"children":[{"type":"text","value":"Demo Page"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Summary"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"동시번역을 위한 빠른 음성합성 기법 제안"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"새로 학습할 필요없이 Inference 단에서 수정하여 사용할 수 있는 파이프라인 제안 (Tacotron2 사용)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"기존 TTS 시스템"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101376816-6bff4800-38f4-11eb-9dca-1592c05c6759.png","alt":"image"},"children":[]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Text2Phoneme → Phoneme2Spectrogram → Spectrogram2Wave 단계를 거침"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"위와 같은 Full-sentence TTS는 문장 길이가 길어질수록 latency가 길어지는 고질적인 문제점을 가지고 있음"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"이러한 문제점 해결을 위해 아래 파이프라인을 제안"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101377884-bf25ca80-38f5-11eb-8098-6f0b206d01f6.png","alt":"image"},"children":[]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Full-sentence TTS가 아닌, Incremental TTS 방식 제안"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"먼저 만들어진 오디오를 재생하는 동안 뒷단의 오디오를 만들어나가는 방식"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"이와 같은 파이프라인이 가능하려면 특정 단위로 쪼개야함 (E.g. Word)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"하지만 Word 단위로 TTS를 진행한 후, 오디오를 이어붙이게 되면 굉장히 부자연스러운 음성이 합성됨"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"이를 극복하기 위해 lookahead-k Policy 제안\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"t번째 target을 만들때 t+k개의 입력 소스를 통해 생성 (첫 k+1 스텝까지는 wait)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"결과적으로 음질이 크게 떨어지지 않으면서도 latency를 줄임 (문장이 길수록 효과가 큼)"}]},{"type":"text","value":"\n"}]}],"data":{"quirksMode":false}},"excerpt":"EMNLP Paper Review: Speech Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al) Incremental Text-to-Speech…","fields":{"readingTime":{"text":"4 min read"}},"frontmatter":{"title":"EMNLP Paper Review: Speech","userDate":"8 December 2020","date":"2020-12-08T10:00:00.000Z","tags":["speech","paper"],"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/3020a90c23b0e5a906d9e9d75523071a/5a68f/2020-emnlp.png","srcSet":"/static/3020a90c23b0e5a906d9e9d75523071a/1206c/2020-emnlp.png 750w,\n/static/3020a90c23b0e5a906d9e9d75523071a/c1998/2020-emnlp.png 1080w,\n/static/3020a90c23b0e5a906d9e9d75523071a/c6087/2020-emnlp.png 1366w,\n/static/3020a90c23b0e5a906d9e9d75523071a/5a68f/2020-emnlp.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/3020a90c23b0e5a906d9e9d75523071a/3e1c3/2020-emnlp.webp 750w,\n/static/3020a90c23b0e5a906d9e9d75523071a/bbc54/2020-emnlp.webp 1080w,\n/static/3020a90c23b0e5a906d9e9d75523071a/72682/2020-emnlp.webp 1366w,\n/static/3020a90c23b0e5a906d9e9d75523071a/97f4c/2020-emnlp.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.41875}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"children":[{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#181818","images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/2584f/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/2456b/soohwan.png 40w,\n/static/a2699b4a2f164aa71106535e018ceafc/ab12d/soohwan.png 80w,\n/static/a2699b4a2f164aa71106535e018ceafc/2584f/soohwan.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65256/soohwan.webp 40w,\n/static/a2699b4a2f164aa71106535e018ceafc/c6b8d/soohwan.webp 80w,\n/static/a2699b4a2f164aa71106535e018ceafc/03d15/soohwan.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.25}}]}}]}},"relatedPosts":{"totalCount":20,"edges":[{"node":{"id":"64e39e81-9c08-53ad-967e-f53e0ffd1d51","excerpt":"한국어 Tacotron2 이번 포스팅에서는 Tacotron2 아키텍처로 한국어 TTS 시스템을 만드는 방법에 대해 다루겠습니다. Tacotron2 Tacotron2는 17년 12월 구글이 NATURAL TTS SYNTHESIS BY…","frontmatter":{"title":"한국어 Tacotron2","date":"2021-10-10T10:00:00.000Z"},"fields":{"readingTime":{"text":"11 min read"},"slug":"/korean_tacotron2/"}}},{"node":{"id":"8609f7b7-4942-59fe-bfaa-5f82c648649e","excerpt":"Textless NLP: Generating expressive speech from raw audio paper / code / pre-train model / blog Name: Generative Spoken Language Model (GSLM…","frontmatter":{"title":"Textless NLP","date":"2021-09-19T10:00:00.000Z"},"fields":{"readingTime":{"text":"4 min read"},"slug":"/Textledd NLP_ Generating expressive speech from raw audio/"}}},{"node":{"id":"75998e15-7d74-5d05-af5b-1112437e067d","excerpt":"Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition Yu Zhang et al., 2020 Google Research, Brain Team Reference…","frontmatter":{"title":"Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition Paper Review","date":"2021-03-17T10:00:00.000Z"},"fields":{"readingTime":{"text":"3 min read"},"slug":"/Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition/"}}},{"node":{"id":"feb53e83-51f2-5350-ae0e-58157d8dfd22","excerpt":"PORORO Text-To-Speech (TTS) 얼마전에 저희 팀에서 공개한 PORORO: Platform Of neuRal mOdels for natuRal language prOcessing 라이브러리에 제가 공들여만든 TTS…","frontmatter":{"title":"PORORO Text-To-Speech (TTS)","date":"2021-02-16T10:00:00.000Z"},"fields":{"readingTime":{"text":"1 min read"},"slug":"/pororo-tts/"}}},{"node":{"id":"77bed2d4-fc96-5bff-9808-9b9cb45369f3","excerpt":"EMNLP Paper Review: Speech Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al) Incremental Text-to-Speech…","frontmatter":{"title":"EMNLP Paper Review: Speech","date":"2020-12-08T10:00:00.000Z"},"fields":{"readingTime":{"text":"4 min read"},"slug":"/2020 EMNLP Speech Paper Review/"}}}]}},"pageContext":{"slug":"/2020 EMNLP Speech Paper Review/","prev":{"excerpt":"Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism ​ Mohammad Shoeybi et al. 2019. NVIDIA Corp. ​ Summary…","frontmatter":{"title":"Megatron LM Paper Review","tags":["nlp","parallelism","paper"],"date":"2020-12-03T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAACb0lEQVQoz33KTY/UZADA8foVvPMN/AomkshVDnoyvAVComcOGkkMRMMBEsOREA5AFgNhA+rqwoXNvjAz7fN0+vTl6fRl2k47y+x2us3uOpOgGyf796QHDvyO//yNw8MDpBRod4DnBpiWjTRNzE6HvnIQUtI2LfPZDCUllmkihUSYEtf2Wd/apNvrEYQBi8UCw/N8LEuyaj8lSvsUsSDMC1SaECsX0evQkV1cz2PNsnAHIXGWYOseq3KZxPEIHId+x6HerTFC7ZBozZVXp+n6P3PoLfHRXsuHzQT1R4efNq5ycXCe38UQo57w2cjl8vgsv4VL/NC9wCKsGLmKh9Ejqp0So9S/kLsv+e7Vebz8JfNik9uzOdcOWnIZsNp/wr3oLpbO+Gqyzb2dgl8PnrGRr3Cz9zWNGKCFycnqU+JpjFHp5xTeC66uXSB+s8lRG9H8s2D811umWUEy8LDjPnE6RJQl5f4ebxd/4+5u8OP6ZbY7Lm73NR+XnxA3MUYSe5Rpyjfrn2Pqx8z8JU40e3ywW+G96HFr61vOJV+y6pQY0x1OlYoz4y9YiR5xQ1xiEY6pAo/vq+uM6gIjimOSaMgDeYtsbDHftlj+c8b9/ZaiH7Bmr/AkeIwMEm4UOc+3c9bbNfw3FsvBHWbDMVUckQYZ9c4uhlIKISxGWUWaDkmGOftVxSSKyfKMQAWonkI5fVIhqUcl9aimHFW4fQ9HKdLhkK3Xm0wmE4ymabBtm0AHaK0JQ42vNbZShGGIoxyme1Pm8znCcQjCkDAKieKIbq+LEALf9/F8j6OjIwze4/j4mLquybIM13Vp2/b//u73n38B2UarJP6IeMkAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/a4dec0b9c36035e9191658ce9647ae73/a70e6/megatron.png","srcSet":"/static/a4dec0b9c36035e9191658ce9647ae73/37b55/megatron.png 750w,\n/static/a4dec0b9c36035e9191658ce9647ae73/a70e6/megatron.png 791w","sizes":"100vw"},"sources":[{"srcSet":"/static/a4dec0b9c36035e9191658ce9647ae73/0b2ce/megatron.webp 750w,\n/static/a4dec0b9c36035e9191658ce9647ae73/c471e/megatron.webp 791w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5170670037926676}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,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"},"images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.2462962962962962}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"","slug":"/Megatron-lm/"}},"next":{"excerpt":"Hydra: framework for elegantly configuring complex applications Facebook Research에서 공개한 오픈소스. 복잡한 Configuration…","frontmatter":{"title":"Hydra","tags":["toolkit"],"date":"2020-12-28T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAADHElEQVQoz22SW0ySAQCFD8zWS625UstykbkQx4+JGoG1HlzL2rSbNcUKaxYaZgoZKD+KoliWW7VVW4sy5SfT1DC8IXgpLXGl4TXgT1KT1eylHmuLZq23znZezsP3cM4B/qf8cuy924Klb36Yx7/gktmBh8OfcbG1NzbFQK08ZOjHheYXyG99AWnjAFYrr/3xH82X78C4YguT1vACHLJgxowqkukmeQEjGUDW08GAkk4Hcpr6MgrbhrQ5Tf0TEspWkdcyQInru2LT6sw4YbQyzz4ZgLjO+hc4VxbHcMpZoDU8OM4HY1rJhpsk8OEwkPSoHwXNgzhtstefMvaMimstramGNomE6plNMVgEmaZeSCg7zpj6kP4POF8eD6ecJfKQhGpEFsKdVrIPuNREwYQY6w5Sg6JD95/vy22wJmWbuvokRmuNqtneLmuwtqXX27IklP3KYYMlPLW2C0cedjA60wHMlsZgsjBi50KF4PtRYIVXy5fN6wRjfr8fJ409VVmPeydO1nV3V1sGvLrnQ19rOgb9iib7M4nRVp9p6qXED9o4ROMcdlFjDJ8+AfiojYVHzd3k0ydMLugEgYt6UbavKqFx6VYyrt3Swb8dwP6yTUfqbDZ9x6vvSvNrF2q/hN54cBe55jEYblzCLzIUP8kwxkKFAPBq+ZhRRW726UWfJwsjqrylMT2LlcIWpyJc6tLERLzOWZdI54dIayqlj6tVyeTVarnCUppU41VuPe5PBSZUUYIZJTvOVcSBqziKsTwKaE102GKlyPnj3jHMlccf9elFte+LOCluNbf75blAIV0S0+DPRPCSlnvzk4pVNKuO6pxWcapoksC4Ivw2rYluniuLx9friUzMlmxfDhOWO2xPQ6BXy1fM63aM3BFhlYck2ofPB63xkMSjN4WRwulibtlUMTfPTRL9tIZ3dTgniO+QhZTQJM/6vogj9JbygQWdYPmHcW41V/bmwgb21OVtiW41N/NV9lq2U85Kfnl2TZBTzjowmh+WNiQNDHqbtzF69GLYnqnL23aP5K4/2J3BDB1XhAvfFWwWekgCvwHt5mOn1d6UmwAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/affc3911a89df5f958060a468d9d5635/4f407/hydra.png","srcSet":"/static/affc3911a89df5f958060a468d9d5635/e7dcc/hydra.png 750w,\n/static/affc3911a89df5f958060a468d9d5635/50eb2/hydra.png 1080w,\n/static/affc3911a89df5f958060a468d9d5635/4f407/hydra.png 1280w","sizes":"100vw"},"sources":[{"srcSet":"/static/affc3911a89df5f958060a468d9d5635/ee7ce/hydra.webp 750w,\n/static/affc3911a89df5f958060a468d9d5635/819dc/hydra.webp 1080w,\n/static/affc3911a89df5f958060a468d9d5635/b584c/hydra.webp 1280w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,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"},"images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.2462962962962962}}}}]},"fields":{"readingTime":{"text":"6 min read"},"layout":"","slug":"/hydra/"}},"primaryTag":"speech"}},
    "staticQueryHashes": ["3170763342","3229353822"]}