<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 3.13.0"/><link rel="sitemap" type="application/xml" href="/sitemap/sitemap-index.xml"/><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){if(void 0===e.target.dataset.mainImage)return;if(void 0===e.target.dataset.gatsbyImageSsr)return;const t=e.target;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><link rel="canonical" href="https://gatsby-casper.netlify.com/big-model2/" data-baseprotocol="https:" data-basehost="gatsby-casper.netlify.com"/><title data-react-helmet="true">Large Scale LM (2) Distributed Programming</title><link data-react-helmet="true" rel="icon" href="/static/favicon-c81009f10a8374e8d55e679e21663112.ico" type="image/x-icon"/><meta data-react-helmet="true" name="description" content="Large Scale LM (2) Distributed Programming (작성중) 이 자료는 [해당 link…"/><meta data-react-helmet="true" property="og:site_name" content="BEKSI"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:title" content="Large Scale LM (2) Distributed Programming"/><meta data-react-helmet="true" property="og:description" content="Large Scale LM (2) Distributed Programming (작성중) 이 자료는 [해당 link…"/><meta data-react-helmet="true" property="og:url" content="https://bosoek.github.io/big-model2/"/><meta data-react-helmet="true" property="og:image" content="https://bosoek.github.io/static/346eaa433ec4cadd1f537f0536913cd3/ca97d/big-model2.png"/><meta data-react-helmet="true" property="article:published_time" content="2021-11-22T11:00:00.000Z"/><meta data-react-helmet="true" property="article:tag" content="nlp"/><meta data-react-helmet="true" property="article:publisher" content="https://www.facebook.com/profile.php?id=100011713266028"/><meta data-react-helmet="true" property="article:author" content="https://www.facebook.com/profile.php?id=100011713266028"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:title" content="Large Scale LM (2) Distributed Programming"/><meta data-react-helmet="true" name="twitter:description" content="Large Scale LM (2) Distributed Programming (작성중) 이 자료는 [해당 link…"/><meta data-react-helmet="true" name="twitter:url" content="https://bosoek.github.io/big-model2/"/><meta data-react-helmet="true" name="twitter:image" content="https://bosoek.github.io/static/346eaa433ec4cadd1f537f0536913cd3/ca97d/big-model2.png"/><meta data-react-helmet="true" name="twitter:label1" content="Written by"/><meta data-react-helmet="true" name="twitter:data1" content="Soohwan Kim"/><meta data-react-helmet="true" name="twitter:label2" content="Filed under"/><meta data-react-helmet="true" name="twitter:data2" content="nlp"/><meta data-react-helmet="true" property="og:image:width" content="1"/><meta data-react-helmet="true" property="og:image:height" content="0.30885416666666665"/><link rel="preconnect" href="https://www.google-analytics.com"/><link rel="dns-prefetch" href="https://www.google-analytics.com"/><script>
  window.excludeGAPaths=[/^(?:\/preview\/(?:(?!(?:\/|^)\.).)*?)$/];
  function gaOptout(){document.cookie=disableStr+'=true; expires=Thu, 31 Dec 2099 23:59:59 UTC;path=/',window[disableStr]=!0}var gaProperty='UA-XXXX-Y',disableStr='ga-disable-'+gaProperty;document.cookie.indexOf(disableStr+'=true')>-1&&(window[disableStr]=!0);
  if(!(parseInt(navigator.doNotTrack) === 1 || parseInt(window.doNotTrack) === 1 || parseInt(navigator.msDoNotTrack) === 1 || navigator.doNotTrack === "yes")) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-XXXX-Y', 'auto', {"sampleRate":100,"siteSpeedSampleRate":10});
      ga('set', 'anonymizeIp', true);
      
      
      
      
      }</script><link as="script" rel="preload" href="/webpack-runtime-07bd89c0ba3cb6c86c0d.js"/><link as="script" rel="preload" href="/framework-1f167e8ec29420fffee7.js"/><link as="script" rel="preload" href="/app-11465088a5c62aa885e9.js"/><link as="script" rel="preload" href="/1bfc9850-94b89069287213aa7853.js"/><link as="script" rel="preload" href="/b4ffff85-a5d2f6aa896357cc601d.js"/><link as="script" rel="preload" href="/af52a822-c9eb064eb5bad8d65c4a.js"/><link as="script" rel="preload" href="/14cad5d5-8e47c7dcb9a81a3081dc.js"/><link as="script" rel="preload" href="/e0525e89-7522dd770bcde8196745.js"/><link as="script" rel="preload" href="/commons-09b2e09f1f69c33f4392.js"/><link as="script" rel="preload" href="/f43d3337dda7771446a8a3723748296d1554be0e-d425ad4bddf703137135.js"/><link as="script" rel="preload" href="/f913106a4e51e31b31a0ff1c72479e8b5d907cbd-2ca2bb564352d8340d3c.js"/><link as="fetch" rel="preload" href="/page-data/big-model2/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3170763342.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3229353822.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="post-template"><style data-emotion="css-global wbphhm">html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td,article,aside,canvas,details,embed,figure,figcaption,footer,header,hgroup,menu,nav,output,ruby,section,summary,time,mark,audio,video{margin:0;padding:0;border:0;font:inherit;font-size:100%;vertical-align:baseline;}body{line-height:1;}ol,ul{list-style:none;}blockquote,q{quotes:none;}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none;}table{border-spacing:0;border-collapse:collapse;}img{max-width:100%;}html{box-sizing:border-box;font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;}*,*:before,*:after{box-sizing:inherit;}a{background-color:transparent;}a:active,a:hover{outline:0;}b,strong{font-weight:bold;}i,em,dfn{font-style:italic;}h1{margin:0.67em 0;font-size:2em;}small{font-size:80%;}sub,sup{position:relative;font-size:75%;line-height:0;vertical-align:baseline;}sup{top:-0.5em;}sub{bottom:-0.25em;}img{border:0;}svg:not(:root){overflow:hidden;}mark{background-color:#fdffb6;}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em;}button,input,optgroup,select,textarea{margin:0;color:inherit;font:inherit;}button{overflow:visible;border:none;}button,select{text-transform:none;}button,html input[type='button'],input[type='reset'],input[type='submit']{cursor:pointer;-webkit-appearance:button;}button[disabled],html input[disabled]{cursor:default;}button::-moz-focus-inner,input::-moz-focus-inner{padding:0;border:0;}input{line-height:normal;}input:focus{outline:none;}input[type='checkbox'],input[type='radio']{box-sizing:border-box;padding:0;}input[type='number']::-webkit-inner-spin-button,input[type='number']::-webkit-outer-spin-button{height:auto;}input[type='search']{box-sizing:content-box;-webkit-appearance:textfield;}input[type='search']::-webkit-search-cancel-button,input[type='search']::-webkit-search-decoration{-webkit-appearance:none;}legend{padding:0;border:0;}textarea{overflow:auto;}table{border-spacing:0;border-collapse:collapse;}td,th{padding:0;}html{overflow-x:hidden;overflow-y:scroll;font-size:62.5%;-webkit-tap-highlight-color:rgba(0, 0, 0, 0);}body{overflow-x:hidden;color:#303a3e;font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Oxygen,Ubuntu,Cantarell,'Open Sans','Helvetica Neue',sans-serif;font-size:1.6rem;line-height:1.6em;font-weight:400;font-style:normal;letter-spacing:0;text-rendering:optimizeLegibility;background:#fff;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;-moz-font-feature-settings:'liga' on;}::selection{text-shadow:none;background:#cbeafb;}hr{position:relative;display:block;width:100%;margin:2.5em 0 3.5em;padding:0;height:1px;border:0;border-top:1px solid #e4eaed;}audio,canvas,iframe,img,svg,video{vertical-align:middle;}fieldset{margin:0;padding:0;border:0;}textarea{resize:vertical;}p,ul,ol,dl,blockquote{margin:0 0 1.5em 0;}ol,ul{padding-left:1.3em;padding-right:1.5em;}ol ol,ul ul,ul ol,ol ul{margin:0.5em 0 1em;}ul{list-style:disc;}ol{list-style:decimal;}ul,ol{max-width:100%;}li{margin:0.5em 0;padding-left:0.3em;line-height:1.6em;}dt{float:left;margin:0 20px 0 0;width:120px;color:#15171A;font-weight:500;text-align:right;}dd{margin:0 0 5px 0;text-align:left;}blockquote{margin:1.5em 0;padding:0 1.6em 0 1.6em;border-left:#e5eff5 0.5em solid;}blockquote p{margin:0.8em 0;font-size:1.2em;font-weight:300;}blockquote small{display:inline-block;margin:0.8em 0 0.8em 1.5em;font-size:0.9em;opacity:0.8;}blockquote cite{font-weight:bold;}blockquote cite a{font-weight:normal;}a{color:#26a6ed;-webkit-text-decoration:none;text-decoration:none;}a:hover{-webkit-text-decoration:underline;text-decoration:underline;}h1,h2,h3,h4,h5,h6{margin-top:0;line-height:1.15;font-weight:600;text-rendering:optimizeLegibility;}h1{margin:0 0 0.5em 0;font-size:5.5rem;font-weight:600;}@media (max-width: 500px){h1{font-size:2.2rem;}}h2{margin:1.5em 0 0.5em 0;font-size:2.2rem;}@media (max-width: 500px){h2{font-size:1.8rem;}}h3{margin:1.5em 0 0.5em 0;font-size:1.8rem;font-weight:500;}@media (max-width: 500px){h3{font-size:1.7rem;}}h4{margin:1.5em 0 0.5em 0;font-size:1.6rem;font-weight:500;}h5{margin:1.5em 0 0.5em 0;font-size:1.4rem;font-weight:500;}h6{margin:1.5em 0 0.5em 0;font-size:1.4rem;font-weight:500;}body{background:#fff;}@media (prefers-color-scheme: dark){body{color:rgba(255, 255, 255, 0.75);background:#191b1f;}img{opacity:0.9;}}</style><style data-emotion="css wv5on3">.css-wv5on3 .site-main{margin-top:64px;background:#fff;padding-bottom:4vw;}@media (prefers-color-scheme: dark){.css-wv5on3 .site-main{background:#191b1f;}}</style><style data-emotion="css 1qvd43r">.css-1qvd43r{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;min-height:100vh;}.css-1qvd43r .site-main{margin-top:64px;background:#fff;padding-bottom:4vw;}@media (prefers-color-scheme: dark){.css-1qvd43r .site-main{background:#191b1f;}}</style><div class="css-1qvd43r erltajb0"><header class="site-header"><style data-emotion="css 1qxgdzi">.css-1qxgdzi{position:relative;padding:0 5vw;position:fixed;top:0;right:0;left:0;z-index:1000;background:#0a0b0c;}@media (max-width: 700px){.css-1qxgdzi{padding-right:0;padding-left:0;}}</style><div class="css-1qxgdzi"><style data-emotion="css y521qa">.css-y521qa{margin:0 auto;max-width:1040px;width:100%;}</style><div class="css-y521qa"><style data-emotion="css 1yrzsqm">.css-1yrzsqm{position:fixed;top:0;right:0;bottom:0;left:0;z-index:2000;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background:rgba(9, 10, 11, 0.97);opacity:0;-webkit-transition:opacity 0.2s ease-in;transition:opacity 0.2s ease-in;pointer-events:none;}.css-1yrzsqm button{display:inline-block;margin:0 0 0 15px;padding:0 25px;height:52px;outline:none;color:#fff;font-size:1.7rem;line-height:38px;font-weight:400;text-align:center;background:linear-gradient(#4fb7f0, #29a0e0 60%, #29a0e0 90%, #36a6e2);border-radius:8px;-webkit-font-smoothing:subpixel-antialiased;}.css-1yrzsqm form{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0 auto;max-width:540px;}.css-1yrzsqm .form-group{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}.css-1yrzsqm .subscribe-email{display:block;padding:14px 20px;width:100%;border:none;color:#738a94;font-size:2rem;line-height:1em;font-weight:normal;letter-spacing:0.5px;-webkit-user-select:text;-moz-user-select:text;-ms-user-select:text;user-select:text;border-radius:8px;-webkit-transition:border-color 0.15s linear;transition:border-color 0.15s linear;-webkit-appearance:none;}@media (max-width: 500px){.css-1yrzsqm button{margin:12px 0 0;}}@media (prefers-color-scheme: dark){.css-1yrzsqm p{color:rgba(255, 255, 255, 0.7);}}</style><div class="css-1yrzsqm eap1tgp4"><style data-emotion="css 1ry46wd">.css-1ry46wd{position:absolute;top:16px;right:20px;z-index:2000;display:block;width:40px;height:40px;}.css-1ry46wd:before{content:'';position:absolute;top:20px;right:4px;display:block;width:32px;height:1px;background:#fff;opacity:0.8;-webkit-transform:rotate(45deg);-moz-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);}.css-1ry46wd:after{content:'';position:absolute;top:20px;right:4px;display:block;width:32px;height:1px;background:#fff;opacity:0.8;-webkit-transform:rotate(-45deg);-moz-transform:rotate(-45deg);-ms-transform:rotate(-45deg);transform:rotate(-45deg);}.css-1ry46wd:hover{cursor:default;}</style><a class="css-1ry46wd eap1tgp3"></a><style data-emotion="css 1kxdpsw">.css-1kxdpsw{position:relative;margin:0 0 5vw 0;padding:4vw;color:#fff;text-align:center;}</style><div class="css-1kxdpsw eap1tgp2"><style data-emotion="css 19s13e1">.css-19s13e1{display:inline-block;margin:0 0 10px 0;font-size:5.2rem;line-height:1.15em;}</style><h1 class="css-19s13e1 eap1tgp1">Subscribe to <!-- -->BEKSI</h1><style data-emotion="css ahazuo">.css-ahazuo{margin:0 auto 50px;max-width:650px;color:#fff;font-family:Georgia,serif;font-size:2.4rem;line-height:1.3em;font-weight:300;opacity:0.8;}</style><p class="css-ahazuo eap1tgp0">Stay up to date! Get all the latest &amp; greatest posts delivered straight to your inbox</p><style data-emotion="css inpvxq">.css-inpvxq{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0 auto;max-width:460px;}@media (max-width: 500px){.css-inpvxq{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-inpvxq .form-group{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;}}</style><form novalidate="" action="https://twitter.us19.list-manage.com/subscribe/post?u=a89b6987ac248c81b0b7f3a0f&amp;amp;id=7d777b7d75" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="subscribe-form css-inpvxq" target="_blank"><style data-emotion="css 19m0ntg">@media (max-width: 500px){.css-19m0ntg{width:100%;}}</style><div class="form-group css-19m0ntg e1a7m3l0"><style data-emotion="css 1ea5r2o">.css-1ea5r2o{display:block;padding:10px;width:100%;border:#dbe3e7 1px solid;color:#738a94;font-size:1.8rem;line-height:1em;font-weight:normal;-webkit-user-select:text;-moz-user-select:text;-ms-user-select:text;user-select:text;border-radius:5px;-webkit-transition:border-color 0.15s linear;transition:border-color 0.15s linear;-webkit-appearance:none;}.css-1ea5r2o:focus{outline:0;border-color:#bfcdd5;}@media (prefers-color-scheme: dark){.css-1ea5r2o{border-color:#272a30;color:rgba(255, 255, 255, 0.9);background:#202227;}.css-1ea5r2o:focus{border-color:#525866;}}</style><input type="email" class="subscribe-email css-1ea5r2o e1a7m3l2" name="MERGE0" id="MERGE0" placeholder="youremail@example.com"/></div><div style="position:absolute;left:-5000px" aria-hidden="true"><input type="text" name="b_a89b6987ac248c81b0b7f3a0f_7d777b7d75" tabindex="-1"/></div><style data-emotion="css glujqe">.css-glujqe{position:relative;display:inline-block;margin:0 0 0 10px;padding:0 20px;height:43px;outline:none;color:#fff;font-size:1.5rem;line-height:39px;font-weight:400;text-align:center;background:linear-gradient(#4fb7f0, #29a0e0 60%, #29a0e0 90%, #36a6e2);border-radius:5px;-webkit-font-smoothing:subpixel-antialiased;}.css-glujqe:active,.css-glujqe:focus{background:#219bde;}@media (max-width: 500px){.css-glujqe{margin:10px 0 0 0;width:100%;}}@media (prefers-color-scheme: dark){.css-glujqe{opacity:0.9;}}</style><button type="submit" class="css-glujqe e1a7m3l1"><span>Subscribe</span></button></form></div></div><style data-emotion="css lcmrfl">.css-lcmrfl{position:relative;z-index:100;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;overflow-y:hidden;height:64px;font-size:1.3rem;}</style><nav class="css-lcmrfl"><style data-emotion="css crtwut">.css-crtwut{-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;overflow-x:auto;overflow-y:hidden;-webkit-overflow-scrolling:touch;margin-right:10px;padding:10px 0 80px;font-weight:500;letter-spacing:0.2px;text-transform:uppercase;white-space:nowrap;-ms-overflow-scrolling:touch;}@media (max-width: 700px){.css-crtwut{margin-right:0;padding-left:5vw;}}</style><div class="site-nav-left css-crtwut ez7fnwk5"><style data-emotion="css 3oagtl">.css-3oagtl{position:relative;z-index:100;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;display:inline-block;margin-right:32px;padding:12px 0;color:#fff;font-size:1.7rem;line-height:1.8rem;font-weight:bold;letter-spacing:-0.5px;text-transform:none;}.css-3oagtl:hover{-webkit-text-decoration:none;text-decoration:none;}.css-3oagtl img{display:block;width:auto;height:21px;}</style><a class="site-nav-logo css-3oagtl" href="/">BEKSI</a><style data-emotion="css 1xdepn">.css-1xdepn{position:relative;-webkit-align-self:flex-start;-ms-flex-item-align:flex-start;align-self:flex-start;}</style><div class="css-1xdepn ez7fnwk4"><style data-emotion="css d1pqrt">.css-d1pqrt{position:absolute;z-index:1000;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:0 0 0 -12px;padding:0;list-style:none;-webkit-transition:all 1s cubic-bezier(0.19, 1, 0.22, 1);transition:all 1s cubic-bezier(0.19, 1, 0.22, 1);}.css-d1pqrt li{display:block;margin:0;padding:0;}.css-d1pqrt li a{position:relative;display:block;padding:12px 12px;color:#fff;opacity:0.8;-webkit-transition:opacity 0.35s ease-in-out;transition:opacity 0.35s ease-in-out;}.css-d1pqrt li a:hover{-webkit-text-decoration:none;text-decoration:none;opacity:1;}.css-d1pqrt li a:before{content:'';position:absolute;right:100%;bottom:8px;left:12px;height:1px;background:#fff;opacity:0.25;-webkit-transition:all 0.35s ease-in-out;transition:all 0.35s ease-in-out;}.css-d1pqrt li a:hover:before{right:12px;opacity:0.5;}.css-d1pqrt .nav-current{opacity:1;}</style><ul role="menu" class="css-d1pqrt"><li role="menuitem"><a href="/">Home</a></li><li role="menuitem"><a href="/about">About</a></li><li role="menuitem"><a href="/tags/nlp">NLP</a></li><li role="menuitem"><a href="/tags/speech">Speech</a></li><li role="menuitem"><a href="/tags/paper">Paper</a></li><li role="menuitem"><a href="/tags/toolkit">Toolkit</a></li><li role="menuitem"><a href="/tags/book">Book</a></li><li role="menuitem"><a href="/tags/record">Record</a></li><li role="menuitem"><a href="/news">NEWS</a></li><li role="menuitem"><a href="/resume">RESUME</a></li></ul><style data-emotion="css 1wu52sc">.css-1wu52sc{visibility:hidden;position:absolute;top:9px;color:#fff;font-size:1.7rem;font-weight:400;text-transform:none;opacity:0;-webkit-transition:all 1s cubic-bezier(0.19, 1, 0.22, 1);transition:all 1s cubic-bezier(0.19, 1, 0.22, 1);-webkit-transform:translateY(175%);-moz-transform:translateY(175%);-ms-transform:translateY(175%);transform:translateY(175%);}.css-1wu52sc .dash{left:-25px;}.css-1wu52sc .dash:before{content:'– ';opacity:0.5;}</style><span class="nav-post-title css-1wu52sc ez7fnwk0">Large Scale LM (2) Distributed Programming</span></div></div><style data-emotion="css 1p9q30u">.css-1p9q30u{-webkit-flex:0 1 auto;-ms-flex:0 1 auto;flex:0 1 auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:end;-ms-flex-pack:end;-webkit-justify-content:flex-end;justify-content:flex-end;padding:10px 0;height:64px;}@media (max-width: 700px){.css-1p9q30u{display:none;}}</style><div class="css-1p9q30u ez7fnwk3"><style data-emotion="css 1z0rm8f">.css-1z0rm8f{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><div class="css-1z0rm8f ez7fnwk2"><style data-emotion="css uoy7tg">.css-uoy7tg{display:inline-block;margin:0;padding:10px;opacity:0.8;}.css-uoy7tg:hover{opacity:1;}.css-uoy7tg svg{height:1.8rem;fill:#fff;}.css-uoy7tg svg{height:1.6rem;}</style><a class="social-link-github css-uoy7tg" href="https://github.com/BOSOEK" target="_blank" title="Github" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a>,<a class="social-link-fb css-uoy7tg" href="https://www.facebook.com/profile.php?id=100011713266028" target="_blank" title="Facebook" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"></path></svg></a>,<a class="social-link-fb css-uoy7tg" href="https://www.linkedin.com/in/%EB%B3%B4%EC%84%9D-%EA%B9%80-206984217/" target="_blank" title="Facebook" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"></path></svg></a>,</div><style data-emotion="css tong54">.css-tong54{display:block;padding:4px 10px;margin:0 0 0 10px;border:#fff 1px solid;color:#fff;line-height:1em;border-radius:10px;opacity:0.8;}.css-tong54:hover{-webkit-text-decoration:none;text-decoration:none;opacity:1;cursor:pointer;}</style><a class="css-tong54 ez7fnwk1">Subscribe</a></div></nav></div></div></header><style data-emotion="css 12lzzeq">.css-12lzzeq{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;position:relative;padding:0 5vw;}@media (prefers-color-scheme: dark){.css-12lzzeq{background:#191b1f;}}</style><main id="site-main" class="site-main css-12lzzeq"><div class="css-y521qa"><style data-emotion="css 1wcdnkk">.css-1wcdnkk{position:relative;z-index:50;}</style><article class="css-1wcdnkk"><style data-emotion="css 1ypjvfm">.css-1ypjvfm{position:relative;margin:0 auto;padding:70px 170px 50px;border-top-left-radius:3px;border-top-right-radius:3px;}@media (max-width: 1170px){.css-1ypjvfm{padding:60px 11vw 50px;}}@media (max-width: 800px){.css-1ypjvfm{padding-right:5vw;padding-left:5vw;}}@media (max-width: 500px){.css-1ypjvfm{padding:20px 0 35px;}}</style><header class="post-full-header css-1ypjvfm euwger15"><style data-emotion="css a12yu7">.css-a12yu7{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:#738a94;font-size:1.3rem;line-height:1.4em;font-weight:600;text-transform:uppercase;}</style><section class="post-full-tags css-a12yu7 euwger14"><a href="/tags/nlp/">nlp</a>,<b> </b><a href="/tags/parallelism/">parallelism</a>,<b> </b><a href="/tags/large-scale/">large-scale</a>,<b> </b><a href="/tags/lm/">lm</a>,<b> </b></section><style data-emotion="css qia1z6">.css-qia1z6{margin:0 0 0.2em;color:#0b0c0e;}@media (max-width: 500px){.css-qia1z6{margin-top:0.2em;font-size:3.3rem;}}@media (prefers-color-scheme: dark){.css-qia1z6{color:rgba(255, 255, 255, 0.9);}}</style><h1 class="post-full-title css-qia1z6 euwger11">Large Scale LM (2) Distributed Programming</h1><style data-emotion="css 16sbnz0">.css-16sbnz0{margin:20px 0 0;color:var(--midgrey);font-family:Georgia,serif;font-size:2.3rem;line-height:1.4em;font-weight:300;}@media (max-width: 500px){.css-16sbnz0{font-size:1.9rem;line-height:1.5em;}}@media (prefers-color-scheme: dark){.css-16sbnz0{color:#90a2aa;}}</style><p class="post-full-custom-excerpt css-16sbnz0 euwger13"></p><style data-emotion="css 1pygz0x">.css-1pygz0x{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;margin:35px 0 0;padding-top:15px;border-top:1px solid #e4eaed;}.css-1pygz0x .post-full-byline-content{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;}.css-1pygz0x .post-full-byline-content .author-list{-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;padding:0 12px 0 0;}.css-1pygz0x .post-full-byline-meta{margin:2px 0 0;color:#90a2aa;font-size:1.2rem;line-height:1.2em;letter-spacing:0.2px;text-transform:uppercase;}.css-1pygz0x .post-full-byline-meta h4{margin:0 0 3px;font-size:1.3rem;line-height:1.4em;font-weight:500;}.css-1pygz0x .post-full-byline-meta h4 a{color:#2c3036;}.css-1pygz0x .post-full-byline-meta h4 a:hover{color:#15171A;}.css-1pygz0x .post-full-byline-meta .bull{display:inline-block;margin:0 4px;opacity:0.6;}@media (prefers-color-scheme: dark){.css-1pygz0x{border-top-color:#3b4049;}.css-1pygz0x .post-full-byline-meta h4 a{color:rgba(255, 255, 255, 0.75);}.css-1pygz0x .post-full-byline-meta h4 a:hover{color:#fff;}}</style><div class="post-full-byline css-1pygz0x euwger12"><section class="post-full-byline-content"><style data-emotion="css 12fmpzj">.css-12fmpzj{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;margin:0 0 0 4px;padding:0;list-style:none;}</style><ul class="author-list css-12fmpzj epdb2t70"><style data-emotion="css rzestn">.css-rzestn{position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;margin:0;padding:0;}.css-rzestn:hover .author-name-tooltip{opacity:1;-webkit-transform:translateY(0px);-moz-transform:translateY(0px);-ms-transform:translateY(0px);transform:translateY(0px);}</style><li class="author-list-item css-rzestn e1iirwvr1"><style data-emotion="css nqg22v">.css-nqg22v{position:absolute;bottom:130%;left:50%;z-index:600;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;margin-left:-200px;width:400px;font-size:1.4rem;line-height:1.5em;background:white;border-radius:3px;box-shadow:rgba(39, 44, 49, 0.08) 0 12px 26px,rgba(39, 44, 49, 0.06) 1px 3px 8px;opacity:0;-webkit-transition:all 0.35s cubic-bezier(0.4, 0.01, 0.165, 0.99);transition:all 0.35s cubic-bezier(0.4, 0.01, 0.165, 0.99);-webkit-transform:scale(0.98) translateY(15px);-moz-transform:scale(0.98) translateY(15px);-ms-transform:scale(0.98) translateY(15px);transform:scale(0.98) translateY(15px);pointer-events:none;padding:20px 20px 22px;}.css-nqg22v:before{content:'';position:absolute;top:100%;left:50%;display:block;margin-left:-8px;width:0;height:0;border-top:8px solid #fff;border-right:8px solid transparent;border-left:8px solid transparent;}.css-nqg22v .author-info{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;padding:0 0 0 20px;}.css-nqg22v .author-info h2{margin:8px 0 0;font-size:1.6rem;}.css-nqg22v .author-info p{margin:4px 0 0;color:color(var(--midgrey) l(-10%));}.css-nqg22v .author-info .bio h2{margin-top:0;}.css-nqg22v .author-info .bio p{margin-top:0.8em;}.css-nqg22v .author-profile-image{-webkit-flex:0 0 60px;-ms-flex:0 0 60px;flex:0 0 60px;margin:0;width:60px;height:60px;border:none;}@media (max-width: 1170px){.css-nqg22v{margin-left:-50px;width:430px;}.css-nqg22v:before{left:50px;}}@media (max-width: 650px){.css-nqg22v{display:none;}}@media (prefers-color-scheme: dark){.css-nqg22v{background:#22252a;box-shadow:0 12px 26px rgba(0, 0, 0, 0.4);}.css-nqg22v:before{border-top-color:#22252a;}}</style><div class="author-card css-nqg22v"><style data-emotion="css 1kq7wgl">.css-1kq7wgl{display:block;width:100%;height:100%;background:#e4eaed;border-radius:100%;object-fit:cover;}@media (prefers-color-scheme: dark){.css-1kq7wgl{background:#191b1f;}}</style><div class="author-info"><div class="bio"><h2>Soohwan Kim</h2><p>Co-founder/A.I. engineer at TUNiB.</p><p><a href="/author/soohwan-kim/">More posts</a> by<!-- --> <!-- -->Soohwan Kim<!-- -->.</p></div></div></div><style data-emotion="css 1smzq71">.css-1smzq71{display:block;overflow:hidden;margin:0 -4px;width:40px;height:40px;border:#fff 2px solid;border-radius:100%;-webkit-transition:all 0.5s cubic-bezier(0.4, 0.01, 0.165, 0.99) 700ms;transition:all 0.5s cubic-bezier(0.4, 0.01, 0.165, 0.99) 700ms;}@media (max-width: 500px){.css-1smzq71{width:36px;height:36px;}}@media (prefers-color-scheme: dark){.css-1smzq71{border-color:#1a1c20;}}</style><a class="author-avatar css-1smzq71" href="/author/soohwan-kim/"></a></li></ul><section class="post-full-byline-meta"><h4 class="author-name"><a href="/author/soohwan-kim/">Soohwan Kim</a></h4><div class="byline-meta-content"><time class="byline-meta-date" dateTime="2021-11-22">22 Nov 2021</time><span class="byline-reading-time"><span class="bull">•</span>17 min read</span></div></section></section></div></header><style data-emotion="css 8yjx3u">.css-8yjx3u{margin:25px 0 50px;height:800px;background:#c5d2d9 center center;-webkit-background-size:cover;background-size:cover;border-radius:5px;}@media (max-width: 1170px){.css-8yjx3u{margin:25px -6vw 50px;border-radius:0;}.css-8yjx3u img{max-width:1170px;}}@media (max-width: 800px){.css-8yjx3u{height:400px;}}@media (max-width: 500px){.css-8yjx3u{margin-bottom:4vw;height:350px;}}</style><figure class="css-8yjx3u euwger10"><div data-gatsby-image-wrapper="" style="height:100%" class="gatsby-image-wrapper"><div aria-hidden="true" style="padding-top:30.885416666666664%"></div><div aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear;background-color:#f8f8f8;position:absolute;top:0;left:0;bottom:0;right:0"></div><picture><source type="image/webp" data-srcset="/static/346eaa433ec4cadd1f537f0536913cd3/72019/big-model2.webp 750w,/static/346eaa433ec4cadd1f537f0536913cd3/acb5c/big-model2.webp 1080w,/static/346eaa433ec4cadd1f537f0536913cd3/41355/big-model2.webp 1366w,/static/346eaa433ec4cadd1f537f0536913cd3/a0759/big-model2.webp 1920w" sizes="100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="100vw" decoding="async" loading="lazy" data-src="/static/346eaa433ec4cadd1f537f0536913cd3/ca97d/big-model2.png" data-srcset="/static/346eaa433ec4cadd1f537f0536913cd3/260a8/big-model2.png 750w,/static/346eaa433ec4cadd1f537f0536913cd3/99085/big-model2.png 1080w,/static/346eaa433ec4cadd1f537f0536913cd3/cff5f/big-model2.png 1366w,/static/346eaa433ec4cadd1f537f0536913cd3/ca97d/big-model2.png 1920w" alt="Large Scale LM (2) Distributed Programming"/></picture><noscript><picture><source type="image/webp" srcSet="/static/346eaa433ec4cadd1f537f0536913cd3/72019/big-model2.webp 750w,/static/346eaa433ec4cadd1f537f0536913cd3/acb5c/big-model2.webp 1080w,/static/346eaa433ec4cadd1f537f0536913cd3/41355/big-model2.webp 1366w,/static/346eaa433ec4cadd1f537f0536913cd3/a0759/big-model2.webp 1920w" sizes="100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="100vw" decoding="async" loading="lazy" src="/static/346eaa433ec4cadd1f537f0536913cd3/ca97d/big-model2.png" srcSet="/static/346eaa433ec4cadd1f537f0536913cd3/260a8/big-model2.png 750w,/static/346eaa433ec4cadd1f537f0536913cd3/99085/big-model2.png 1080w,/static/346eaa433ec4cadd1f537f0536913cd3/cff5f/big-model2.png 1366w,/static/346eaa433ec4cadd1f537f0536913cd3/ca97d/big-model2.png 1920w" alt="Large Scale LM (2) Distributed Programming"/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1)}}</script></div></figure><style data-emotion="css prfsya">.css-prfsya{position:relative;margin:0 auto;padding:0 170px 6vw;min-height:230px;font-family:sans-serif,serif;font-size:2rem;line-height:1.6em;background:#fff;}@media (max-width: 1170px){.css-prfsya{padding:0 11vw;}}@media (max-width: 800px){.css-prfsya{padding:0 5vw;font-size:1.8rem;}}@media (max-width: 500px){.css-prfsya{padding:0;}}@media (max-width: 500px){.css-prfsya .post-full-custom-excerpt{font-size:1.9rem;line-height:1.5em;}}.css-prfsya .no-image{padding-top:0;}.css-prfsya h1,.css-prfsya h2,.css-prfsya h3,.css-prfsya h4,.css-prfsya h5,.css-prfsya h6,.css-prfsya p,.css-prfsya ul,.css-prfsya ol,.css-prfsya dl,.css-prfsya pre,.css-prfsya blockquote,.css-prfsya .post-full-comments,.css-prfsya .footnotes{margin:0 0 1.5em 0;min-width:100%;}@media (max-width: 500px){.css-prfsya p,.css-prfsya ul,.css-prfsya ol,.css-prfsya dl,.css-prfsya pre,.css-prfsya .post-full-comments,.css-prfsya .footnotes{margin-bottom:1.28em;}}.css-prfsya li{word-break:break-word;}.css-prfsya li p{margin:0;}.css-prfsya a{color:#15171A;word-break:break-word;box-shadow:#15171A 0 -1px 0 inset;-webkit-transition:all 0.2s ease-in-out;transition:all 0.2s ease-in-out;}.css-prfsya a:hover{color:#3eb0ef;-webkit-text-decoration:none;text-decoration:none;box-shadow:#3eb0ef 0 -1px 0 inset;}.css-prfsya strong,.css-prfsya em{color:#0a0b0c;}.css-prfsya small{display:inline-block;line-height:1.6em;}.css-prfsya img,.css-prfsya video{display:block;margin:1.5em auto;max-width:1040px;height:auto;}@media (max-width: 1040px){.css-prfsya img,.css-prfsya video{width:100%;}}.css-prfsya img[src$='#full']{max-width:none;width:100vw;}.css-prfsya img+br+small{display:block;margin-top:-3em;margin-bottom:1.5em;text-align:center;}.css-prfsya iframe{margin:0 auto!important;}.css-prfsya blockquote{margin:0 0 1.5em;padding:0 1.5em;border-left:#3eb0ef 3px solid;}@media (max-width: 500px){.css-prfsya blockquote{padding:0 1.3em;}}.css-prfsya blockquote p{margin:0 0 1em 0;color:inherit;font-size:inherit;line-height:inherit;font-style:italic;}.css-prfsya blockquote p:last-child{margin-bottom:0;}.css-prfsya code{padding:0 5px 2px;font-size:0.8em;line-height:1em;font-weight:400!important;background:#e5eff5;border-radius:3px;}.css-prfsya p code{word-break:break-all;}.css-prfsya pre{overflow-x:auto;padding:20px;max-width:100%;color:#e5eff5;font-size:1.4rem;line-height:1.5em;border-radius:5px;}.css-prfsya pre ::selection{color:#3b474d;}.css-prfsya pre code{padding:0;font-size:inherit;line-height:inherit;background:transparent;}.css-prfsya pre code :not(span){color:inherit;}.css-prfsya .fluid-width-video-wrapper{margin:1.5em 0 3em;}.css-prfsya hr{margin:2em 0;}.css-prfsya hr:after{content:'';position:absolute;top:-15px;left:50%;display:block;margin-left:-10px;width:1px;height:30px;background:#e4eaed;box-shadow:#fff 0 0 0 5px;-webkit-transform:rotate(45deg);-moz-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);}.css-prfsya hr+p{margin-top:1.2em;}.css-prfsya h1,.css-prfsya h2,.css-prfsya h3,.css-prfsya h4,.css-prfsya h5,.css-prfsya h6{color:#0a0b0c;font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Oxygen,Ubuntu,Cantarell,'Open Sans','Helvetica Neue',sans-serif;}.css-prfsya h1{margin:0.5em 0 0.4em;font-size:4.2rem;line-height:1.25em;font-weight:600;}.css-prfsya p+h1{margin-top:0.8em;}@media (max-width: 800px){.css-prfsya h1{font-size:3.2rem;line-height:1.25em;}}.css-prfsya h2{margin:0.5em 0 0.4em;font-size:3.2rem;line-height:1.25em;font-weight:600;}.css-prfsya p+h2{margin-top:0.8em;}@media (max-width: 800px){.css-prfsya h2{margin-bottom:0.3em;font-size:2.8rem;line-height:1.25em;}}.css-prfsya h3{margin:0.5em 0 0.2em;font-size:2.5rem;line-height:1.3em;font-weight:600;}.css-prfsya h2+h3{margin-top:0.7em;}@media (max-width: 800px){.css-prfsya h3{margin-bottom:0.3em;font-size:2.4rem;line-height:1.3em;}}.css-prfsya h4{margin:0.5em 0 0.2em;font-size:2.5rem;font-weight:600;}.css-prfsya h2+h4{margin-top:0.7em;}.css-prfsya h3+h4{margin-top:0;}@media (max-width: 800px){.css-prfsya h4{margin-bottom:0.3em;font-size:2.4rem;line-height:1.3em;}}.css-prfsya h5{display:block;margin:0.5em 0;padding:0.4em 1em 0.9em;border:0;color:#3eb0ef;font-family:Georgia,serif;font-size:3.2rem;line-height:1.35em;text-align:center;}@media (min-width: 1180px){.css-prfsya h5{max-width:1060px;}}@media (max-width: 800px){.css-prfsya h5{margin-bottom:1em;margin-left:1.3em;padding:0 0 0.5em;font-size:2.4rem;text-align:initial;}}.css-prfsya h6{margin:0.5em 0 0.2em 0;font-size:2rem;font-weight:700;}@media (max-width: 800px){.css-prfsya h6{font-size:1.8rem;line-height:1.4em;}}.css-prfsya table{display:inline-block;overflow-x:auto;margin:0.5em 0 2.5em;max-width:100%;width:auto;border-spacing:0;border-collapse:collapse;font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Oxygen,Ubuntu,Cantarell,'Open Sans','Helvetica Neue',sans-serif;font-size:1.6rem;white-space:nowrap;vertical-align:top;}.css-prfsya table{-webkit-overflow-scrolling:touch;background:radial-gradient(ellipse at left, rgba(0, 0, 0, 0.2) 0%, rgba(0, 0, 0, 0) 75%) 0 center,radial-gradient(ellipse at right, rgba(0, 0, 0, 0.2) 0%, rgba(0, 0, 0, 0) 75%) 100% center;background-attachment:scroll,scroll;-webkit-background-size:10px 100%,10px 100%;background-size:10px 100%,10px 100%;background-repeat:no-repeat;}.css-prfsya table td:first-of-type{background-image:linear-gradient(
      to right,
      rgba(255, 255, 255, 1) 50%,
      rgba(255, 255, 255, 0) 100%
    );-webkit-background-size:20px 100%;background-size:20px 100%;background-repeat:no-repeat;}.css-prfsya table td:last-child{background-image:linear-gradient(
      to left,
      rgba(255, 255, 255, 1) 50%,
      rgba(255, 255, 255, 0) 100%
    );-webkit-background-position:100% 0;background-position:100% 0;-webkit-background-size:20px 100%;background-size:20px 100%;background-repeat:no-repeat;}.css-prfsya table th{color:#15171A;font-size:1.2rem;font-weight:700;letter-spacing:0.2px;text-align:left;text-transform:uppercase;background-color:#f4f8fb;}.css-prfsya table th,.css-prfsya table td{padding:6px 12px;border:#e1edf4 1px solid;}@media (prefers-color-scheme: dark){.css-prfsya{background:#191b1f;}.css-prfsya h1,.css-prfsya h2,.css-prfsya h3,.css-prfsya h4,.css-prfsya h6{color:rgba(255, 255, 255, 0.9);}.css-prfsya a{color:#fff;box-shadow:inset 0 -1px 0 #fff;}.css-prfsya strong{color:#fff;}.css-prfsya em{color:#fff;}.css-prfsya code{color:#fff;background:#000;}.css-prfsya hr{border-top-color:#17191c;}.css-prfsya hr:after{background:#17191c;box-shadow:#191b1f 0 0 0 5px;}.css-prfsya figcaption{color:rgba(255, 255, 255, 0.6);}.css-prfsya table td:first-of-type{background-image:linear-gradient(to right, #191b1f 50%, #191b1f 100%);}.css-prfsya table td:last-child{background-image:linear-gradient(270deg, #191b1f 50%, rgba(25, 27, 31, 0));}.css-prfsya table th{color:rgba(255, 255, 255, 0.85);background-color:#2b2f36;}.css-prfsya table th,.css-prfsya table td{border:#2b2f36 1px solid;}.css-prfsya .kg-bookmark-container,.css-prfsya .kg-bookmark-container:hover{color:rgba(255, 255, 255, 0.75);box-shadow:0 0 1px rgba(255, 255, 255, 0.9);}}.css-prfsya code[class*='language-'],.css-prfsya pre[class*='language-']{color:white;background:none;font-family:Consolas,Menlo,Monaco,source-code-pro,Courier New,monospace;font-feature-settings:normal;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;margin-bottom:0;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;}.css-prfsya pre[class*='language-']{overflow:auto;}.css-prfsya pre[class*='language-']::-moz-selection{background:hsl(207, 4%, 16%);}.css-prfsya pre[class*='language-']::selection{background:hsl(207, 4%, 16%);}.css-prfsya pre[class*='language-']::-moz-selection,.css-prfsya pre[class*='language-'] ::-moz-selection{text-shadow:none;background:hsla(0, 0%, 100%, 0.15);}.css-prfsya pre[class*='language-']::selection,.css-prfsya pre[class*='language-'] ::selection{text-shadow:none;background:hsla(0, 0%, 100%, 0.15);}.css-prfsya *:not(pre)>code[class*='language-']{border-radius:0.3em;background:rgb(1, 22, 39);color:white;padding:0.15em 0.5em;white-space:normal;}.css-prfsya .token.attr-name{color:rgb(173, 219, 103);font-style:italic;}.css-prfsya .token.comment{color:rgb(128, 147, 147);}.css-prfsya .token.string,.css-prfsya .token.url{color:rgb(173, 219, 103);}.css-prfsya .token.variable{color:rgb(214, 222, 235);}.css-prfsya .token.number{color:rgb(247, 140, 108);}.css-prfsya .token.builtin,.css-prfsya .token.char,.css-prfsya .token.constant,.css-prfsya .token.function{color:rgb(130, 170, 255);}.css-prfsya .token.punctuation{color:rgb(199, 146, 234);}.css-prfsya .token.selector,.css-prfsya .token.doctype{color:rgb(199, 146, 234);font-style:'italic';}.css-prfsya .token.class-name{color:rgb(255, 203, 139);}.css-prfsya .token.tag,.css-prfsya .token.operator,.css-prfsya .token.keyword{color:#ffa7c4;}.css-prfsya .token.boolean{color:rgb(255, 88, 116);}.css-prfsya .token.property{color:rgb(128, 203, 196);}.css-prfsya .token.namespace{color:rgb(178, 204, 214);}.css-prfsya pre[data-line]{padding:1em 0 1em 3em;position:relative;}.css-prfsya .gatsby-highlight-code-line{background-color:hsla(207, 95%, 15%, 1);display:block;margin-right:-1.3125rem;margin-left:-1.3125rem;padding-right:1em;padding-left:1.25em;border-left:0.25em solid #ffa7c4;}.css-prfsya .gatsby-highlight{margin-bottom:1.75rem;margin-left:-1.3125rem;margin-right:-1.3125rem;border-radius:10px;background:#011627;-webkit-overflow-scrolling:touch;overflow:auto;}.css-prfsya .gatsby-highlight pre[class*='language-']{float:left;min-width:100%;}</style><section class="post-full-content css-prfsya e1ee9s2g0"><div><h1>Large Scale LM (2) Distributed Programming (작성중)</h1>
<p>이 자료는 <a href="https://github.com/tunib-ai/large-scale-lm-tutorials">[해당 link]</a> 를 참고하며 제 언어로 재작성한 글입니다.<br/>
저의 추가적인 메모나 의견이 삽입되거나 삭제된 내용이 있습니다.<br/>
더 퀄리티가 좋은 자료는 위의 링크를 참고하시길 바랍니다.</p>
<hr/>
<p>Large-Scale 모델은 메모리를 많이 먹기 때문에 어느 정도 커지게 되면 하나의 GPU에 올릴 수가 없습니다.
Big Model 학습이 어려운 주된 이유죠. 그래서 이런 Large-Scale 모델의 경우 여러대의 GPU에 모델을 쪼개서 올려야 합니다.
그리고 쪼개진 모델을 받은 GPU들간에 네트워크로 통신을 하면서 값을 주고 받아야 합니다. 이렇게 여러대의 장비로 분산시켜서
처리하는 작업을 분산처리라고 합니다. 이번 포스트에서는 PyTorch 프레임워크를 이용한 분산 프로그래밍 기초에 대해서 알아보겠습니다.</p>
<h2>Multi-processing with PyTorch</h2>
<p>분산 프로그래밍의 원활한 이해를 돕기 위해 PyTorch의 Multi-processing 애플리케이션에 대한 튜토리얼을 먼저 살펴보겠습니다.</p>
<h3>Multi-process Terms</h3>
<ul>
<li>Node: 컴퓨터 혹은 서버와 같은 장비를 말합니다. AI 쪽에서는 보통 GPU 여러대가 묶여있는 하나의 컴퓨터 or 서버를 칭합니다.</li>
<li>Global Rank: 원래는 프로세스의 우선순위를 의미하지만 여기서는 의미는 주로 <strong>GPU의 ID</strong>라고 보면 됩니다.</li>
<li>Local Rank: 원래는 한 노드내에서의 프로세스 우선순위를 의미하지만, 여기서는 <strong>한 노드내의 GPU ID</strong>라고 보면 됩니다.</li>
<li>World Size: 프로세스의 개수를 의미합니다. 여기서는 주로 GPU의 개수를 의미합니다.</li>
</ul>
<img src="https://github.com/tunib-ai/large-scale-lm-tutorials/raw/ca29ff9f945a59abcc3e3f1000c4d83de97973d4/images/process_terms.png" width="500"/>  
<h3>Multi-process Application 실행 방법</h3>
<p>PyTorch Multi-process 어플리케이션 실행 방법은 두 가지가 있습니다.</p>
<ol>
<li>으사용자의 코드가 메인 프로세스가 되어 특정 함수를 서브프로세스로 분기한다.</li>
<li>PyTorch 런쳐가 메인 프로세스가 되어 사용자 코드 전체를 서브 프로세스로 분기한다.</li>
</ol>
<h3>1) 사용자의 코드가 메인 프로세스가 되어 특정 함수를 서브프로세스로 분기한다.</h3>
<img src="https://github.com/tunib-ai/large-scale-lm-tutorials/raw/ca29ff9f945a59abcc3e3f1000c4d83de97973d4/images/multi_process_1.png" width="500"/> 
<p>일반적으로 <code class="language-text">Spawn</code>과 <code class="language-text">Fork</code> 등 두 가지 방식으로 분기할 수 있습니다.</p>
<ul>
<li><code class="language-text">Spawn</code>
<ul>
<li>메인 프로세스의 자원을 물려주지 않고 필요한 만큼의 자원만 서브프로세스에게 새로 할당</li>
<li>속도가 느리지만 안전한 방식</li>
</ul>
</li>
<li><code class="language-text">Fork</code>
<ul>
<li>메인 프로세스의 모든 자원을 서브 프로세스와 공유하고 프로세스를 시작</li>
<li>속도가 빠르지만 위험한 방식</li>
</ul>
</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>multiprocessing <span class="token keyword">as</span> mp


<span class="token keyword">def</span> <span class="token function">fn</span><span class="token punctuation">(</span>rank<span class="token punctuation">,</span> param1<span class="token punctuation">,</span> param2<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;</span><span class="token interpolation"><span class="token punctuation">{</span>param1<span class="token punctuation">}</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">{</span>param2<span class="token punctuation">}</span></span><span class="token string"> - rank: </span><span class="token interpolation"><span class="token punctuation">{</span>rank<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>


processes <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
mp<span class="token punctuation">.</span>set_start_method<span class="token punctuation">(</span><span class="token string">&quot;spawn&quot;</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> rank <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    process <span class="token operator">=</span> mp<span class="token punctuation">.</span>Process<span class="token punctuation">(</span>target<span class="token operator">=</span>fn<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>rank<span class="token punctuation">,</span> <span class="token string">&quot;A0&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;B1&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    process<span class="token punctuation">.</span>daemon <span class="token operator">=</span> <span class="token boolean">False</span>
    process<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    processes<span class="token punctuation">.</span>append<span class="token punctuation">(</span>process<span class="token punctuation">)</span>

<span class="token keyword">for</span> process <span class="token keyword">in</span> processes<span class="token punctuation">:</span>
    process<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">A0 B1 - rank: 0
A0 B1 - rank: 2
A0 B1 - rank: 3
A0 B1 - rank: 1</code></pre></div>
<h3>2) PyTorch 런처가 부모 프로세스가 되어 사용자 코드 전체를 서브프로세스로 분기한다.</h3>
<img src="https://github.com/tunib-ai/large-scale-lm-tutorials/raw/ca29ff9f945a59abcc3e3f1000c4d83de97973d4/images/multi_process_2.png" width="500"/>
<p>이 방식은 <code class="language-text">python -m torch.distributed.launch --nproc_per_node=n OOO.py</code>와 같은 방식으로 실행해줘야 동작합니다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> os

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;hello world, </span><span class="token interpolation"><span class="token punctuation">{</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&#x27;RANK&#x27;</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">hello world, 0
hello world, 1
hello world, 2
hello world, 3</code></pre></div>
<h2>Distributed Programming with PyTorch</h2>
<h4>Concept of Message Passing</h4>
<p>OS 과목에서 배우는 개념이죠. 몇 년 전에 OS 과목을 배울 때 Message Passing은 분산 환경에서 주로 사용된다고 배운 기억이 있습니다.
Message Passing이란 Shared Memory(공유 메모리) 없이 프로세스간에 데이터를 주고 받는 방법입니다.
특정 태그가 달린 데이터를 네트워크에 보내면 다른 프로세스간 해당 데이터를 리시브를 하도록 하는 방식입니다.
코드 레벨에서 특정 태그를 이용하여 프로그래밍 해두면 원하는대로 원하는 프로세스에 데이터를 전달할 수 있습니다.
Large-scale 모델 개발시 이용되는 분산 통신 역시 대부분 이런 Message Passing 기법이 사용됩니다.</p>
<img src="https://user-images.githubusercontent.com/42150335/147876208-04481ccb-e115-41c4-9722-9639c185c498.png" width="400"/>  
<h4>MPI (Message Passing Interface)</h4>
<p>MPI는 Message Passing에 대한 표준 인터페이스입니다. MPI는 Message Passing에 사용되는 여러 연산 (e.g. broadcast, reduce, scatter, gather, …)
등이 정의되어 있으며 대표적으로 OpenMPI라는 오픈소스가 존재합니다.</p>
<p><a href="https://www.open-mpi.org/">https://www.open-mpi.org/</a></p>
<h4>NCCL &amp; GLOO</h4>
<p>하지만 실제 사용에서는 openmpi보다는 nccl이나 gloo 같은 라이브러리를 많이 사용합니다.</p>
<ul>
<li>NCCL (NVIDIA COllective Communication Library)
<ul>
<li>NVIDIA에서 개발한 GPU 특화 Message Passing 라이브러리 (<code class="language-text">nickel</code>라고 읽는다고 합니다.)</li>
<li>NVIDIA GPU에서 사용시, 다른 라이브러리에 비해 월등히 빠르다고 알려져 있습니다.</li>
</ul>
</li>
<li>GLOO (Facebook’s Collective Communication Library)
<ul>
<li>Facebook에서 개발된 Message Passing 라이브러리입니다.</li>
<li><code class="language-text">torch</code>에서 주로 CPU 분산 처리에 사용됩니다.</li>
</ul>
</li>
<li>일반적으로는 CPU는 GLOO, GPU는 NCCL을 사용하면 됩니다.</li>
</ul>
<h4>torch.distributed 패키지</h4>
<p>torch.distributed 패키지는 gloo, nccl, openmpi 등을 하이레벨에서 래핑하고 있기 때문에,
일반적으로는 torch.distributed를 이용해서 프로그래밍을 하게 됩니다.</p>
<h4>Process Group</h4>
<p>프로세스가 많은 경우, 관리하기가 어렵습니다. 이럴때는 보통 프로세스 그룹을 만들어서 관리를 합니다.
<code class="language-text">torch.distributed</code>의 <code class="language-text">init_process_group</code>을 호출하면 전체 프로세스가 속한 default group이 만들어집니다.</p>
<p>주의할 점은 <code class="language-text">init_process_group</code> 함수는 반드시 서브프로세스에서 실행되어야 하며, 추가로 사용자가 원하는 프로세스들만 모아서
그룹을 생성하려면 <code class="language-text">new_group</code>을 호출해야 합니다.</p>
<ul>
<li>예제 1</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&quot;RANK&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&quot;0&quot;</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&quot;LOCAL_RANK&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&quot;0&quot;</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&quot;WORLD_SIZE&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&quot;1&quot;</span>

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&quot;MASTER_ADDR&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&quot;localhost&quot;</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&quot;MASTER_PORT&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&quot;29500&quot;</span>

dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span><span class="token string">&#x27;nccl&#x27;</span><span class="token punctuation">,</span> rank<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> wirld_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
process_group <span class="token operator">=</span> dist<span class="token punctuation">.</span>new_group<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre></div>
<ul>
<li>예제 2</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>multiprocessing <span class="token keyword">as</span> mp
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist


<span class="token keyword">def</span> <span class="token function">fn</span><span class="token punctuation">(</span>rank<span class="token punctuation">,</span> world_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span><span class="token string">&#x27;nccl&#x27;</span><span class="token punctuation">,</span> rank<span class="token operator">=</span>rank<span class="token punctuation">,</span> world_size<span class="token operator">=</span>world_size<span class="token punctuation">)</span>
    group <span class="token operator">=</span> dist<span class="token punctuation">.</span>new_group<span class="token punctuation">(</span><span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>world_size<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&quot;MASTER_ADDR&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&quot;localhost&quot;</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&quot;MASTER_PORT&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&quot;29500&quot;</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&quot;WORLD_SIZE&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&quot;4&quot;</span>

mp<span class="token punctuation">.</span>spawn<span class="token punctuation">(</span>
  fn<span class="token operator">=</span>fn<span class="token punctuation">,</span>
  args<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  nprocs<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>
  join<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
  daemon<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
  start_method<span class="token operator">=</span><span class="token string">&quot;spawn&quot;</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span></code></pre></div>
<p>위 코드의 경우 python3 ***.py와 같이 실행하면 됩니다.</p>
<ul>
<li>예제 3</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist

dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span>backend<span class="token operator">=</span><span class="token string">&quot;nccl&quot;</span><span class="token punctuation">)</span>
group <span class="token operator">=</span> dist<span class="token punctuation">.</span>new_group<span class="token punctuation">(</span><span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>dist<span class="token punctuation">.</span>get_world_size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre></div>
<p>위 코드는 python3 -m torch.distributed.launch —nproc_per_node=N ***.py와 같이 실행할 수 있습니다.</p>
<h4>P2P Communication (Point to Point)</h4>
<img src="https://user-images.githubusercontent.com/42150335/147877032-e1439e42-8db2-451a-9098-43063ac914e1.png" width="300"/>  
<p>P2P 통신은 특정 프로세스에서 다른 프로세스로 데이터를 전송하는 통신입니다. torch.distributed 패키지의 <code class="language-text">send</code>, <code class="language-text">recv</code> 함수를 활용하여 통신할 수 있습니다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist

dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span><span class="token string">&quot;gloo&quot;</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
    tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
    dist<span class="token punctuation">.</span>send<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dst<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">elif</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
    tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;rank 1 before: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">\n&quot;</span></span><span class="token punctuation">)</span>
    dist<span class="token punctuation">.</span>recv<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> src<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;rank 1 after: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">\n&quot;</span></span><span class="token punctuation">)</span>

<span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">raise</span> RuntimeError<span class="token punctuation">(</span><span class="token string">&quot;wrong rank&quot;</span><span class="token punctuation">)</span></code></pre></div>
<p><code class="language-text">send</code>, <code class="language-text">recv</code>는 동기적으로 통신합니다. 비동기 방식 (non-blocking)으로 사용하려면 <code class="language-text">isend</code>, <code class="language-text">irecv</code>를 사용해야 합니다.
비동기 방식에서는 <code class="language-text">wait()</code> 메서드를 통해 다른 프로세스의 통신이 끝날때까지 기다린 뒤에 접근해야 합니다.
멀티스레딩 프로그래밍 할 때가 기억나네요 😅</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist

dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span><span class="token string">&quot;gloo&quot;</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
    tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
    request <span class="token operator">=</span> dist<span class="token punctuation">.</span>isend<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dst<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">elif</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
    tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
    request <span class="token operator">=</span> dist<span class="token punctuation">.</span>irecv<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> src<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">raise</span> RuntimeError<span class="token punctuation">(</span><span class="token string">&quot;wrong rank&quot;</span><span class="token punctuation">)</span>

request<span class="token punctuation">.</span>wait<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;rank </span><span class="token interpolation"><span class="token punctuation">{</span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></code></pre></div>
<h3>Collective Communication</h3>
<p>Collective Communication은 여러 프로세스가 참여하는 통신을 의미합니다. 다양한 연산들이 있지만 기본적으로
아래 4개의 연산이 중요합니다.</p>
<img src="https://user-images.githubusercontent.com/42150335/147877159-26b24204-de88-416b-9ad0-5c1061a82c26.png" width="450"/>
<p>여기 4개에 추가로 <code class="language-text">all-reduce</code>, <code class="language-text">all-gather</code>, <code class="language-text">reduce-scatter</code> 등의 복합 연산과 동기화 연산인 <code class="language-text">barrier</code>까지 총 8개 연산에 대해 아래에서 알아보겠습니다.</p>
<h4>Broadcast</h4>
<p>Broadcast는 특정 프로세스의 데이터를 그룹내의 모든 프로세스에 복사하는 연산입니다.</p>
<img src="https://user-images.githubusercontent.com/42150335/147877187-10e16fb5-620f-496f-b52f-04769d47ad69.png" width="400"/>  
<p><code class="language-text">torch.distributed.broadcast</code>로 사용 가능합니다. <code class="language-text">broadcast</code>는 상황에 따라서 P2P 통신 용도로도 사용 가능합니다.</p>
<ul>
<li>참고 예제 (deepspeed/runtime/pipe/p2p.py)</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">send</span><span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dest_stage<span class="token punctuation">,</span> async_op<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">global</span> _groups
    <span class="token keyword">assert</span> async_op <span class="token operator">==</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token string">&quot;Doesnt support async_op true&quot;</span>
    src_stage <span class="token operator">=</span> _grid<span class="token punctuation">.</span>get_stage_id<span class="token punctuation">(</span><span class="token punctuation">)</span>
    _is_valid_send_recv<span class="token punctuation">(</span>src_stage<span class="token punctuation">,</span> dest_stage<span class="token punctuation">)</span>

    dest_rank <span class="token operator">=</span> _grid<span class="token punctuation">.</span>stage_to_global<span class="token punctuation">(</span>stage_id<span class="token operator">=</span>dest_stage<span class="token punctuation">)</span>
    <span class="token keyword">if</span> async_op<span class="token punctuation">:</span>
        <span class="token keyword">global</span> _async
        op <span class="token operator">=</span> dist<span class="token punctuation">.</span>isend<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dest_rank<span class="token punctuation">)</span>
        _async<span class="token punctuation">.</span>append<span class="token punctuation">(</span>op<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>

        <span class="token keyword">if</span> can_send_recv<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> dist<span class="token punctuation">.</span>send<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dest_rank<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            group <span class="token operator">=</span> _get_send_recv_group<span class="token punctuation">(</span>src_stage<span class="token punctuation">,</span> dest_stage<span class="token punctuation">)</span>
            src_rank <span class="token operator">=</span> _grid<span class="token punctuation">.</span>stage_to_global<span class="token punctuation">(</span>stage_id<span class="token operator">=</span>src_stage<span class="token punctuation">)</span>
            <span class="token keyword">return</span> dist<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> src_rank<span class="token punctuation">,</span> group<span class="token operator">=</span>group<span class="token punctuation">,</span> async_op<span class="token operator">=</span>async_op<span class="token punctuation">)</span></code></pre></div>
<h4>Reduce</h4>
<p>Reduce는 각 프로세스가 가진 데이터로 특정 연산을 수행해서 출력을 하나의 디바이스로 모아주는 연산입니다.
주로 sum, max, min 등의 연산을 수행합니다.</p>
<img src="https://user-images.githubusercontent.com/42150335/147877296-57e4f5e4-9d50-4424-a674-08e3d5ecc20a.png" width="400"/>  
<ul>
<li>Reduce sum 예시</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist

dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span><span class="token string">&quot;nccl&quot;</span><span class="token punctuation">)</span>
rank <span class="token operator">=</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>rank<span class="token punctuation">)</span>

tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>current_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> rank
<span class="token comment"># rank==0 =&gt; [[0, 0], [0, 0]]</span>
<span class="token comment"># rank==1 =&gt; [[1, 1], [1, 1]]</span>
<span class="token comment"># rank==2 =&gt; [[2, 2], [2, 2]]</span>
<span class="token comment"># rank==3 =&gt; [[3, 3], [3, 3]]</span>

dist<span class="token punctuation">.</span><span class="token builtin">reduce</span><span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> op<span class="token operator">=</span>torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>ReduceOp<span class="token punctuation">.</span>SUM<span class="token punctuation">,</span> dst<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> rank <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>

<span class="token comment"># tensor([[6., 6.],</span>
<span class="token comment">#         [6., 6.]]</span></code></pre></div>
<h4>Scatter</h4>
<p>Scatter는 여러 element를 쪼개서 각 device에 뿌려주는 연산입니다.</p>
<img src="https://user-images.githubusercontent.com/42150335/147877358-f444a3e4-de35-4bd9-bb1d-9825b505add2.png" width="400"/>
<ul>
<li>예시</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist

dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span><span class="token string">&quot;gloo&quot;</span><span class="token punctuation">)</span>
<span class="token comment"># nccl은 scatter를 지원하지 않습니다.</span>
rank <span class="token operator">=</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>rank<span class="token punctuation">)</span>


output <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;before rank </span><span class="token interpolation"><span class="token punctuation">{</span>rank<span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>output<span class="token punctuation">}</span></span><span class="token string">\n&quot;</span></span><span class="token punctuation">)</span>

<span class="token keyword">if</span> rank <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
    inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token number">20.0</span><span class="token punctuation">,</span> <span class="token number">30.0</span><span class="token punctuation">,</span> <span class="token number">40.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> split_size_or_sections<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment"># (tensor([10]), tensor([20]), tensor([30]), tensor([40]))</span>
    dist<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>output<span class="token punctuation">,</span> scatter_list<span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">,</span> src<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    dist<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>output<span class="token punctuation">,</span> src<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;after rank </span><span class="token interpolation"><span class="token punctuation">{</span>rank<span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>output<span class="token punctuation">}</span></span><span class="token string">\n&quot;</span></span><span class="token punctuation">)</span>

<span class="token comment"># before rank 0: tensor([0.])</span>
<span class="token comment"># before rank 3: tensor([0.])</span>
<span class="token comment"># after rank 3: tensor([40.])</span>
<span class="token comment"># before rank 1: tensor([0.])</span>
<span class="token comment"># before rank 2: tensor([0.])</span>
<span class="token comment"># after rank 0: tensor([10.])</span>
<span class="token comment"># after rank 1: tensor([20.])</span>
<span class="token comment"># after rank 2: tensor([30.])</span></code></pre></div>
<p><code class="language-text">nccl</code>에서는 scatter 연산이 지원되지 않아서 아래 같은 방법으로 scatter 연산을 수행합니다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist

dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span><span class="token string">&quot;nccl&quot;</span><span class="token punctuation">)</span>
rank <span class="token operator">=</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>rank<span class="token punctuation">)</span>

inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token number">20.0</span><span class="token punctuation">,</span> <span class="token number">30.0</span><span class="token punctuation">,</span> <span class="token number">40.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>tensor<span class="token operator">=</span>inputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> split_size_or_sections<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> inputs<span class="token punctuation">[</span>rank<span class="token punctuation">]</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>current_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;after rank </span><span class="token interpolation"><span class="token punctuation">{</span>rank<span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>output<span class="token punctuation">}</span></span><span class="token string">\n&quot;</span></span><span class="token punctuation">)</span>

<span class="token comment"># after rank 2: tensor([30.], device=&#x27;cuda:2&#x27;)</span>
<span class="token comment"># after rank 3: tensor([40.], device=&#x27;cuda:3&#x27;) </span>
<span class="token comment"># after rank 0: tensor([10.], device=&#x27;cuda:0&#x27;)</span>
<span class="token comment"># after rank 1: tensor([20.], device=&#x27;cuda:1&#x27;)</span></code></pre></div>
<ul>
<li>Megatron-LM Scatter 예시</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_split</span><span class="token punctuation">(</span>input_<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Split the tensor along its last dimension and keep the
    corresponding slice.&quot;&quot;&quot;</span>

    world_size <span class="token operator">=</span> get_tensor_model_parallel_world_size<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># Bypass the function if we are using only 1 GPU.</span>
    <span class="token keyword">if</span> world_size<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> input_

    <span class="token comment"># Split along last dimension.</span>
    input_list <span class="token operator">=</span> split_tensor_along_last_dim<span class="token punctuation">(</span>input_<span class="token punctuation">,</span> world_size<span class="token punctuation">)</span>

    <span class="token comment"># Note: torch.split does not create contiguous tensors by default.</span>
    rank <span class="token operator">=</span> get_tensor_model_parallel_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>
    output <span class="token operator">=</span> input_list<span class="token punctuation">[</span>rank<span class="token punctuation">]</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> output

<span class="token keyword">class</span> <span class="token class-name">_ScatterToModelParallelRegion</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>Function<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Split the input and keep only the corresponding chuck to the rank.&quot;&quot;&quot;</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">symbolic</span><span class="token punctuation">(</span>graph<span class="token punctuation">,</span> input_<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> _split<span class="token punctuation">(</span>input_<span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>ctx<span class="token punctuation">,</span> input_<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> _split<span class="token punctuation">(</span>input_<span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>ctx<span class="token punctuation">,</span> grad_output<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> _gather<span class="token punctuation">(</span>grad_output<span class="token punctuation">)</span></code></pre></div>
<h4>Gather</h4>
<p>Gather는 여러 디바이스에 존재하는 텐서를 하나로 모아주는 연산입니다.</p>
<img src="https://user-images.githubusercontent.com/42150335/147877443-3e479d6f-c7e0-4da4-9f77-723e7e3208a6.png" width="400"/>
<ul>
<li>gather 예시</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist

dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span><span class="token string">&quot;gloo&quot;</span><span class="token punctuation">)</span>
<span class="token comment"># nccl은 gather를 지원하지 않습니다.</span>
rank <span class="token operator">=</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>rank<span class="token punctuation">)</span>

<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> rank
<span class="token comment"># rank==0 =&gt; [0]</span>
<span class="token comment"># rank==1 =&gt; [1]</span>
<span class="token comment"># rank==2 =&gt; [2]</span>
<span class="token comment"># rank==3 =&gt; [3]</span>

<span class="token keyword">if</span> rank <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
    outputs_list <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    dist<span class="token punctuation">.</span>gather<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> gather_list<span class="token operator">=</span>outputs_list<span class="token punctuation">,</span> dst<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>outputs_list<span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    dist<span class="token punctuation">.</span>gather<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> dst<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># [tensor([0.]), tensor([1.]), tensor([2.]), tensor([3.])]</span></code></pre></div>
<h4>All-reduce</h4>
<p>이름 앞에 All이 붙은 연산들은 해당 연산을 수행한 뒤, 결과를 모든 디바이스로 broadcast하는 연산입니다.
아래 그림은 All-reduce의 예시입니다.</p>
<img src="https://user-images.githubusercontent.com/42150335/147877565-20269bae-5962-4fbb-a392-77999b0812a2.png" width="400"/>
<ul>
<li>All-reduce sum 예시</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist

dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span><span class="token string">&quot;nccl&quot;</span><span class="token punctuation">)</span>
rank <span class="token operator">=</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>rank<span class="token punctuation">)</span>

tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>current_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> rank
<span class="token comment"># rank==0 =&gt; [[0, 0], [0, 0]]</span>
<span class="token comment"># rank==1 =&gt; [[1, 1], [1, 1]]</span>
<span class="token comment"># rank==2 =&gt; [[2, 2], [2, 2]]</span>
<span class="token comment"># rank==3 =&gt; [[3, 3], [3, 3]]</span>

dist<span class="token punctuation">.</span>all_reduce<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> op<span class="token operator">=</span>torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>ReduceOp<span class="token punctuation">.</span>SUM<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;rank </span><span class="token interpolation"><span class="token punctuation">{</span>rank<span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">\n&quot;</span></span><span class="token punctuation">)</span>

<span class="token comment"># rank 1: tensor([[6., 6.],</span>
<span class="token comment">#         [6., 6.]], device=&#x27;cuda:1&#x27;)</span>
<span class="token comment"># rank 2: tensor([[6., 6.],</span>
<span class="token comment">#         [6., 6.]], device=&#x27;cuda:2&#x27;)</span>
<span class="token comment"># rank 0: tensor([[6., 6.],</span>
<span class="token comment">#         [6., 6.]], device=&#x27;cuda:0&#x27;)</span>
<span class="token comment"># rank 3: tensor([[6., 6.],</span>
<span class="token comment">#         [6., 6.]], device=&#x27;cuda:3&#x27;)</span></code></pre></div>
<h4>All-gather</h4>
<p>All-gather는 gather를 수행한 뒤, 모아진 결과를 모든 디바이스로 복사합니다.
All-reduce와 비슷해보이지만 결과를 보면 다른 연산인 것을 알 수 있습니다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist

dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span><span class="token string">&quot;nccl&quot;</span><span class="token punctuation">)</span>
rank <span class="token operator">=</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>rank<span class="token punctuation">)</span>

<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>current_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> rank
<span class="token comment"># rank==0 =&gt; [0]</span>
<span class="token comment"># rank==1 =&gt; [1]</span>
<span class="token comment"># rank==2 =&gt; [2]</span>
<span class="token comment"># rank==3 =&gt; [3]</span>

outputs_list <span class="token operator">=</span> <span class="token punctuation">[</span>
    torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> device<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>current_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> device<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>current_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> device<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>current_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> device<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>current_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

dist<span class="token punctuation">.</span>all_gather<span class="token punctuation">(</span>tensor_list<span class="token operator">=</span>outputs_list<span class="token punctuation">,</span> tensor<span class="token operator">=</span><span class="token builtin">input</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>outputs_list<span class="token punctuation">)</span>

<span class="token comment"># [tensor([0.], device=&#x27;cuda:1&#x27;), tensor([1.], device=&#x27;cuda:1&#x27;), tensor([2.], device=&#x27;cuda:1&#x27;), tensor([3.], device=&#x27;cuda:1&#x27;)]</span>
<span class="token comment"># [tensor([0.], device=&#x27;cuda:0&#x27;), tensor([1.], device=&#x27;cuda:0&#x27;), tensor([2.], device=&#x27;cuda:0&#x27;), tensor([3.], device=&#x27;cuda:0&#x27;)]</span>
<span class="token comment"># [tensor([0.], device=&#x27;cuda:2&#x27;), tensor([1.], device=&#x27;cuda:2&#x27;), tensor([2.], device=&#x27;cuda:2&#x27;), tensor([3.], device=&#x27;cuda:2&#x27;)]</span>
<span class="token comment"># [tensor([0.], device=&#x27;cuda:3&#x27;), tensor([1.], device=&#x27;cuda:3&#x27;), tensor([2.], device=&#x27;cuda:3&#x27;), tensor([3.], device=&#x27;cuda:3&#x27;)]</span></code></pre></div>
<h4>Reduce-scatter</h4>
<p>Reduce scatter는 Reduce를 수행한 뒤, 결과를 쪼개서 디바이스에 반환합니다.</p>
<img src="https://user-images.githubusercontent.com/42150335/147877668-57d1728c-1451-4f6a-a37a-6c59bcb42d68.png" width="400"/>
<ul>
<li>Reduce scatter 예제</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist

dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span><span class="token string">&quot;nccl&quot;</span><span class="token punctuation">)</span>
rank <span class="token operator">=</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>rank<span class="token punctuation">)</span>

input_list <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>current_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> rank
input_list <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>input_list<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> split_size_or_sections<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment"># rank==0 =&gt; [0, 00, 000, 0000]</span>
<span class="token comment"># rank==1 =&gt; [1, 10, 100, 1000]</span>
<span class="token comment"># rank==2 =&gt; [2, 20, 200, 2000]</span>
<span class="token comment"># rank==3 =&gt; [3, 30, 300, 3000]</span>

output <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>current_device<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">)</span>

dist<span class="token punctuation">.</span>reduce_scatter<span class="token punctuation">(</span>
    output<span class="token operator">=</span>output<span class="token punctuation">,</span>
    input_list<span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span>input_list<span class="token punctuation">)</span><span class="token punctuation">,</span>
    op<span class="token operator">=</span>torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>ReduceOp<span class="token punctuation">.</span>SUM<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;rank </span><span class="token interpolation"><span class="token punctuation">{</span>rank<span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>output<span class="token punctuation">}</span></span><span class="token string">\n&quot;</span></span><span class="token punctuation">)</span>

<span class="token comment"># rank 0: tensor([6], device=&#x27;cuda:0&#x27;)</span>
<span class="token comment"># rank 2: tensor([600], device=&#x27;cuda:2&#x27;)</span>
<span class="token comment"># rank 1: tensor([60], device=&#x27;cuda:1&#x27;)</span>
<span class="token comment"># rank 3: tensor([6000], device=&#x27;cuda:3&#x27;)</span></code></pre></div>
<h4>Barrier</h4>
<p>Barrier는 프로세스 동기화를 위해 사용됩니다. 먼저 barrier에 도착한 프로세스는 모든 프로세스가 해당 지점까지 실행되는 것을 기다립니다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> time
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist

dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span><span class="token string">&quot;nccl&quot;</span><span class="token punctuation">)</span>
rank <span class="token operator">=</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> rank <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
    seconds <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">while</span> seconds <span class="token operator">&lt;=</span> <span class="token number">3</span><span class="token punctuation">:</span>
        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        seconds <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;rank 0 - seconds: </span><span class="token interpolation"><span class="token punctuation">{</span>seconds<span class="token punctuation">}</span></span><span class="token string">\n&quot;</span></span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;rank </span><span class="token interpolation"><span class="token punctuation">{</span>rank<span class="token punctuation">}</span></span><span class="token string">: no-barrier\n&quot;</span></span><span class="token punctuation">)</span>
dist<span class="token punctuation">.</span>barrier<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;rank </span><span class="token interpolation"><span class="token punctuation">{</span>rank<span class="token punctuation">}</span></span><span class="token string">: barrier\n&quot;</span></span><span class="token punctuation">)</span>

<span class="token comment"># rank 2: no-barrier</span>
<span class="token comment"># rank 1: no-barrier</span>
<span class="token comment"># rank 3: no-barrier</span>
<span class="token comment"># rank 0 - seconds: 1</span>
<span class="token comment"># rank 0 - seconds: 2</span>
<span class="token comment"># rank 0 - seconds: 3</span>
<span class="token comment"># rank 0 - seconds: 4</span>
<span class="token comment"># rank 0: no-barrier</span>
<span class="token comment"># rank 0: barrier</span>
<span class="token comment"># rank 1: barrier</span>
<span class="token comment"># rank 3: barrier</span>
<span class="token comment"># rank 2: barrier</span></code></pre></div></div></section><style data-emotion="css 186r8xi">.css-186r8xi{margin:1.5em 0;padding:6.5vw 7vw 8vw;border:#e4eaed 1px solid;text-align:center;background:linear-gradient(
    #fbfdfe,
    #f4f8fb
  );border-radius:3px;}.css-186r8xi p{margin-bottom:0.2em 0 1em;color:#738a94;font-size:2.1rem;line-height:1.55em;}@media (max-width: 650px){.css-186r8xi p{font-size:1.6rem;}}.css-186r8xi .form-group{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}@media (prefers-color-scheme: dark){.css-186r8xi{border:none;background:linear-gradient(#000, #000);}.css-186r8xi p{color:rgba(255, 255, 255, 0.7);}}</style><section class="css-186r8xi ebkqguh0"><style data-emotion="css 1ogx56f">.css-1ogx56f{margin:0 0 3px 0;padding:0;color:#15171A;font-size:3.5rem;line-height:1;font-weight:600;}@media (max-width: 650px){.css-1ogx56f{font-size:2.4rem;}}@media (prefers-color-scheme: dark){.css-1ogx56f{color:rgba(255, 255, 255, 0.9);}}</style><h3 class="css-1ogx56f">Subscribe to <!-- -->BEKSI</h3><p>Get the latest posts delivered right to your inbox</p><form novalidate="" action="https://twitter.us19.list-manage.com/subscribe/post?u=a89b6987ac248c81b0b7f3a0f&amp;amp;id=7d777b7d75" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="subscribe-form css-inpvxq" target="_blank"><div class="form-group css-19m0ntg e1a7m3l0"><input type="email" class="subscribe-email css-1ea5r2o e1a7m3l2" name="MERGE0" id="MERGE0" placeholder="youremail@example.com"/></div><div style="position:absolute;left:-5000px" aria-hidden="true"><input type="text" name="b_a89b6987ac248c81b0b7f3a0f_7d777b7d75" tabindex="-1"/></div><button type="submit" class="css-glujqe e1a7m3l1"><span>Subscribe</span></button></form></section></article></div></main><style data-emotion="css dcfhc9">.css-dcfhc9{position:relative;padding:0 5vw;}</style><style data-emotion="css 1aa7tg3">.css-1aa7tg3{border-bottom:1px solid rgba(255, 255, 255, 0.1);background:#0a0b0c;position:relative;padding:0 5vw;}.css-1aa7tg3 .post-card{padding-bottom:0;border-bottom:none;}.css-1aa7tg3 .post-card:after{display:none;}.css-1aa7tg3 .post-card-primary-tag{color:#fff;opacity:0.6;}.css-1aa7tg3 .post-card-title{color:#fff;opacity:0.8;-webkit-transition:all 0.2s ease-in-out;transition:all 0.2s ease-in-out;}.css-1aa7tg3 .post-card:hover .post-card-image{opacity:1;}.css-1aa7tg3 .post-card-excerpt{color:rgba(255, 255, 255, 0.6);}.css-1aa7tg3 .static-avatar{border-color:#000;}.css-1aa7tg3 .post-card-byline-content{color:rgba(255, 255, 255, 0.6);}.css-1aa7tg3 .post-card-byline-content a{color:rgba(255, 255, 255, 0.8);}.css-1aa7tg3 .author-avatar{border-color:#0a0b0c;}.css-1aa7tg3 .author-profile-image{background:#0a0b0c;}@media (max-width: 650px){.css-1aa7tg3 .post-card{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;margin:25px;padding:25px 0 0;border-bottom:1px solid rgba(255, 255, 255, 0.1);}}</style><aside class="read-next css-1aa7tg3 e12hyek91"><div class="css-y521qa"><style data-emotion="css 1ehfk3g">.css-1ehfk3g{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;margin:0 -25px;padding:60px 0 0 0;}</style><div class="read-next-feed css-1ehfk3g e12hyek90"><style data-emotion="css 1gm6nmw">.css-1gm6nmw{position:relative;-webkit-flex:0 1 326px;-ms-flex:0 1 326px;flex:0 1 326px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;overflow:hidden;margin:0 25px 50px;padding:25px;background:linear-gradient(
    #1a1c20,
    #0a0b0c
  );border-radius:3px;}.css-1gm6nmw a{-webkit-transition:all 0.2s ease-in-out;transition:all 0.2s ease-in-out;}.css-1gm6nmw a:hover{-webkit-text-decoration:none;text-decoration:none;}@media (max-width: 1170px){.css-1gm6nmw{-webkit-flex:1 1 261px;-ms-flex:1 1 261px;flex:1 1 261px;margin-bottom:5vw;}}@media (max-width: 650px){.css-1gm6nmw{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;margin:0 25px;padding:0;background:none;}}</style><article class="read-next-card css-1gm6nmw et5vsv94"><header class="read-next-card-header"><style data-emotion="css 1wo4mzo">.css-1wo4mzo{margin:0;color:rgba(255, 255, 255, 0.6);font-size:1.2rem;line-height:1em;font-weight:300;letter-spacing:0.4px;text-transform:uppercase;}.css-1wo4mzo a{color:#fff;font-weight:500;-webkit-text-decoration:none;text-decoration:none;opacity:0.8;}.css-1wo4mzo a:hover{opacity:1;}</style><h3 class="css-1wo4mzo et5vsv93"><span>More in</span> <a href="/tags/nlp/">nlp</a></h3></header><style data-emotion="css ejekmm">.css-ejekmm{font-size:1.7rem;}.css-ejekmm ul{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;margin:0;padding:0;list-style:none;}.css-ejekmm li{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;margin:0;padding:20px 0;border-bottom:rgba(255, 255, 255, 0.1);}.css-ejekmm li:last-of-type{padding-bottom:5px;border:none;}.css-ejekmm h4{margin:0;font-size:1.6rem;line-height:1.35em;font-weight:600;}.css-ejekmm li a{display:block;color:#fff;opacity:0.8;}.css-ejekmm li a:hover{opacity:1;}</style><div class="read-next-card-content css-ejekmm et5vsv92"><ul><li><h4><a href="/generate/">Decoding Strategy (디코딩 전략)</a></h4><style data-emotion="css f7c4dv">.css-f7c4dv{margin-top:2px;font-size:1.2rem;line-height:1.4em;font-weight:400;}.css-f7c4dv p{margin:0;color:rgba(255, 255, 255, 0.6);}</style><div class="read-next-card-meta css-f7c4dv et5vsv91"><p><time dateTime="2022-01-15">15 Jan 2022</time> - <!-- --> min read</p></div></li><li><h4><a href="/fid_and_rag/">Generation with Retrieval</a></h4><div class="read-next-card-meta css-f7c4dv et5vsv91"><p><time dateTime="2022-01-05">05 Jan 2022</time> - <!-- --> min read</p></div></li><li><h4><a href="/bert_fp/">Fine-grained Post-training for Improving Retrieval-based Dialogue Systems Paper Review</a></h4><div class="read-next-card-meta css-f7c4dv et5vsv91"><p><time dateTime="2021-12-18">18 Dec 2021</time> - <!-- --> min read</p></div></li></ul></div><style data-emotion="css qqvtec">.css-qqvtec{position:relative;margin:40px 0 5px;}.css-qqvtec a{padding:7px 12px 8px 14px;border:1px solid rgba(255, 255, 255, 0.6);color:rgba(255, 255, 255, 0.6);font-size:1.3rem;border-radius:999px;-webkit-transition:all 0.35s ease-in-out;transition:all 0.35s ease-in-out;}.css-qqvtec a:hover{border-color:#fecd35;color:#fecd35;-webkit-text-decoration:none;text-decoration:none;}</style><footer class="read-next-card-footer css-qqvtec et5vsv90"><a href="/tags/nlp/">See all 30 posts<!-- --> →</a></footer></article><style data-emotion="css 1aiulzc">.css-1aiulzc{position:relative;-webkit-flex:1 1 301px;-ms-flex:1 1 301px;flex:1 1 301px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;overflow:hidden;margin:0 0 40px;padding:0 20px 40px;min-height:220px;-webkit-background-size:cover;background-size:cover;}</style><article class="post-card   css-1aiulzc"><style data-emotion="css c0hj8a">.css-c0hj8a{position:relative;display:block;overflow:hidden;border-radius:5px 5px 0 0;}</style><a class="post-card-image-link css-c0hj8a" href="/big-model1/"><style data-emotion="css wa09yz">.css-wa09yz{width:auto;height:200px;background:#c5d2d9 no-repeat center center;-webkit-background-size:cover;background-size:cover;}@media (prefers-color-scheme: dark){.css-wa09yz{background:#191b1f;}}</style><div class="post-card-image css-wa09yz eg6d1df7"><div data-gatsby-image-wrapper="" style="height:100%" class="gatsby-image-wrapper"><div aria-hidden="true" style="padding-top:48.72093023255814%"></div><img aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear" decoding="async" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAACnUlEQVQoz21RbUhTYRR+y8qEiH5If4IsbpCUyLVZWVTM/VAzRcqpOcnJ1C2h8EdRYlIzKXIWzmypSV8ihhlBUURIMSMZWUYNGVGaDd2c17zbvdvd/Xx34g4kIg8cDrznPM953vMgjDHEYmrGlk01REnGslox/ACAdWPOlxue9nfnvhrszRm8f2tzp836rOdmq6XzShNCKmAJuCwpjkFYkGOfxz+Co+O6UFtVPtfcUE8/6m2H5wM9cM9h89haGqG7rdn35mHXesRyPMQwXlbZUp2Z9eEx13vw+31T2oNZ+8+dMrlt1rPQ13NDcrRZoaGuCjdWG6IPLp9PQ1P+xf/UQQxAUmSQFRkEkQee53GU49SxbwghZDIcHTVVFCsN9bVgrioDi74ADIf2+O9ea9yIvPO0yvafuiDHQVSSgBdllR9LkqTOeerM1cl7NelD9ZbK4YIcrSc/V9tvLD7y2qDNmu6yNiWj6Tn6n+8pCgZBlIGXlPgbxvElWDUPAMbNxuP6XN2BgQp94XDNiRKDviivrMZwTGfKz9ZYT29dg8JRAasAAMCiLON5hsNzNIMpRsKiHGdR+4qiqD7Dh/LigqulRXkniw7rXpiNpRaE0MoafeaqZpMWDV3YV4JUYbKC48ZwogJMmIVFhgFqMQCiFIX4Qf/GFAAkdHe0ol3k7vS0nZmbCnUahFArulSZg86UZmchXpTZAB1mqVCEpRmOZcIcy7IR1kctsL/pBTYYolkuEmKEKCOKfOTrtOv2WkcqWgFuY8Jja+bqJy0ZiU47mdh3cQcCqEBIEEXCPTlDfJmcJVyeX4TL4yXGvvuJCW+QmPCGiE+TFBGgAoTIBbdRP0e3vG3XJDnbyRSnndz+roMkR+xk6oid1IzYyRT3nYykP3nQTewD6OfJAAAAAElFTkSuQmCC" alt=""/><picture><source type="image/webp" data-srcset="/static/d6ed5ee3d7d66b561a10d5ef112636a6/6c332/big-model1.webp 750w,/static/d6ed5ee3d7d66b561a10d5ef112636a6/03806/big-model1.webp 1080w,/static/d6ed5ee3d7d66b561a10d5ef112636a6/698e5/big-model1.webp 1366w,/static/d6ed5ee3d7d66b561a10d5ef112636a6/e01f3/big-model1.webp 1720w" sizes="100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="100vw" decoding="async" loading="lazy" data-src="/static/d6ed5ee3d7d66b561a10d5ef112636a6/31d4c/big-model1.png" data-srcset="/static/d6ed5ee3d7d66b561a10d5ef112636a6/4ec63/big-model1.png 750w,/static/d6ed5ee3d7d66b561a10d5ef112636a6/2df19/big-model1.png 1080w,/static/d6ed5ee3d7d66b561a10d5ef112636a6/e3ec4/big-model1.png 1366w,/static/d6ed5ee3d7d66b561a10d5ef112636a6/31d4c/big-model1.png 1720w" alt="Large Scale LM (1) Background cover image"/></picture><noscript><picture><source type="image/webp" srcSet="/static/d6ed5ee3d7d66b561a10d5ef112636a6/6c332/big-model1.webp 750w,/static/d6ed5ee3d7d66b561a10d5ef112636a6/03806/big-model1.webp 1080w,/static/d6ed5ee3d7d66b561a10d5ef112636a6/698e5/big-model1.webp 1366w,/static/d6ed5ee3d7d66b561a10d5ef112636a6/e01f3/big-model1.webp 1720w" sizes="100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="100vw" decoding="async" loading="lazy" src="/static/d6ed5ee3d7d66b561a10d5ef112636a6/31d4c/big-model1.png" srcSet="/static/d6ed5ee3d7d66b561a10d5ef112636a6/4ec63/big-model1.png 750w,/static/d6ed5ee3d7d66b561a10d5ef112636a6/2df19/big-model1.png 1080w,/static/d6ed5ee3d7d66b561a10d5ef112636a6/e3ec4/big-model1.png 1366w,/static/d6ed5ee3d7d66b561a10d5ef112636a6/31d4c/big-model1.png 1720w" alt="Large Scale LM (1) Background cover image"/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1)}}</script></div></div></a><style data-emotion="css 1lh7kdz">.css-1lh7kdz{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}</style><div class="post-card-content css-1lh7kdz eg6d1df6"><style data-emotion="css 1fjrpmt">.css-1fjrpmt{position:relative;display:block;color:#15171A;}.css-1fjrpmt:hover{-webkit-text-decoration:none;text-decoration:none;}</style><a class="post-card-content-link css-1fjrpmt" href="/big-model1/"><style data-emotion="css 1w0j2bn">.css-1w0j2bn{margin:15px 0 0;}</style><header class="post-card-header css-1w0j2bn eg6d1df0"><style data-emotion="css oghrx5">.css-oghrx5{margin:0 0 0.2em;color:#3eb0ef;font-size:1.2rem;font-weight:500;letter-spacing:0.2px;text-transform:uppercase;}</style><div class="post-card-primary-tag css-oghrx5 eg6d1df5"><a href="/tags/nlp/">nlp</a>,<b> </b><a href="/tags/parallelism/">parallelism</a>,<b> </b><a href="/tags/large-scale/">large-scale</a>,<b> </b><a href="/tags/lm/">lm</a>,<b> </b></div><style data-emotion="css 3lgx4i">.css-3lgx4i{margin:0 0 0.4em;line-height:1.15em;-webkit-transition:color 0.2s ease-in-out;transition:color 0.2s ease-in-out;}@media (prefers-color-scheme: dark){.css-3lgx4i{color:rgba(255, 255, 255, 0.85);}}</style><h2 class="post-card-title css-3lgx4i eg6d1df4">Large Scale LM (1) Background</h2></header><style data-emotion="css ltebj6">.css-ltebj6{font-family:sans-serif,serif;}@media (prefers-color-scheme: dark){.css-ltebj6{color:#90a2aa!important;}}</style><section class="post-card-excerpt css-ltebj6 eg6d1df3"><p>Large Scale LM (1) Background 이 자료는 [해당 link…</p></section></a><style data-emotion="css 143c7df">.css-143c7df{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;padding:0;}</style><footer class="post-card-meta css-143c7df eg6d1df2"><ul class="author-list css-12fmpzj epdb2t70"><li class="author-list-item css-rzestn e1iirwvr1"><style data-emotion="css 1ub0qw9">.css-1ub0qw9{position:absolute;bottom:105%;z-index:999;display:block;padding:2px 8px;color:white;font-size:1.2rem;letter-spacing:0.2px;white-space:nowrap;background:#15171A;border-radius:3px;box-shadow:rgba(39, 44, 49, 0.08) 0 12px 26px,rgba(39, 44, 49, 0.03) 1px 3px 8px;opacity:0;-webkit-transition:all 0.35s cubic-bezier(0.4, 0.01, 0.165, 0.99);transition:all 0.35s cubic-bezier(0.4, 0.01, 0.165, 0.99);-webkit-transform:translateY(6px);-moz-transform:translateY(6px);-ms-transform:translateY(6px);transform:translateY(6px);pointer-events:none;}@media (max-width: 700px){.css-1ub0qw9{display:none;}}</style><div class="author-name-tooltip css-1ub0qw9 e1iirwvr0">Soohwan Kim</div><a class="author-avatar css-1smzq71" href="/author/soohwan-kim/"><div data-gatsby-image-wrapper="" class="gatsby-image-wrapper author-profile-image css-1kq7wgl"><div aria-hidden="true" style="padding-top:124.62962962962962%"></div><img aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear" decoding="async" src="data:image/png;base64,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" alt=""/><picture><source type="image/webp" data-srcset="/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w" sizes="100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="100vw" decoding="async" loading="lazy" data-src="/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png" data-srcset="/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w" alt="Soohwan Kim"/></picture><noscript><picture><source type="image/webp" srcSet="/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w" sizes="100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="100vw" decoding="async" loading="lazy" src="/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png" srcSet="/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w" alt="Soohwan Kim"/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1)}}</script></div></a></li></ul><style data-emotion="css 1rrg0pi">.css-1rrg0pi{-webkit-flex:1 1 50%;-ms-flex:1 1 50%;flex:1 1 50%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;margin:4px 0 0 10px;color:#90a2aa;font-size:1.2rem;line-height:1.4em;font-weight:400;letter-spacing:0.2px;text-transform:uppercase;}.css-1rrg0pi span{margin:0;}.css-1rrg0pi a{color:#434952;font-weight:600;}@media (prefers-color-scheme: dark){.css-1rrg0pi a{color:rgba(255, 255, 255, 0.75);}}</style><div class="post-card-byline-content css-1rrg0pi eg6d1df1"><span><a href="/author/soohwan-kim/">Soohwan Kim</a></span><span class="post-card-byline-date"><time dateTime="2021-11-22">22 Nov 2021</time> <span class="bull">•</span> <!-- -->5 min read</span></div></footer></div></article><article class="post-card   css-1aiulzc"><a class="post-card-image-link css-c0hj8a" href="/gpt/"><div class="post-card-image css-wa09yz eg6d1df7"><div data-gatsby-image-wrapper="" style="height:100%" class="gatsby-image-wrapper"><div aria-hidden="true" style="padding-top:60.614525139664806%"></div><img aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear" decoding="async" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABYElEQVQoz4VT2YqDQBD0/z/Gp8RHwYBRBEEISMxl7kRMyA25tJbqZWSUTbZgxGOmurqqNcqyBBdxvV4xnU6xXq/xfD7lnfreXJ++GfqG2WwGy7LQ6/UQxzGa+ESuFzCaL+73O4qiQLfbhWma6HQ6WK1WeDwe/5JWhPpG4ng8isogCISw3W7LfZZlH0kpgjD+8oQqX6+XeHq73TAej+E4DjzPw/l8/qq0prCJ9/uN5XKJfr+PKIowGo1E+ddQdDLK5tLbYOJUN5/PpYDv+1KkSahQa5kqSKDIFaiQE0AsFgvxc7fb1bo5nU4yaoZu6GQyweFwqBFeLhdJmQrVbNJHjtVgMECe53Jmu93+EupVhsOhJKzPHQ+wRQZFMCRVjMGRjAU4Vnw2eOHfEYYhbNuG67qiVG+JBFSZJAlarZbsoeJm2+KhMn6z2VRq0jTFfr+vNrEVFqGPJKKPHCWe00Nkyj+l75jRYdU4HAAAAABJRU5ErkJggg==" alt=""/><picture><source type="image/webp" data-srcset="/static/833f7784ccf61f40030aff940fe3ac06/4c8d7/gpt.webp 716w" sizes="100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="100vw" decoding="async" loading="lazy" data-src="/static/833f7784ccf61f40030aff940fe3ac06/7eac2/gpt.png" data-srcset="/static/833f7784ccf61f40030aff940fe3ac06/7eac2/gpt.png 716w" alt="GPT (Generative Pre-trained Transformer) cover image"/></picture><noscript><picture><source type="image/webp" srcSet="/static/833f7784ccf61f40030aff940fe3ac06/4c8d7/gpt.webp 716w" sizes="100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="100vw" decoding="async" loading="lazy" src="/static/833f7784ccf61f40030aff940fe3ac06/7eac2/gpt.png" srcSet="/static/833f7784ccf61f40030aff940fe3ac06/7eac2/gpt.png 716w" alt="GPT (Generative Pre-trained Transformer) cover image"/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1)}}</script></div></div></a><div class="post-card-content css-1lh7kdz eg6d1df6"><a class="post-card-content-link css-1fjrpmt" href="/gpt/"><header class="post-card-header css-1w0j2bn eg6d1df0"><div class="post-card-primary-tag css-oghrx5 eg6d1df5"><a href="/tags/nlp/">nlp</a>,<b> </b><a href="/tags/parallelism/">parallelism</a>,<b> </b><a href="/tags/large-scale/">large-scale</a>,<b> </b><a href="/tags/lm/">lm</a>,<b> </b></div><h2 class="post-card-title css-3lgx4i eg6d1df4">GPT (Generative Pre-trained Transformer)</h2></header><section class="post-card-excerpt css-ltebj6 eg6d1df3"><p>GPT (Generative Pre-trained Transformer) 1 gpt1 먼저 알아보고, gpt2에 대해 알아보겠습니다. GPT1 Improving Language Understanding by Generative Pre-Training…</p></section></a><footer class="post-card-meta css-143c7df eg6d1df2"><ul class="author-list css-12fmpzj epdb2t70"><li class="author-list-item css-rzestn e1iirwvr1"><div class="author-name-tooltip css-1ub0qw9 e1iirwvr0">Soohwan Kim</div><a class="author-avatar css-1smzq71" href="/author/soohwan-kim/"><div data-gatsby-image-wrapper="" class="gatsby-image-wrapper author-profile-image css-1kq7wgl"><div aria-hidden="true" style="padding-top:124.62962962962962%"></div><img aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear" decoding="async" src="data:image/png;base64,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" alt=""/><picture><source type="image/webp" data-srcset="/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w" sizes="100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="100vw" decoding="async" loading="lazy" data-src="/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png" data-srcset="/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w" alt="Soohwan Kim"/></picture><noscript><picture><source type="image/webp" srcSet="/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w" sizes="100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="100vw" decoding="async" loading="lazy" src="/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png" srcSet="/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w" alt="Soohwan Kim"/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1)}}</script></div></a></li></ul><div class="post-card-byline-content css-1rrg0pi eg6d1df1"><span><a href="/author/soohwan-kim/">Soohwan Kim</a></span><span class="post-card-byline-date"><time dateTime="2021-11-23">23 Nov 2021</time> <span class="bull">•</span> <!-- -->13 min read</span></div></footer></div></article></div></div></aside><style data-emotion="css 1turcvg">.css-1turcvg{position:relative;padding:0 5vw;position:relative;padding-top:20px;padding-bottom:60px;color:#fff;background:#000;}</style><footer class="css-1turcvg"><style data-emotion="css 1d3gyi8">.css-1d3gyi8{margin:0 auto;max-width:1040px;width:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:rgba(255, 255, 255, 0.7);font-size:1.3rem;}.css-1d3gyi8 a{color:rgba(255, 255, 255, 0.7);}.css-1d3gyi8 a:hover{color:rgba(255, 255, 255, 1);-webkit-text-decoration:none;text-decoration:none;}@media (max-width: 650px){.css-1d3gyi8{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}}</style><div class="css-1d3gyi8"><section class="copyright"><a href="/">BEKSI</a> © <!-- -->2022<!-- --> <a href="/">| <!-- -->BEKSI<!-- --> <!-- -->All Rights Reserved.</a></section><style data-emotion="css pwtbz1">.css-pwtbz1{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}.css-pwtbz1 a{position:relative;margin-left:20px;}.css-pwtbz1 a:before{content:'';position:absolute;top:11px;left:-11px;display:block;width:2px;height:2px;background:#fff;border-radius:100%;}.css-pwtbz1 a:first-of-type:before{display:none;}@media (max-width: 650px){.css-pwtbz1 a:first-of-type{margin-left:0;}}</style><nav class="css-pwtbz1 e1iieua40"><a href="/">Latest Posts</a><a href="https://www.facebook.com/profile.php?id=100011713266028" target="_blank" rel="noopener noreferrer">Facebook</a><a href="https://github.com/scttcper/gatsby-casper" target="_blank" rel="noopener noreferrer">Casper</a><a href="/rss.xml">RSS</a></nav></div></footer></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/big-model2/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-11465088a5c62aa885e9.js"],"component---src-pages-404-tsx":["/component---src-pages-404-tsx-4f4cd53c461d6b3acd9e.js"],"component---src-pages-about-tsx":["/component---src-pages-about-tsx-d581cb58f9bb79a11c85.js"],"component---src-pages-news-tsx":["/component---src-pages-news-tsx-1db28158794e0b4f9fd9.js"],"component---src-pages-resume-tsx":["/component---src-pages-resume-tsx-50bc3155a9e6037177f0.js"],"component---src-templates-author-tsx":[],"component---src-templates-index-tsx":["/component---src-templates-index-tsx-2d2f5e1e78b2b8ac4a19.js"],"component---src-templates-post-tsx":[],"component---src-templates-tags-tsx":["/component---src-templates-tags-tsx-7505fbd783de6d294781.js"]};/*]]>*/</script><script src="/f913106a4e51e31b31a0ff1c72479e8b5d907cbd-2ca2bb564352d8340d3c.js" async=""></script><script src="/f43d3337dda7771446a8a3723748296d1554be0e-d425ad4bddf703137135.js" async=""></script><script src="/commons-09b2e09f1f69c33f4392.js" async=""></script><script src="/e0525e89-7522dd770bcde8196745.js" async=""></script><script src="/14cad5d5-8e47c7dcb9a81a3081dc.js" async=""></script><script src="/af52a822-c9eb064eb5bad8d65c4a.js" async=""></script><script src="/b4ffff85-a5d2f6aa896357cc601d.js" async=""></script><script src="/1bfc9850-94b89069287213aa7853.js" async=""></script><script src="/app-11465088a5c62aa885e9.js" async=""></script><script src="/framework-1f167e8ec29420fffee7.js" async=""></script><script src="/webpack-runtime-07bd89c0ba3cb6c86c0d.js" async=""></script></body></html>