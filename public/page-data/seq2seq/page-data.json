{
    "componentChunkName": "component---src-templates-post-tsx",
    "path": "/seq2seq/",
    "result": {"data":{"logo":null,"markdownRemark":{"html":"<h1>Seq2seq (Sequence to sequence)</h1>\n<p>본 포스팅을 이해하기 위해서는 다음 글에 대한 이해가 선행되는 것이 좋습니다.</p>\n<ul>\n<li><a href=\"https://sooftware.io/rnn/\">RNN (Recurrent Neural Network)</a></li>\n<li><a href=\"https://sooftware.io/lstm_gru/\">LSTM &#x26; GRU (Long Short Term Memory &#x26; Gated Recurrent Unit)</a></li>\n</ul>\n<hr>\n<h2>Seq2seq (Sequence-to-Sequence)</h2>\n<p>세상에는 많은 시계열 데이터 (Sequence Data) 가 존재한다.<br>\n텍스트, 음성, 영상 등 많은 종류의 시계열 데이터가 존재하고,<br>\n이러한 시계열 데이터들을 다른 시계열 데이터로 변환하는 문제들도 숱하게 생각할 수 있다.</p>\n<img src=\"https://user-images.githubusercontent.com/42150335/134771361-dc0b6d38-12b1-4bc6-a750-d6c5eaa1666a.png\" width=\"600\">  \n<p>예컨대 기계 번역이나 음성 인식을 예로 들 수 있다.<br>\n(Neural Machine Translation or Speech Recognition)</p>\n<p>이러한 문제를 위한 모델로 2개의 RNN을 이용하는 Seq2seq<sup>sequence to sequence</sup>라는 모델을 살펴보자 !!</p>\n<h2>Seq2seq의 원리</h2>\n<img src=\"https://user-images.githubusercontent.com/42150335/134771395-4ecc674d-ddc6-4225-8737-bbbe7b8ce3c7.png\" width=\"600\">  \n<p>Seq2seq를 Encoder-Decoder 모델이라고도 많이들 부른다.<br>\n이름이 말해주듯이 2개의 모듈, Encoder와 Decoder가 등장한다.</p>\n<p>Encoder는 어떤 시계열 데이터를 압축해서 표현해주고,<br>\nDecoder는 압축된 데이터를 다른 시계열 데이터로 변환해준다.</p>\n<img src=\"https://user-images.githubusercontent.com/42150335/134771419-8f2db6a1-57ee-4fa2-a1b9-506316975c78.png\" width=\"600\">  \n<p>인코더는 데이터를 입력받아서 하나의 벡터로 정보를 압축한다.<br>\n이 때의 벡터를 <b>컨텍스트 벡터 (Context Vector)</b> 라고 하며,<br>\n디코더는 이 컨텍스트 벡터를 이용해서 위의 그림과 같은 번역을 수행하는 것이다.</p>\n<h2>Encoder</h2>\n<img src=\"https://user-images.githubusercontent.com/42150335/134771435-8cdf6c13-93ee-4e20-963a-710d35bd3ace.png\" width=\"600\">  \n<p>그럼 한번 Encoder부터 살펴보자.<br>\nEncoder의 계층은 위의 그림처럼 구성된다.</p>\n<p>위의 그림처럼 Encoder는 RNN (or LSTM, GRU) 을 이용하여 데이터를<br>\nh라는 Hidden State Vector로 변환한다.</p>\n<p>Encoder가 출력하는 벡터 h는 마지막 RNN 셀의 Hidden State이다.<br>\n즉, Encoder는 그냥 RNN을 이어놓은 것에 불과하다.</p>\n<p>여기서 주목할 점은 Encoder가 내놓는 Context Vector는 결국 마지막 RNN 셀의<br>\nHidden State므로, 고정 길이 벡터라는 사실이다.</p>\n<img src=\"https://user-images.githubusercontent.com/42150335/134771463-ad53f595-0b1b-4927-86d6-6b07559d6f82.png\" width=\"600\">\n<p>그래서 인코딩 한다라는 말은 결국 임의 길의의 시계열 데이터를 고정 길이 벡터로 변환하는 작업이 된다.</p>\n<h2>Decoder</h2>\n<img src=\"https://user-images.githubusercontent.com/42150335/134771491-201c18ba-5ded-4a64-97a4-b1fade60f963.png\" width=\"600\">  \n<p>다음으로 Decoder를 살펴보자.<br>\nDecoder는 기본적으로 RNNLM (RNN Language Model)이다.</p>\n<p>Decoder는 Encoder로부터 Context Vector (h)를 넘겨받는다.<br>\n그리고 첫 입력으로 문장의 시작을 의미하는 심볼인 [s]가 들어간다.<br>\n([s]는 [sos], [bos], [Go] 등 많은 이름으로 불린다)</p>\n<img src=\"https://user-images.githubusercontent.com/42150335/134771524-eb819bce-12f8-460e-899c-b3e9d7a0f1c1.png\" width=\"600\">  \n<p>Decoder의 첫번째 RNN 셀은 Context Vector와 [s], 이 2개의 입력을 바탕으로<br>\n새로운 Hidden State를 계산하고 이를 Affine 계층과 Softmax 계층을 거쳐서<br>\n다음에 등장할 확률이 높은 “안녕하세요”를 예측한다.</p>\n<p>※ Affine 계층은 Hidden State를 입력으로 받아 분류 개수로 출력해주는 피드포워드 네트워크이다  ※</p>\n<img src=\"https://user-images.githubusercontent.com/42150335/134771557-ad262610-582b-46cb-92de-6de78c8e0be5.png\" width=\"600\">  \n<p>그리고 계산한 새로운 Hidden State와 예측한 “안녕하세요”를 입력으로 해서 2번째 예측을 수행한다.</p>\n<img src=\"https://user-images.githubusercontent.com/42150335/134771585-7c026d60-3349-4838-925f-c7bc56df6dc8.png\" width=\"600\">  \n<p>위의 과정을 문장의 끝을 의미하는 심볼인 [/s]가 다음 단어로 예측될 때까지 반복한다.<br>\n([/s]는 [eos], [end] 등 많은 이름으로 불린다)</p>\n<h3>Decoder와 RNNLM</h3>\n<p>여기서 디코더와 RNNLM (RNN Language Model).<br>\n즉, RNN을 이용해서 문장을 생성하는 모델과의 유일한 차이점은<br>\n인코더에서 만든 Context Vector를 입력받는다는 점만이 다르다.</p>\n<p>컨텍스트 벡터를 초기 입력으로 받는다는 사소한 차이점이 평범한 언어 모델도<br>\n기계 번역, 음성 인식과 같은 복잡한 문제도 풀 수 있는 Decoder로 탈바꿈 시킬 수 있다.</p>\n<h2>Seqseq의 전체 모습</h2>\n<img src=\"https://user-images.githubusercontent.com/42150335/134771633-8fbf84f2-1b31-4b3c-ad1e-242558ceb450.png\" width=\"600\">\n<p>위는 Encoder와 Decoder를 연결한 Seq2seq의 전체 그림이다.<br>\n위의 그림에서 볼 수 있듯이, Encoder의 마지막 Hidden State가<br>\nEncoder와 Decoder의 순전파와 역전파를 이어주는 다리가 된다.</p>\n<h2>Seq2seq 개선</h2>\n<p>이번에는 앞에서 본 기본적인 Seq2seq 구조를 조금 개선해보자.<br>\n효과적인 기법이 몇 가지 존재하는데 그 중 2가지를 살펴보자.</p>\n<img src=\"https://user-images.githubusercontent.com/42150335/134771651-1d17c46e-f9b9-487a-9f82-71c108569f09.png\" width=\"600\">  \n<p>첫 번째 개선안은 아주 손 쉬운 방법이다.<br>\n위 그림에서 보듯이 입력 데이터의 순서를 반전시키는 것이다.</p>\n<p>위의 트릭은 「“Sequence to sequence learning with neural networks.” Advances in neural information processing system. 2014.」 논문에서 제안했다.</p>\n<p>이 트릭을 사용하면 많은 경우 학습이 빨라져서, 최종 정확도도 좋아진다고 한다.</p>\n<p>그렇다면 왜 입력 데이터를 반전시키는 것만으로 학습이 빨라지고 정확도가 향상되는 걸까?<br>\n직관적으로는 Gradient의 전파가 원활해지기 때문이라고 볼 수 있다.</p>\n<img src=\"https://user-images.githubusercontent.com/42150335/134771684-c6d18e9e-c1d3-4521-a56b-58c6e25e77dc.png\" width=\"600\">  \n<p>예를 들어 “나는 고양이로소이다”를 “I am a cat”으로 번역하는 문제에서,<br>\n“나”라는 단어가 “I”까지 가는 것보다 데이터를 반전시켰을 때 Gradient 전파가 잘 될 것이다.</p>\n<p>물론 평균적인 거리는 그대로이지만,<br>\n시계열 데이터는 관련 문제에서는 앞쪽 데이터에 대한 정확한 예측이 선행되면<br>\n뒤의 예측에서도 좋은 결과로 이어지는 경우가 많기 때문에 더 좋은 결과가 나오지 않을까 싶다.</p>\n<p>필자가 진행중인 음성 인식 (Speech Recognition) 프로젝트에서도<br>\n입력 데이터를 반전시켰을 때 학습 속도가 상당히 개선되는 것을 확인했고,<br>\n정확도 역시 더욱 좋아졌다.</p>\n<p>매우 간단한 트릭이기 때문에 한 번 시도해보는 것을 추천한다.</p>\n<h3>Peaky Seq2seq</h3>\n<img src=\"https://user-images.githubusercontent.com/42150335/134771714-4ffc097f-a72a-4e45-ae5f-d381f35064bd.png\" width=\"600\">  \n<p>이어서 Seq2seq 두 번째 개선안이다.<br>\n앞서 배운 Seq2seq의 동작을 다시 한 번 살펴보게 되면,<br>\nEncoder는 입력 데이터를 고정 길이의 컨텍스트 벡터로 변환한다.</p>\n<p>Decoder 입장에서는 이 컨텍스트 벡터만이 예측을 하는데에 제공되는 유일한 정보인 셈이다.<br>\n그러나 이 중요한 정보를 기본 Seq2seq에서는 최초 RNN 셀에만 전달이 된다.</p>\n<p>이러한 점을 수정해서 중요한 정보가 담긴 컨텍스트 벡터를 디코더의<br>\n다른 계층들에게도 전달해주는 것이다.</p>\n<p>이러한 아이디어는 「”learning phrase representation using RNN encoder-decoder for statistical machine translation” Cho, Kyunhyun 2014.」 논문에서 제안되었다.</p>\n<p>Peeky Seq2seq는 기본 Seq2seq에 비해 꽤나 더 좋은 성능을 보인다고 알려져있다.<br>\n하지만 Peeky Seq2seq는 기본 Seq2seq에 비해 파라미터가 더 늘어나기 때문에<br>\n계산량 역시 늘어나게 된다.</p>\n<p>그리고 Seq2seq의 정확도는 하이퍼파라미터에 영향을 크게 받으므로,<br>\n실제 문제에서는 어떤 성능을 낼지 미지수이다.</p>\n<h2>Seq2seq의 한계</h2>\n<p>하지만 이러한 기본적인 Seq2seq에는 한계점이 존재한다.<br>\n입력 데이터가 길어지게 되면 성능이 확연하게 떨어진다는 것이다.</p>\n<p>이러한 Seq2seq의 한계를 극복하기 위해 제안된 Attention Mechanism이 있다.<br>\n실제로 엄청난 성능 향상을 일으킨 이 어텐션 기법에 대해서는 다음 글에서 알아보자.</p>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Seq2seq (Sequence to sequence)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"본 포스팅을 이해하기 위해서는 다음 글에 대한 이해가 선행되는 것이 좋습니다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://sooftware.io/rnn/"},"children":[{"type":"text","value":"RNN (Recurrent Neural Network)"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://sooftware.io/lstm_gru/"},"children":[{"type":"text","value":"LSTM & GRU (Long Short Term Memory & Gated Recurrent Unit)"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"hr","properties":{},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Seq2seq (Sequence-to-Sequence)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"세상에는 많은 시계열 데이터 (Sequence Data) 가 존재한다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n텍스트, 음성, 영상 등 많은 종류의 시계열 데이터가 존재하고,"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n이러한 시계열 데이터들을 다른 시계열 데이터로 변환하는 문제들도 숱하게 생각할 수 있다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134771361-dc0b6d38-12b1-4bc6-a750-d6c5eaa1666a.png","width":600},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"예컨대 기계 번역이나 음성 인식을 예로 들 수 있다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n(Neural Machine Translation or Speech Recognition)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이러한 문제를 위한 모델로 2개의 RNN을 이용하는 Seq2seq"},{"type":"element","tagName":"sup","properties":{},"children":[{"type":"text","value":"sequence to sequence"}]},{"type":"text","value":"라는 모델을 살펴보자 !!"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Seq2seq의 원리"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134771395-4ecc674d-ddc6-4225-8737-bbbe7b8ce3c7.png","width":600},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Seq2seq를 Encoder-Decoder 모델이라고도 많이들 부른다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n이름이 말해주듯이 2개의 모듈, Encoder와 Decoder가 등장한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Encoder는 어떤 시계열 데이터를 압축해서 표현해주고,"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\nDecoder는 압축된 데이터를 다른 시계열 데이터로 변환해준다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134771419-8f2db6a1-57ee-4fa2-a1b9-506316975c78.png","width":600},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"인코더는 데이터를 입력받아서 하나의 벡터로 정보를 압축한다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n이 때의 벡터를 "},{"type":"element","tagName":"b","properties":{},"children":[{"type":"text","value":"컨텍스트 벡터 (Context Vector)"}]},{"type":"text","value":" 라고 하며,"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n디코더는 이 컨텍스트 벡터를 이용해서 위의 그림과 같은 번역을 수행하는 것이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Encoder"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134771435-8cdf6c13-93ee-4e20-963a-710d35bd3ace.png","width":600},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그럼 한번 Encoder부터 살펴보자."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\nEncoder의 계층은 위의 그림처럼 구성된다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"위의 그림처럼 Encoder는 RNN (or LSTM, GRU) 을 이용하여 데이터를"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\nh라는 Hidden State Vector로 변환한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Encoder가 출력하는 벡터 h는 마지막 RNN 셀의 Hidden State이다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n즉, Encoder는 그냥 RNN을 이어놓은 것에 불과하다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"여기서 주목할 점은 Encoder가 내놓는 Context Vector는 결국 마지막 RNN 셀의"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\nHidden State므로, 고정 길이 벡터라는 사실이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134771463-ad53f595-0b1b-4927-86d6-6b07559d6f82.png","width":600},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그래서 인코딩 한다라는 말은 결국 임의 길의의 시계열 데이터를 고정 길이 벡터로 변환하는 작업이 된다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Decoder"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134771491-201c18ba-5ded-4a64-97a4-b1fade60f963.png","width":600},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"다음으로 Decoder를 살펴보자."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\nDecoder는 기본적으로 RNNLM (RNN Language Model)이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Decoder는 Encoder로부터 Context Vector (h)를 넘겨받는다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n그리고 첫 입력으로 문장의 시작을 의미하는 심볼인 [s]가 들어간다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n([s]는 [sos], [bos], [Go] 등 많은 이름으로 불린다)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134771524-eb819bce-12f8-460e-899c-b3e9d7a0f1c1.png","width":600},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Decoder의 첫번째 RNN 셀은 Context Vector와 [s], 이 2개의 입력을 바탕으로"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n새로운 Hidden State를 계산하고 이를 Affine 계층과 Softmax 계층을 거쳐서"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n다음에 등장할 확률이 높은 “안녕하세요”를 예측한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"※ Affine 계층은 Hidden State를 입력으로 받아 분류 개수로 출력해주는 피드포워드 네트워크이다  ※"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134771557-ad262610-582b-46cb-92de-6de78c8e0be5.png","width":600},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그리고 계산한 새로운 Hidden State와 예측한 “안녕하세요”를 입력으로 해서 2번째 예측을 수행한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134771585-7c026d60-3349-4838-925f-c7bc56df6dc8.png","width":600},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"위의 과정을 문장의 끝을 의미하는 심볼인 [/s]가 다음 단어로 예측될 때까지 반복한다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n([/s]는 [eos], [end] 등 많은 이름으로 불린다)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Decoder와 RNNLM"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"여기서 디코더와 RNNLM (RNN Language Model)."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n즉, RNN을 이용해서 문장을 생성하는 모델과의 유일한 차이점은"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n인코더에서 만든 Context Vector를 입력받는다는 점만이 다르다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"컨텍스트 벡터를 초기 입력으로 받는다는 사소한 차이점이 평범한 언어 모델도"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n기계 번역, 음성 인식과 같은 복잡한 문제도 풀 수 있는 Decoder로 탈바꿈 시킬 수 있다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Seqseq의 전체 모습"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134771633-8fbf84f2-1b31-4b3c-ad1e-242558ceb450.png","width":600},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"위는 Encoder와 Decoder를 연결한 Seq2seq의 전체 그림이다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n위의 그림에서 볼 수 있듯이, Encoder의 마지막 Hidden State가"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\nEncoder와 Decoder의 순전파와 역전파를 이어주는 다리가 된다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Seq2seq 개선"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이번에는 앞에서 본 기본적인 Seq2seq 구조를 조금 개선해보자."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n효과적인 기법이 몇 가지 존재하는데 그 중 2가지를 살펴보자."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134771651-1d17c46e-f9b9-487a-9f82-71c108569f09.png","width":600},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"첫 번째 개선안은 아주 손 쉬운 방법이다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n위 그림에서 보듯이 입력 데이터의 순서를 반전시키는 것이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"위의 트릭은 「“Sequence to sequence learning with neural networks.” Advances in neural information processing system. 2014.」 논문에서 제안했다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이 트릭을 사용하면 많은 경우 학습이 빨라져서, 최종 정확도도 좋아진다고 한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그렇다면 왜 입력 데이터를 반전시키는 것만으로 학습이 빨라지고 정확도가 향상되는 걸까?"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n직관적으로는 Gradient의 전파가 원활해지기 때문이라고 볼 수 있다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134771684-c6d18e9e-c1d3-4521-a56b-58c6e25e77dc.png","width":600},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"예를 들어 “나는 고양이로소이다”를 “I am a cat”으로 번역하는 문제에서,"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n“나”라는 단어가 “I”까지 가는 것보다 데이터를 반전시켰을 때 Gradient 전파가 잘 될 것이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"물론 평균적인 거리는 그대로이지만,"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n시계열 데이터는 관련 문제에서는 앞쪽 데이터에 대한 정확한 예측이 선행되면"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n뒤의 예측에서도 좋은 결과로 이어지는 경우가 많기 때문에 더 좋은 결과가 나오지 않을까 싶다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"필자가 진행중인 음성 인식 (Speech Recognition) 프로젝트에서도"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n입력 데이터를 반전시켰을 때 학습 속도가 상당히 개선되는 것을 확인했고,"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n정확도 역시 더욱 좋아졌다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"매우 간단한 트릭이기 때문에 한 번 시도해보는 것을 추천한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Peaky Seq2seq"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134771714-4ffc097f-a72a-4e45-ae5f-d381f35064bd.png","width":600},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이어서 Seq2seq 두 번째 개선안이다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n앞서 배운 Seq2seq의 동작을 다시 한 번 살펴보게 되면,"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\nEncoder는 입력 데이터를 고정 길이의 컨텍스트 벡터로 변환한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Decoder 입장에서는 이 컨텍스트 벡터만이 예측을 하는데에 제공되는 유일한 정보인 셈이다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n그러나 이 중요한 정보를 기본 Seq2seq에서는 최초 RNN 셀에만 전달이 된다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이러한 점을 수정해서 중요한 정보가 담긴 컨텍스트 벡터를 디코더의"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n다른 계층들에게도 전달해주는 것이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이러한 아이디어는 「”learning phrase representation using RNN encoder-decoder for statistical machine translation” Cho, Kyunhyun 2014.」 논문에서 제안되었다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Peeky Seq2seq는 기본 Seq2seq에 비해 꽤나 더 좋은 성능을 보인다고 알려져있다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n하지만 Peeky Seq2seq는 기본 Seq2seq에 비해 파라미터가 더 늘어나기 때문에"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n계산량 역시 늘어나게 된다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그리고 Seq2seq의 정확도는 하이퍼파라미터에 영향을 크게 받으므로,"},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n실제 문제에서는 어떤 성능을 낼지 미지수이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Seq2seq의 한계"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"하지만 이러한 기본적인 Seq2seq에는 한계점이 존재한다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n입력 데이터가 길어지게 되면 성능이 확연하게 떨어진다는 것이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이러한 Seq2seq의 한계를 극복하기 위해 제안된 Attention Mechanism이 있다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n실제로 엄청난 성능 향상을 일으킨 이 어텐션 기법에 대해서는 다음 글에서 알아보자."}]}],"data":{"quirksMode":false}},"excerpt":"Seq2seq (Sequence to sequence) 본 포스팅을 이해하기 위해서는 다음 글에 대한 이해가 선행되는 것이 좋습니다. RNN (Recurrent Neural Network) LSTM & GRU (Long Short Term Memory…","fields":{"readingTime":{"text":"10 min read"}},"frontmatter":{"title":"Seq2seq (Sequence to sequence)","userDate":"25 January 2020","date":"2020-01-25T10:00:00.000Z","tags":["nlp"],"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/3f604bd7e174e888d547ccba99e0fccb/a6e9f/seq2seq.png","srcSet":"/static/3f604bd7e174e888d547ccba99e0fccb/4a1e8/seq2seq.png 750w,\n/static/3f604bd7e174e888d547ccba99e0fccb/a6e9f/seq2seq.png 773w","sizes":"100vw"},"sources":[{"srcSet":"/static/3f604bd7e174e888d547ccba99e0fccb/f9860/seq2seq.webp 750w,\n/static/3f604bd7e174e888d547ccba99e0fccb/c53c5/seq2seq.webp 773w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5808538163001293}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"children":[{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#181818","images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/2584f/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/2456b/soohwan.png 40w,\n/static/a2699b4a2f164aa71106535e018ceafc/ab12d/soohwan.png 80w,\n/static/a2699b4a2f164aa71106535e018ceafc/2584f/soohwan.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65256/soohwan.webp 40w,\n/static/a2699b4a2f164aa71106535e018ceafc/c6b8d/soohwan.webp 80w,\n/static/a2699b4a2f164aa71106535e018ceafc/03d15/soohwan.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.25}}]}}]}},"relatedPosts":{"totalCount":30,"edges":[{"node":{"id":"06ac0e32-0688-50f0-810d-134ef8b168ab","excerpt":"Decoding Strategy (디코딩 전략) 이번 포스팅에서는 자연어처리 모델의 디코딩 전략에 관해서 다뤄보려고 합니다. 디코딩이란 말처럼 디코딩은 디코더에서\n수행하는 작업입니다. 즉, BERT와 같은 인코더 모델에서 사용하는게 아니라 GPT…","frontmatter":{"title":"Decoding Strategy (디코딩 전략)","date":"2022-01-15T10:00:00.000Z"},"fields":{"readingTime":{"text":"9 min read"},"slug":"/generate/"}}},{"node":{"id":"db36f120-4fb0-5bf7-af53-16447fe6cdd4","excerpt":"Generation with Retrieval 이번에 딥마인드에서 RETRO(Retrieval-Enhanced Transformer) 라는 모델을 내놓았습니다. 문서 retrieval + GPT 기반 모델인데,\n7B 모델임에도 불구하고 2…","frontmatter":{"title":"Generation with Retrieval","date":"2022-01-04T23:00:00.000Z"},"fields":{"readingTime":{"text":"6 min read"},"slug":"/fid_and_rag/"}}},{"node":{"id":"3b4040eb-d53d-5064-beec-cfbf7a7a0fe2","excerpt":"Fine-grained Post-training for Improving Retrieval-based Dialogue Systems Paper Review Paper: https://aclanthology.org/2021.naacl-main.12…","frontmatter":{"title":"Fine-grained Post-training for Improving Retrieval-based Dialogue Systems Paper Review","date":"2021-12-18T10:00:00.000Z"},"fields":{"readingTime":{"text":"2 min read"},"slug":"/bert_fp/"}}},{"node":{"id":"78976688-33d9-53c4-8489-5099082b9972","excerpt":"GPT (Generative Pre-trained Transformer) 1 gpt1 먼저 알아보고, gpt2에 대해 알아보겠습니다. GPT1 Improving Language Understanding by Generative Pre-Training…","frontmatter":{"title":"GPT (Generative Pre-trained Transformer)","date":"2021-11-23T11:00:00.000Z"},"fields":{"readingTime":{"text":"13 min read"},"slug":"/gpt/"}}},{"node":{"id":"ad5b0c9b-8199-5f10-bfc9-6bb05942e164","excerpt":"Large Scale LM (2) Distributed Programming (작성중) 이 자료는 [해당 link…","frontmatter":{"title":"Large Scale LM (2) Distributed Programming","date":"2021-11-22T11:00:00.000Z"},"fields":{"readingTime":{"text":"17 min read"},"slug":"/big-model2/"}}}]}},"pageContext":{"slug":"/seq2seq/","prev":{"excerpt":"LSTM & GRU 본 포스팅을 이해가기 위해서는 아래 글에 대한 이해가 선행되는 것이 좋습니다. RNN (Recurrent Neural Network) LSTM 등장 배경 RNN…","frontmatter":{"title":"LSTM & GRU","tags":["nlp"],"date":"2020-01-24T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAABTklEQVQY00WQW0/iUBSF+/9/jQNRZxAyE+IDZGIMRAERoVhBaCm90nN6bt+kOOp62NnJXll75fOcczTSGow5r1gNShqchc/76XQiiiJw4AyYxq8dtVBYA9bas8/7CFMs9gGT8IGNHLOWY1blkLf8CVFJmhRVK47ZgaCY8VY9sUwXTLYrXrMJ23ROVuRIWeM1H61VdGdTuuM+y80VftlhfbjE3/+hVgZ3rgqJihnFF/hpm2ne4cftgNHuhln8i1JkGGX+N1SS7nRC7+43G/+aYNMmSH/ymvSpKoltAq2g0GtmWYtd0cNPOgz+DpmurnneXVHLDCdqvIaRNYbV/p3lfsHhOCdM58TikUy+o5X5CqzUllF4ycOuzX3QYvjSYxzdME/7aNewdHhxHFOWJa6Bah3oD7iYim+5r1mKAqEFaRESJWviJCQ6RiRJQp7n/AOTZMQLmbVhtgAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/385b4880d470b853d530d77243bb4c52/b3525/lstm_gru.png","srcSet":"/static/385b4880d470b853d530d77243bb4c52/2107c/lstm_gru.png 750w,\n/static/385b4880d470b853d530d77243bb4c52/b3525/lstm_gru.png 773w","sizes":"100vw"},"sources":[{"srcSet":"/static/385b4880d470b853d530d77243bb4c52/28c13/lstm_gru.webp 750w,\n/static/385b4880d470b853d530d77243bb4c52/b6f78/lstm_gru.webp 773w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.31565329883570503}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,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"},"images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.2462962962962962}}}}]},"fields":{"readingTime":{"text":"18 min read"},"layout":"","slug":"/lstm_gru/"}},"next":{"excerpt":"Attention 본 포스팅을 이해하기 위해서는 다음 글에 대한 이해가 선행되는 것이 좋습니다. RNN (Recurrent Neural Network) LSTM & GRU (Long Short Term Memory & Gated Recurrent…","frontmatter":{"title":"Attention Mechanism (어텐션 메커니즘)","tags":["nlp"],"date":"2020-01-26T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABXElEQVQoz4WRW0sCYRCG9w93EQj9gy6CzuVVRVl2WCQsw3NWalpBbRpBSVAXlnhoy+Ouu37fE+5KeFUDwzPvwAzf+43CHyGHKaVTdwY2X6ZBHzDAYU8KDCno2Db2qK8MB/5KhHAW4w/C/BpSPYHFDTgIwcI67Lp99o5gegUFMQApGKcc09K2nBfq4RS17UP0eJrGbhA9maW6f8xnPO1wqCtbARQxsvcf5040JjfTeGNFPL4s3tgDnq0Mq9EiU9uXjp7YSKNYeT/tpxzmtUr7KY+Z8zs0sj5az1eIvA9R/6BQz5MqqWjlC85fAtyVzxx9W05yWtqnULlAvVlB6YRnaWtRmpFFusUEzcgS3YdTWtFluo/nNEMz2O+vaN8pMpUd7qpRrhoq9/U4ueoBWj1GrqpS1JMk3tZQvmzXUss9Jrr7ZdR67pVr5sjzwPVvdC3Mjo20YNAHYfFbyz78ABZI/M2kpFnAAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/a9c3aa2f1074a9ebdde0b36f5881c273/e7aa3/attention.png","srcSet":"/static/a9c3aa2f1074a9ebdde0b36f5881c273/ea5bc/attention.png 750w,\n/static/a9c3aa2f1074a9ebdde0b36f5881c273/e7aa3/attention.png 773w","sizes":"100vw"},"sources":[{"srcSet":"/static/a9c3aa2f1074a9ebdde0b36f5881c273/2a863/attention.webp 750w,\n/static/a9c3aa2f1074a9ebdde0b36f5881c273/99eab/attention.webp 773w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.351875808538163}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,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"},"images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.2462962962962962}}}}]},"fields":{"readingTime":{"text":"8 min read"},"layout":"","slug":"/attention/"}},"primaryTag":"nlp"}},
    "staticQueryHashes": ["3170763342","3229353822"]}