{
    "componentChunkName": "component---src-templates-post-tsx",
    "path": "/2020 EMNLP Speech Paper Review/",
    "result": {"data":{"logo":null,"markdownRemark":{"html":"<h1>EMNLP Paper Review: Speech</h1>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2010.08518\">Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al)</a></li>\n<li><a href=\"https://arxiv.org/abs/1911.02750\">Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework (Mingbo Ma et al)</a></li>\n</ul>\n<h2>Adaptive Feature Selection for End-to-End Speech Translation</h2>\n<ul>\n<li>EMNLP 2020</li>\n<li>Biao Zhang, Ivan Titov, Barry Haddow, Rico Sennrich</li>\n</ul>\n<h3>Summary</h3>\n<ul>\n<li>End-to-End Speech Translation (E2E ST)를 다룬 논문</li>\n<li>Speech Translation\n<ul>\n<li>Cascade: 음성 (source) → 음성인식 모델 → 텍스트 (source) → 번역 모델 → 텍스트 (target)</li>\n<li>E2E: 음성 (source) → 음성번역 모델 → 텍스트 (target)</li>\n</ul>\n</li>\n<li>Cascade 방식은 음성인식에서의 오류가 기계번역으로 전파가 되는 단점이 있음</li>\n<li>E2E 번역이 최근 많이 연구되고 있으나, Cascade 방식의 성능을 따라잡지 못하고 있음</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/42150335/101368190-32294400-38ea-11eb-924b-5b0a2e25d2e6.png\" alt=\"image\"></p>\n<ul>\n<li>E2E ST가 어려운 주된 이유로, 음성마다 단어 발화 길이가 다르며, 노이즈 혹은 중간중간 끊기는 등 일관적이지 않다는 특징 때문이라고 주장</li>\n<li>그래서 인코딩 된 피쳐를 선택적으로 사용해야 된다고 주장 (Adaptive Feature Selection)</li>\n<li>AFS는 인코더 아웃풋에서 필요없는 프레임은 제거하는 역할을 함 (L<sub>0</sub>Drop - Zhang et al., 2020)</li>\n<li>결과적으로 본 논문은 아래와 같은 파이프라인을 제안함</li>\n</ul>\n<img src=\"https://user-images.githubusercontent.com/42150335/101366218-073df080-38e8-11eb-8699-dd6ebc2d70dc.png\" width=\"300\">  \n<ul>\n<li>Training Pipeline\n<ol>\n<li>ASR 모델 학습 (Hybrid Cross Entropy + CTC)</li>\n<li>AFS 모델을 추가해서 ASR 모델 파인튜닝</li>\n<li>ASR &#x26; AFS 모델은 Freeze한 채로 ST Encoder, ST Decoder 학습</li>\n</ol>\n</li>\n<li>Result on MuST-C En-De</li>\n</ul>\n<img src=\"https://user-images.githubusercontent.com/42150335/101370007-4a9a5e00-38ec-11eb-8f41-7f6de1b9d583.png\" width=\"500\">\n<ul>\n<li>AFS는 모델을 더 빠르게 하면서도 성능을 높였음</li>\n<li>성능은 Cascade보다는 살짝 낮음</li>\n</ul>\n<hr>\n<h2>Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework</h2>\n<ul>\n<li>EMNLP 2020</li>\n<li>Mingbo Ma, Baigong Zheng, Kaibo Liu, Renjie Zheng, Hairong Liu, Kainan Peng, Kenneth Church, Liang Huang  (Baidu Research)</li>\n<li><a href=\"https://inctts.github.io/\">Demo Page</a></li>\n</ul>\n<h3>Summary</h3>\n<ul>\n<li>동시번역을 위한 빠른 음성합성 기법 제안</li>\n<li>새로 학습할 필요없이 Inference 단에서 수정하여 사용할 수 있는 파이프라인 제안 (Tacotron2 사용)</li>\n<li>기존 TTS 시스템</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/42150335/101376816-6bff4800-38f4-11eb-9dca-1592c05c6759.png\" alt=\"image\"></p>\n<p>Text2Phoneme → Phoneme2Spectrogram → Spectrogram2Wave 단계를 거침</p>\n<ul>\n<li>위와 같은 Full-sentence TTS는 문장 길이가 길어질수록 latency가 길어지는 고질적인 문제점을 가지고 있음</li>\n<li>이러한 문제점 해결을 위해 아래 파이프라인을 제안</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/42150335/101377884-bf25ca80-38f5-11eb-8098-6f0b206d01f6.png\" alt=\"image\"></p>\n<ul>\n<li>Full-sentence TTS가 아닌, Incremental TTS 방식 제안</li>\n<li>먼저 만들어진 오디오를 재생하는 동안 뒷단의 오디오를 만들어나가는 방식</li>\n<li>이와 같은 파이프라인이 가능하려면 특정 단위로 쪼개야함 (E.g. Word)</li>\n<li>하지만 Word 단위로 TTS를 진행한 후, 오디오를 이어붙이게 되면 굉장히 부자연스러운 음성이 합성됨</li>\n<li>이를 극복하기 위해 lookahead-k Policy 제안\n<ul>\n<li>t번째 target을 만들때 t+k개의 입력 소스를 통해 생성 (첫 k+1 스텝까지는 wait)</li>\n</ul>\n</li>\n<li>결과적으로 음질이 크게 떨어지지 않으면서도 latency를 줄임 (문장이 길수록 효과가 큼)</li>\n</ul>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"EMNLP Paper Review: Speech"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/2010.08518"},"children":[{"type":"text","value":"Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al)"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/1911.02750"},"children":[{"type":"text","value":"Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework (Mingbo Ma et al)"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Adaptive Feature Selection for End-to-End Speech Translation"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"EMNLP 2020"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Biao Zhang, Ivan Titov, Barry Haddow, Rico Sennrich"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Summary"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"End-to-End Speech Translation (E2E ST)를 다룬 논문"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Speech Translation\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Cascade: 음성 (source) → 음성인식 모델 → 텍스트 (source) → 번역 모델 → 텍스트 (target)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"E2E: 음성 (source) → 음성번역 모델 → 텍스트 (target)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Cascade 방식은 음성인식에서의 오류가 기계번역으로 전파가 되는 단점이 있음"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"E2E 번역이 최근 많이 연구되고 있으나, Cascade 방식의 성능을 따라잡지 못하고 있음"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101368190-32294400-38ea-11eb-924b-5b0a2e25d2e6.png","alt":"image"},"children":[]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"E2E ST가 어려운 주된 이유로, 음성마다 단어 발화 길이가 다르며, 노이즈 혹은 중간중간 끊기는 등 일관적이지 않다는 특징 때문이라고 주장"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"그래서 인코딩 된 피쳐를 선택적으로 사용해야 된다고 주장 (Adaptive Feature Selection)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"AFS는 인코더 아웃풋에서 필요없는 프레임은 제거하는 역할을 함 (L"},{"type":"element","tagName":"sub","properties":{},"children":[{"type":"text","value":"0"}]},{"type":"text","value":"Drop - Zhang et al., 2020)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"결과적으로 본 논문은 아래와 같은 파이프라인을 제안함"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101366218-073df080-38e8-11eb-8699-dd6ebc2d70dc.png","width":300},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Training Pipeline\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ASR 모델 학습 (Hybrid Cross Entropy + CTC)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"AFS 모델을 추가해서 ASR 모델 파인튜닝"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ASR & AFS 모델은 Freeze한 채로 ST Encoder, ST Decoder 학습"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Result on MuST-C En-De"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101370007-4a9a5e00-38ec-11eb-8f41-7f6de1b9d583.png","width":500},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"AFS는 모델을 더 빠르게 하면서도 성능을 높였음"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"성능은 Cascade보다는 살짝 낮음"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"hr","properties":{},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"EMNLP 2020"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Mingbo Ma, Baigong Zheng, Kaibo Liu, Renjie Zheng, Hairong Liu, Kainan Peng, Kenneth Church, Liang Huang  (Baidu Research)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://inctts.github.io/"},"children":[{"type":"text","value":"Demo Page"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Summary"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"동시번역을 위한 빠른 음성합성 기법 제안"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"새로 학습할 필요없이 Inference 단에서 수정하여 사용할 수 있는 파이프라인 제안 (Tacotron2 사용)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"기존 TTS 시스템"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101376816-6bff4800-38f4-11eb-9dca-1592c05c6759.png","alt":"image"},"children":[]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Text2Phoneme → Phoneme2Spectrogram → Spectrogram2Wave 단계를 거침"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"위와 같은 Full-sentence TTS는 문장 길이가 길어질수록 latency가 길어지는 고질적인 문제점을 가지고 있음"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"이러한 문제점 해결을 위해 아래 파이프라인을 제안"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101377884-bf25ca80-38f5-11eb-8098-6f0b206d01f6.png","alt":"image"},"children":[]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Full-sentence TTS가 아닌, Incremental TTS 방식 제안"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"먼저 만들어진 오디오를 재생하는 동안 뒷단의 오디오를 만들어나가는 방식"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"이와 같은 파이프라인이 가능하려면 특정 단위로 쪼개야함 (E.g. Word)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"하지만 Word 단위로 TTS를 진행한 후, 오디오를 이어붙이게 되면 굉장히 부자연스러운 음성이 합성됨"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"이를 극복하기 위해 lookahead-k Policy 제안\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"t번째 target을 만들때 t+k개의 입력 소스를 통해 생성 (첫 k+1 스텝까지는 wait)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"결과적으로 음질이 크게 떨어지지 않으면서도 latency를 줄임 (문장이 길수록 효과가 큼)"}]},{"type":"text","value":"\n"}]}],"data":{"quirksMode":false}},"excerpt":"EMNLP Paper Review: Speech Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al) Incremental Text-to-Speech…","fields":{"readingTime":{"text":"4 min read"}},"frontmatter":{"title":"EMNLP Paper Review: Speech","userDate":"8 December 2020","date":"2020-12-08T10:00:00.000Z","tags":["speech","paper"],"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/3020a90c23b0e5a906d9e9d75523071a/5a68f/2020-emnlp.png","srcSet":"/static/3020a90c23b0e5a906d9e9d75523071a/1206c/2020-emnlp.png 750w,\n/static/3020a90c23b0e5a906d9e9d75523071a/c1998/2020-emnlp.png 1080w,\n/static/3020a90c23b0e5a906d9e9d75523071a/c6087/2020-emnlp.png 1366w,\n/static/3020a90c23b0e5a906d9e9d75523071a/5a68f/2020-emnlp.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/3020a90c23b0e5a906d9e9d75523071a/3e1c3/2020-emnlp.webp 750w,\n/static/3020a90c23b0e5a906d9e9d75523071a/bbc54/2020-emnlp.webp 1080w,\n/static/3020a90c23b0e5a906d9e9d75523071a/72682/2020-emnlp.webp 1366w,\n/static/3020a90c23b0e5a906d9e9d75523071a/97f4c/2020-emnlp.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.41875}}},"author":[]}},"relatedPosts":{"totalCount":9,"edges":[{"node":{"id":"77bed2d4-fc96-5bff-9808-9b9cb45369f3","excerpt":"EMNLP Paper Review: Speech Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al) Incremental Text-to-Speech…","frontmatter":{"title":"EMNLP Paper Review: Speech","date":"2020-12-08T10:00:00.000Z"},"fields":{"readingTime":{"text":"4 min read"},"slug":"/2020 EMNLP Speech Paper Review/"}}},{"node":{"id":"12b0b820-8abf-5c73-a6ce-0ddb411555be","excerpt":"Conformer: Convolution-augmented Transformer for Speech Recognition Anmol Gulati et al. Google Inc. INTERSPEECH, 2020 Reference Conformer…","frontmatter":{"title":"Conformer Paper Review","date":"2020-08-30T10:00:00.000Z"},"fields":{"readingTime":{"text":"4 min read"},"slug":"/conformer/"}}},{"node":{"id":"0f0a6d01-488e-5cf1-9207-9abc587e9253","excerpt":"AI & Speech Processing: Application-2 본 글은 광운대학교 전자공학과 박호종 교수님의 강의를 듣고 작성되었음을 밝힙니다. Speaker Verification and Identification Verification…","frontmatter":{"title":"AI & Speech Processing: Application-2","date":"2020-04-17T10:00:00.000Z"},"fields":{"readingTime":{"text":"4 min read"},"slug":"/audio_app2/"}}},{"node":{"id":"fd5d74d7-116c-51c6-9461-9b2d99a9212e","excerpt":"AI & Speech Processing: Application-1 본 글은 광운대학교 전자공학과 박호종 교수님의 강의를 듣고 작성되었음을 밝힙니다. 음성/오디오/sound…","frontmatter":{"title":"AI & Speech Processing: Application-1","date":"2020-04-15T10:00:00.000Z"},"fields":{"readingTime":{"text":"7 min read"},"slug":"/audio_app/"}}},{"node":{"id":"699f85ab-3152-5362-9d3a-a64a4a16b74a","excerpt":"AI & Speech Signal Processing Lecture : DSP for Audio 본 글은 광운대학교 전자공학과 박호종 교수님의 강의를 듣고 작성되었음을 밝힙니다. 이제는 오디오에 특화된 DSP로 넘어가보자. Short-Time…","frontmatter":{"title":"AI & Speech Processing: DSP for Audio","date":"2020-04-11T10:00:00.000Z"},"fields":{"readingTime":{"text":"5 min read"},"slug":"/dsp_for_audio/"}}}]}},"pageContext":{"slug":"/2020 EMNLP Speech Paper Review/","prev":{"excerpt":"Below is just about everything you’ll need to style in the theme. Check the source code to see the many embedded elements within paragraphs…","frontmatter":{"title":"Electra Paper Review","tags":["nlp","paper"],"date":"2020-09-23T07:03:47.149Z","draft":null,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABY0lEQVQoz02SacuCUBCF/f+/qO9BGFnaSqVp0UIl7aWtnpdn4MIrXObO3HPObHpVVen7/er3++n1eunz+ej5fOrxeKgsSx2PRw2HQ/N5x7/dbrper7pcLmbhvN9voeVJ0m6302az0Ww202KxUJZlut/vJgwBkeVyqfl8bj6fK4I4CeHweSgnSWKiBBGG2Gg0VKvV1O12dTqdtF6vtd1uNRgM5Pu+6vW6RqOR4eM41nQ6tUo9sqxWKwMj5IQRSNPUKj6fz0akGtqleizFgEMYUbSsZQi0QiUAD4eDtUtbzI47mP1+bxhmyXyLolCe51YEHGsZAR4hAeCOCAIuERjeqQxBtxAOPniX2KNU5sJgmddkMrF7v983Szu8s7D/8V6vp/F4rDAMzcJlJB4OIAAEW62W2u22CWHdaTabiqLI3judjvngiXEnzg5MMAgCE4UImKxYwCzD/VbM0B1iWJbJUvEZxR8WlJe1e/a3LQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/7ccdb9951c9d362c8a3548e8c2a87231/59ccb/electra.png","srcSet":"/static/7ccdb9951c9d362c8a3548e8c2a87231/c68af/electra.png 750w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/87f65/electra.png 1080w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/d464a/electra.png 1366w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/59ccb/electra.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ccdb9951c9d362c8a3548e8c2a87231/9fb02/electra.webp 750w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/cd76f/electra.webp 1080w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/b7397/electra.webp 1366w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/507b8/electra.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4479166666666667}}},"author":[]},"fields":{"readingTime":{"text":"4 min read"},"layout":"post","slug":"/electra/"}},"next":{"excerpt":"2020년 회고 다사다난했던 2020년이 지나고 어느덧 2021년 새해가 밝았습니다. 🤗 🤗 코로나라는 세계적인 재앙 때문에 생활부터 모든게 많이 달라진 한 해 였습니다. 여태까지…","frontmatter":{"title":"2020년 회고","tags":["record"],"date":"2020-12-31T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAADPklEQVQ4yzWT/U/TVxTGv1QCIbQIThYXFSjlbUrZooMC6hwEAkmR1paCLYGCthUoraW8Q6GUFlpaGVJBWsEiaud7XGKWmCzL/rTP8r26H27OzX15znPO8xxpYGCQsTEP6+EYoXAM39QcU/45orFtdpMHLAdCBFbWCUe2CK5tsLS8xuz8MvHEI3Env7979z4jIw6G7feQLBYri0tBtuI7xOI74pMct3f2WFhcZWMzQTgS5yD1jOTjlEi2tBxk/8mRSDQzs4R/eoFJzxRW6xCSzNDlmsDrnWZ+IcBaaJO5bwxWgxHBPLIRF5/r6n6kpKQErfYn+ix32Nl9wkE6I9jL94ODdqS+vjs4nRPY7fcEaGI7KUBlhvJeZhjb+h2j0UxRURHFxcWUlZVRWakh/eyYL//8y+cvf5N9+5HDzAuk0VEnHo9fZNh9nGJv/5BUOiMyZ998JPM8y1HmJbduGamprkWlKuL8+QuoKyqpqFBTr23ANjiEa8zNrzfbkBzOr+XeH5tkfmGF5F6ap0cnvMi+42X2PSev3pI+fI5O14LBaEbX3CIAtdoGVEoVBQUFSJJEIBji2vUbSN1desbHvaLs/9WMbe2wlXjEZvQhiYdJnK4JmpqaSe6nMBhNXLxwEbW6ksLCQnJzc2nU6fj0+S+8Pj+S0dgnypSbLzc59fSY45PXIr764wNv3v8pmJ09W0p1dQ2nFArOnPmOy5e1AjAnJ4eeXgORaIzVUBipra0Dm20Yq20Ys3kA39SssJEsyEEqQ/b1B6y2IfLy8rl0qZ7e3tvcNlnQaKpRKlV0dnbR02Ogu1tPa+t1pJbma7S23uC3m+10delpb+/Eah3G7fYxPbNINLqNydTPuXM/CJDa2jrBVN7n5eejrtQIG9XU1ArlJaPBjH3EwcioE5fLjd3uwOEYZ2LiAe5JH37/vPBXVVWNsI0sgFymLExp6fecLjot+qg4pUChUCD199sE0APfLHPzAQIrYSGOvOTRkpWX2Wo0VSgLlSiVSsrLKwQjvd5AR0e3OCsrK+fKlV+QTOZ+oaLH6/8GuE5oPfp1ttejrIWiwvRXrzYKceR5NZkswoPahp9pamoRDmhs1FFf38B/iywfcoGnX+MAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/c6c1288528036ea9df3176dbafeffabf/b444b/2020.png","srcSet":"/static/c6c1288528036ea9df3176dbafeffabf/b444b/2020.png 600w","sizes":"100vw"},"sources":[{"srcSet":"/static/c6c1288528036ea9df3176dbafeffabf/9ff6b/2020.webp 600w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6666666666666666}}},"author":[]},"fields":{"readingTime":{"text":"21 min read"},"layout":"","slug":"/2020/"}},"primaryTag":"speech"}},
    "staticQueryHashes": ["3170763342","3229353822"]}