{
    "componentChunkName": "component---src-templates-post-tsx",
    "path": "/Data-Importance/",
    "result": {"data":{"logo":null,"markdownRemark":{"html":"<hr>\n<h1>데이터 중요도 파악(Permutation Importance)</h1>\n<p>모델의 레이블에 영향을 주는 Feature의 중요도를 <strong>Sklearn의 Permutation Importance</strong> 를 사용해 파악한다.</p>\n<ul>\n<li>\n<h3>Permutation Importance</h3>\n<p><strong>모델 예측시 가장 영향을 많이 주는 Feature를 파악하는 방법</strong></p>\n<p>모델의 훈련이 끝난 후 계산되며 <strong>모델이 특정 Feature를 안썻을때, 성능 손실에 얼마나 영향을 주는지로 그 Feature의 중요도를 파악하는 방법</strong> 이다.</p>\n<blockquote>\n<p>어떤 모델이든 적용 가능하다!</p>\n</blockquote>\n</li>\n<li>\n<h3>Permutation Importance의 장점</h3>\n<p>기존에는 특정 Feature를 제거후 모델을 학습해서 중요도를 파악했지만 자원 소모가 너무 크다.</p>\n<p>때문에 Permutation Importance는 <strong>특정 Feature를 무작위로 섞어 Target과의 연결 고리를 끊어 해당 Feature를 안쓰는 것처럼(노이즈)</strong> 만든다.</p>\n<p>그후 예측값과 실제값의 차이가 더 생겼는지로 해당 Feature의 영향력을 파악한다.</p>\n<p>이러한 과정 덕분에 <strong>모델의 재학습이 필요없다!</strong></p>\n<blockquote>\n<p>훈련 모델과 데이터만 있으면 변수 중요도를 뽑을 수 있다. 반대로 모델 학습 과정, 내부 구조 정보가 필요 없어서 어느 모델이든 적용 가능하다.</p>\n</blockquote>\n<h4><strong>Permutation Importance의 다른 특징은 각 Feature의 중요도에는 다른 Feature와의 상호작용도 포함된다는 것이다!</strong></h4>\n<p><code class=\"language-text\">특정 Feature를 섞으면 다른 Feature와의 관계가 끝어져서 해당 Feature와의 모든 상호작용이 사라진다. 때문에 두 Feature간 상호작용의 영향은 두개의 Feature Importance에 중복 포함된다.</code></p>\n</li>\n<li>\n<h3>Permutation Importance의 단점</h3>\n<ul>\n<li>\n<p>특정 Feature를 무작위로 섞어서 실행시마다 Feature Importance 결과가 달라진다.</p>\n<blockquote>\n<p>섞는 횟수를 늘려 예측 에러 분산을 감소할 수 있지만 Feature 개수가 많을 경우 연살량이 증가하기 때문에 Permutation의 적절한 회수를 선택해야한다.</p>\n</blockquote>\n</li>\n<li>\n<p>Feature를 무작위로 섞기에 비현실적인 데이터 조합이 생길 수 있다.</p>\n<blockquote>\n<p>Feature간 상관관계가 높을 경우 발샐할 수 있으며 이런 데이터의 비개연성, 비현실성이 증가하면 예측값에 영향을 미칠 가능성이 있고 우리가 원하던 결과가 아니기에 이를 염두하고 해석해야한다.</p>\n</blockquote>\n<p>예로, 키와 몸무게를 랜덤하게 섞다보면 키가 2m인데 몸무게가 30kg인 데이터가 만들어 질 수도 있다.</p>\n</li>\n</ul>\n</li>\n<li>\n<h3>실행 코드</h3>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">from sklearn.inspection import permutation_importance # sklearn 22 버전부터 해당\nfrom sklearn.metrics import make_scorer\n\n# MAPE\ndef mean_absolute_percentage_error(y_test, y_pred):\n    y_test, y_pred = np.array(y_test), np.array(y_pred)\n    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n\n# fix_model : 훈련된 모델\n# X_train : 훈련데이터 Feature\n# y_train : 훈련데이터 Target\n# scoring : Feature 를 Shuffler 한 뒤, 예측값과 실제값을 어떤 Metric 을 사용해 비교할지\n# n_repeats : 특정 Feature 를 몇번 Shuffle 할 것인지\n# random_state : 난수 고정\nresult = permutation_importance(fix_model, X_train, y_train, scoring = make_scorer(mean_absolute_percentage_error,greater_is_better=False),\n                            n_repeats=30,\n                            random_state=0)\n# Feature label\nFeature = train[['lr','lc','rc','ld','rd','lnnz','rnnz','lr*lc','lc*rc','lr*rc']] \n\n# Feature 중요도를 오름차순으로 정렬한 뒤, 해당 Feature 의 index 를 저장\nsorted_result = result.importances_mean.argsort()\n\n# 결과를 DataFrame 화\nimportances = pd.DataFrame(result.importances_mean[sorted_result], index=Feature.columns[sorted_result]).sort_values(0, ascending=False)   \nimportances</code></pre></div>\n<hr>\n<blockquote>\n<h3>만약 인간의 뇌가 우리가 이해할 수 있을 정도로 단순하다면,</h3>\n<p>if the human brain was simple enough for us to understand,</p>\n<h3>우리는 그렇게 단순할 수 없을 것이다. -에머슨 M.푸(Emerson M. Pooh)</h3>\n<p>we wouldn’t be that simple.</p>\n</blockquote>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"hr","properties":{},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"데이터 중요도 파악(Permutation Importance)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"모델의 레이블에 영향을 주는 Feature의 중요도를 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Sklearn의 Permutation Importance"}]},{"type":"text","value":" 를 사용해 파악한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Permutation Importance"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"모델 예측시 가장 영향을 많이 주는 Feature를 파악하는 방법"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"모델의 훈련이 끝난 후 계산되며 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"모델이 특정 Feature를 안썻을때, 성능 손실에 얼마나 영향을 주는지로 그 Feature의 중요도를 파악하는 방법"}]},{"type":"text","value":" 이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"어떤 모델이든 적용 가능하다!"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Permutation Importance의 장점"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"기존에는 특정 Feature를 제거후 모델을 학습해서 중요도를 파악했지만 자원 소모가 너무 크다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"때문에 Permutation Importance는 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"특정 Feature를 무작위로 섞어 Target과의 연결 고리를 끊어 해당 Feature를 안쓰는 것처럼(노이즈)"}]},{"type":"text","value":" 만든다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그후 예측값과 실제값의 차이가 더 생겼는지로 해당 Feature의 영향력을 파악한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이러한 과정 덕분에 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"모델의 재학습이 필요없다!"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"훈련 모델과 데이터만 있으면 변수 중요도를 뽑을 수 있다. 반대로 모델 학습 과정, 내부 구조 정보가 필요 없어서 어느 모델이든 적용 가능하다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h4","properties":{},"children":[{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Permutation Importance의 다른 특징은 각 Feature의 중요도에는 다른 Feature와의 상호작용도 포함된다는 것이다!"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"특정 Feature를 섞으면 다른 Feature와의 관계가 끝어져서 해당 Feature와의 모든 상호작용이 사라진다. 때문에 두 Feature간 상호작용의 영향은 두개의 Feature Importance에 중복 포함된다."}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Permutation Importance의 단점"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"특정 Feature를 무작위로 섞어서 실행시마다 Feature Importance 결과가 달라진다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"섞는 횟수를 늘려 예측 에러 분산을 감소할 수 있지만 Feature 개수가 많을 경우 연살량이 증가하기 때문에 Permutation의 적절한 회수를 선택해야한다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Feature를 무작위로 섞기에 비현실적인 데이터 조합이 생길 수 있다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Feature간 상관관계가 높을 경우 발샐할 수 있으며 이런 데이터의 비개연성, 비현실성이 증가하면 예측값에 영향을 미칠 가능성이 있고 우리가 원하던 결과가 아니기에 이를 염두하고 해석해야한다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"예로, 키와 몸무게를 랜덤하게 섞다보면 키가 2m인데 몸무게가 30kg인 데이터가 만들어 질 수도 있다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"실행 코드"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"text"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-text"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"from sklearn.inspection import permutation_importance # sklearn 22 버전부터 해당\nfrom sklearn.metrics import make_scorer\n\n# MAPE\ndef mean_absolute_percentage_error(y_test, y_pred):\n    y_test, y_pred = np.array(y_test), np.array(y_pred)\n    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n\n# fix_model : 훈련된 모델\n# X_train : 훈련데이터 Feature\n# y_train : 훈련데이터 Target\n# scoring : Feature 를 Shuffler 한 뒤, 예측값과 실제값을 어떤 Metric 을 사용해 비교할지\n# n_repeats : 특정 Feature 를 몇번 Shuffle 할 것인지\n# random_state : 난수 고정\nresult = permutation_importance(fix_model, X_train, y_train, scoring = make_scorer(mean_absolute_percentage_error,greater_is_better=False),\n                            n_repeats=30,\n                            random_state=0)\n# Feature label\nFeature = train[['lr','lc','rc','ld','rd','lnnz','rnnz','lr*lc','lc*rc','lr*rc']] \n\n# Feature 중요도를 오름차순으로 정렬한 뒤, 해당 Feature 의 index 를 저장\nsorted_result = result.importances_mean.argsort()\n\n# 결과를 DataFrame 화\nimportances = pd.DataFrame(result.importances_mean[sorted_result], index=Feature.columns[sorted_result]).sort_values(0, ascending=False)   \nimportances"}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"hr","properties":{},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"만약 인간의 뇌가 우리가 이해할 수 있을 정도로 단순하다면,"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"if the human brain was simple enough for us to understand,"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"우리는 그렇게 단순할 수 없을 것이다. -에머슨 M.푸(Emerson M. Pooh)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"we wouldn’t be that simple."}]},{"type":"text","value":"\n"}]}],"data":{"quirksMode":false}},"excerpt":"데이터 중요도 파악(Permutation Importance) 모델의 레이블에 영향을 주는 Feature의 중요도를 Sklearn의 Permutation Importance 를 사용해 파악한다. Permutation Importance…","fields":{"readingTime":{"text":"5 min read"}},"frontmatter":{"title":"데이터 중요도 파악(Permutation Importance)","userDate":"9 May 2021","date":"2021-05-09T10:00:00.000Z","tags":["ml&dl"],"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#d8d8d8","images":{"fallback":{"src":"/static/77f233d69942df62a648b0e73584df2c/bc15a/data_importance.png","srcSet":"/static/77f233d69942df62a648b0e73584df2c/bc15a/data_importance.png 560w","sizes":"100vw"},"sources":[{"srcSet":"/static/77f233d69942df62a648b0e73584df2c/6de64/data_importance.webp 560w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5589285714285714}}},"author":[{"id":"Bosoek Kim","bio":"A.I. developer and robot engineer","avatar":{"children":[{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/05e3074d52e075301cf8995aefacaaf6/f1874/bosoek.png","srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/f31ef/bosoek.png 40w,\n/static/05e3074d52e075301cf8995aefacaaf6/8f5cc/bosoek.png 80w,\n/static/05e3074d52e075301cf8995aefacaaf6/f1874/bosoek.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/e73fe/bosoek.webp 40w,\n/static/05e3074d52e075301cf8995aefacaaf6/3e808/bosoek.webp 80w,\n/static/05e3074d52e075301cf8995aefacaaf6/4fcad/bosoek.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.9916666666666667}}]}}]}},"relatedPosts":{"totalCount":8,"edges":[{"node":{"id":"57a76984-8204-5d3d-8e03-242e413cbed9","excerpt":"BMO 약 한달 가까이 진행한 BMO 프로젝트가 끝났다. 개인적으로 죽을만큼 힘들었어서 지난 한달 반을 기록해본다. 프로젝트를 시작한 계기는 GSM 페스티벌이었다. 우리 학교는 매년 GSM…","frontmatter":{"title":"BMO","date":"2022-01-09T10:00:00.000Z"},"fields":{"readingTime":{"text":"10 min read"},"slug":"/BMO/"}}},{"node":{"id":"301b4249-fd97-59b2-ae8b-2e40b5ae4970","excerpt":"GAN으로 우주 사진 생성하기 평소 우주에 관심이 많아 우주 관련 프로젝트를 할 거 없나 찾다가 GAN을 알게되어 GAN…","frontmatter":{"title":"GAN으로 우주 사진 생성하기","date":"2021-10-30T10:00:00.000Z"},"fields":{"readingTime":{"text":"5 min read"},"slug":"/space_image/"}}},{"node":{"id":"cfc99eb9-02e8-50c0-8d4c-e0bebe894ad8","excerpt":"KLUE로 모델 평가하기 CREW 약 2달 이상 진행 했던 KLUE로 모델 평가하기 Crew활동이 끝났다. 여러 감정들이 들어 지난 2달 동안의 Crew…","frontmatter":{"title":"KLUE로 모델 평가하기 CREW","date":"2021-09-15T10:00:00.000Z"},"fields":{"readingTime":{"text":"5 min read"},"slug":"/klue_baseline/"}}},{"node":{"id":"bba440b9-4552-535f-b052-f3151f7ae141","excerpt":"Numpy 튜토리얼 넘파이는 벡터(1차원 배열), 행렬(2차원 배열) 등 수치 연산을 하는 선형 대수(Linear algebra) 라이브러리이다. 기초 개념 Numpy…","frontmatter":{"title":"Numpy 튜토리얼","date":"2021-08-20T10:00:00.000Z"},"fields":{"readingTime":{"text":"6 min read"},"slug":"/Numpy/"}}},{"node":{"id":"93c5f0ee-6aca-5343-8bd4-0c98cc0e7201","excerpt":"Matplotlib Tutorial 은 파이썬 기반 그래프(플롯) 시각화 라이브러리이다.\n 모듈의 각각의 함수로 그래프를 만들고 변화를 줄수 있다. 기본 그래프 pyplot.show() 그렸던 그래프들 출력하는 함수 pyplot.plot…","frontmatter":{"title":"Matplotlib Tutorial","date":"2021-07-20T10:00:00.000Z"},"fields":{"readingTime":{"text":"18 min read"},"slug":"/matplotlib/"}}}]}},"pageContext":{"slug":"/Data-Importance/","prev":{"excerpt":"분류 모델 성능 평가 지표 분류 모델을 만들고 나면 분류기의 예측력을 검증해야 한다. 이때 분류 모델이 정답을 맞히거나 틀리는 경우들은 총 4가지가 생긴다. 이때 생기는 개념이 1종 오류,…","frontmatter":{"title":"분류 모델 성능 평가 지표","tags":["ml&dl"],"date":"2021-05-03T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABkklEQVQoz22QXZOaMBSG/f+/yIsFLxbLKEk6gEpCPkgCJKtSUOxSqwU6ox27tftcnMw5k2fOO2cyfqDv+3sdhmH8jOHGo53cR+M4VlW1XC4RQrPZLAgCCCFCiBDied50OkUIQQiNMY//f+Q7XdfJG2VZAgDm8zkAII5jCKHjOAAAhNBmszmfz/9sfqLve2utVGq9XlNKlVLWWpqmYRgaY7Ise5Yvl0tRFMYYa22e577vzz3Pdd0gCDzPcx3nxXnxXl/9L34cx4/kk/tT1zVjTGstpczznGC8rw+R2m2bE6NpUZa4+LbS1fF4pJT+3XyXm6bhnCc3GOdvxuzef622Z9uN1trqcBKHAe9/dtdBfoz9ODUAgHPOGEuSZLlYSKVdRHCWIwhTgr9iOY+Y1ipJkme5rmshhNZaCFEUBaV0W7dI7k3znglh7JuuTrhs2tN3zvknseMbhBCMsVJSH66w6PRpLEpjqsNqd43sj/YyiP/ltm3DMCSEMMbSNI2iUGrtxzQV+Wa9ZoxumFqsWH676EP+DSHvV/DthO75AAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/0c8989e5082dad4a67acb7a1c50465cf/2d99a/confusion_matrix.png","srcSet":"/static/0c8989e5082dad4a67acb7a1c50465cf/2d99a/confusion_matrix.png 431w","sizes":"100vw"},"sources":[{"srcSet":"/static/0c8989e5082dad4a67acb7a1c50465cf/d8b57/confusion_matrix.webp 431w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5614849187935035}}},"author":[{"id":"Bosoek Kim","bio":"A.I. developer and robot engineer","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACLklEQVQ4y2P4TwFgoInmf//+/QWDf//+kaD5D1gDXA8ym7BmiNIvX76cOHnqzt17f/78hQsS1rx6zbqyyuqk1HRTK1tLW4fUjKzHj5/8////79+/ODVD5C5eumRoaq6tb2RkZmlp62Bt76imrVtVU4fVcgY01+YWFOsbm9k7uZpb25ta2emZWhlZWOsZmpRVVuNzNkRzT1+/mq6BsaWdq4urnYNTT3FmUUK4pJKGqpbu3bv30ByPrvnDpy+zO5o6cpNOzGm/uaz/3PyuvZPqne3tvL28Xrx8heZ49AD7++fv38Obbi1ovzi37fP22ZvbSh6tnXJndv293Wt+ga3AE9ogYz8e2vp0ec/jFX3vN059tKr/y/bZnzZO/vn8Hkwel2aw3O+vn7/sX/Zpw6R36yZ+3TH74/Y5P98++4ehE1s8g1X8fP34676ln7fNfr9p6oftc//9/kUgqtBC7u2XT++un/ywpvfz3iXvPn94/eUzpn50zRDJq88eLz577MPn9z9Pbfn/6Nq1V89nHd1z5tHdf3gCDGLw0w/v5hzbN//EgSvPnxy9f+vh+3f7b12deWTPzCN7zj66B7bgH05nb7t6fuaR3YtOHZp3fP+sY3vnndg//8SBecf3zz95cMnpw19//oQ7kAHNwV9+fF908tCcY/sWnjy44OTBhScPLTh5EKJ/IZjx8P0buBvRU9jzj+/nnTgw9/h+iGYImnscrPnUodnH9t54+RSUlsCaAQFSIZcLZuFkAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/05e3074d52e075301cf8995aefacaaf6/5f340/bosoek.png","srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/21474/bosoek.png 750w,\n/static/05e3074d52e075301cf8995aefacaaf6/5f340/bosoek.png 929w","sizes":"100vw"},"sources":[{"srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/1d102/bosoek.webp 750w,\n/static/05e3074d52e075301cf8995aefacaaf6/14d80/bosoek.webp 929w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.9913885898815931}}}}]},"fields":{"readingTime":{"text":"5 min read"},"layout":"post","slug":"/Classification-performance-evaluation/"}},"next":{"excerpt":"Keras 모델 생성 방법(Keras models) 케라스의 구현 방식에는 Sequential API, Functional API, Subclassing API 총…","frontmatter":{"title":"Keras 모델 생성 방법(Keras models)","tags":["ml&dl"],"date":"2021-07-11T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAABlklEQVQoz3WQ3U8TQRTF97/zwUSJb0Qf/OAjERGCFv4NYxBQjNJSKm15aRN4AmqsFGlIhX4NuzxoMZKa0C0KXVp2dn5kt2wpCZ7JyZ0795ybe0fjEso9qk0vV4pUap211VW+ZbNsbmZIJhKk0+lO3dMqrkHzC92N/LstJea/BvVTC/PEwmo2UY7s6Lr1PjXHUcguOl4BGi0bs9GiaTue0X0/tlqcnNm4Htcsb/Bq3ADpSJSSndyfxv+cc2nzP2jbP+okv1dJ5NoMZ34Rzx6yvPOHZK5K7me9PaGjyB8ck9k3Ses1VnarfBZHbOybfDVqbBg1fpsW2khEcGcyz/OIYGhBMBwRjHzaYyhc5vbrXcbjutfQXbX3bZ7edwX6gyUGQiX6giX6g2WeLQhuvdphar2C5prvTRd5GhYeB+fLDM4LBkKCu28KTCwZ3pp/rXPuzxboCwlexHTGYvplNAjEDXqmCkyuVdBmUhXGFnVeuoLoFQMxg9HFPd5/OfAmtFqSQFTw8EORxx+LPOrik7kSD2bzRLcOuQDs5DQZIr/JAwAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/a69e6f199c85675db3ef070121b2ae92/799d6/keras_model.png","srcSet":"/static/a69e6f199c85675db3ef070121b2ae92/799d6/keras_model.png 462w","sizes":"100vw"},"sources":[{"srcSet":"/static/a69e6f199c85675db3ef070121b2ae92/00990/keras_model.webp 462w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4134199134199134}}},"author":[{"id":"Bosoek Kim","bio":"A.I. developer and robot engineer","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACLklEQVQ4y2P4TwFgoInmf//+/QWDf//+kaD5D1gDXA8ym7BmiNIvX76cOHnqzt17f/78hQsS1rx6zbqyyuqk1HRTK1tLW4fUjKzHj5/8////79+/ODVD5C5eumRoaq6tb2RkZmlp62Bt76imrVtVU4fVcgY01+YWFOsbm9k7uZpb25ta2emZWhlZWOsZmpRVVuNzNkRzT1+/mq6BsaWdq4urnYNTT3FmUUK4pJKGqpbu3bv30ByPrvnDpy+zO5o6cpNOzGm/uaz/3PyuvZPqne3tvL28Xrx8heZ49AD7++fv38Obbi1ovzi37fP22ZvbSh6tnXJndv293Wt+ga3AE9ogYz8e2vp0ec/jFX3vN059tKr/y/bZnzZO/vn8Hkwel2aw3O+vn7/sX/Zpw6R36yZ+3TH74/Y5P98++4ehE1s8g1X8fP34676ln7fNfr9p6oftc//9/kUgqtBC7u2XT++un/ywpvfz3iXvPn94/eUzpn50zRDJq88eLz577MPn9z9Pbfn/6Nq1V89nHd1z5tHdf3gCDGLw0w/v5hzbN//EgSvPnxy9f+vh+3f7b12deWTPzCN7zj66B7bgH05nb7t6fuaR3YtOHZp3fP+sY3vnndg//8SBecf3zz95cMnpw19//oQ7kAHNwV9+fF908tCcY/sWnjy44OTBhScPLTh5EKJ/IZjx8P0buBvRU9jzj+/nnTgw9/h+iGYImnscrPnUodnH9t54+RSUlsCaAQFSIZcLZuFkAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/05e3074d52e075301cf8995aefacaaf6/5f340/bosoek.png","srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/21474/bosoek.png 750w,\n/static/05e3074d52e075301cf8995aefacaaf6/5f340/bosoek.png 929w","sizes":"100vw"},"sources":[{"srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/1d102/bosoek.webp 750w,\n/static/05e3074d52e075301cf8995aefacaaf6/14d80/bosoek.webp 929w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.9913885898815931}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"","slug":"/model_Creation/"}},"primaryTag":"ml&dl"}},
    "staticQueryHashes": ["3170763342","3229353822"]}