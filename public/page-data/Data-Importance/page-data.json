{
    "componentChunkName": "component---src-templates-post-tsx",
    "path": "/Data-Importance/",
    "result": {"data":{"logo":null,"markdownRemark":{"html":"<hr>\n<h1>데이터 중요도 파악</h1>\n<p>모델의 레이블에 영향을 주는 Feature의 중요도를 <strong>Sklearn의 Permutation Importance</strong> 를 사용해 파악한다.</p>\n<ul>\n<li>\n<h3>Permutation Importance</h3>\n<p><strong>모델 예측시 가장 영향을 많이 주는 Feature를 파악하는 방법</strong></p>\n<p>모델의 훈련이 끝난 후 계산되며 <strong>모델이 특정 Feature를 안썻을때, 성능 손실에 얼마나 영향을 주는지로 그 Feature의 중요도를 파악하는 방법</strong> 이다.</p>\n<blockquote>\n<p>어떤 모델이든 적용 가능하다!</p>\n</blockquote>\n</li>\n<li>\n<h3>Permutation Importance의 장점</h3>\n<p>기존에는 특정 Feature를 제거후 모델을 학습해서 중요도를 파악했지만 자원 소모가 너무 크다.</p>\n<p>때문에 Permutation Importance는 <strong>특정 Feature를 무작위로 섞어 Target과의 연결 고리를 끊어 해당 Feature를 안쓰는 것처럼(노이즈)</strong> 만든다.</p>\n<p>그후 예측값과 실제값의 차이가 더 생겼는지로 해당 Feature의 영향력을 파악한다.</p>\n<p>이러한 과정 덕분에 <strong>모델의 재학습이 필요없다!</strong></p>\n<blockquote>\n<p>훈련 모델과 데이터만 있으면 변수 중요도를 봅을 수 있다. 반대로 모델 학습 과정, 내부 구조 정보가 필요 없어서 어느 모델이든 적용 가능하다.</p>\n</blockquote>\n<h4><strong>Permutation Importance의 다른 특징은 각 Feature의 중요도에는 다른 Feature와의 상호작용도 포함된다는 것이다!</strong></h4>\n<p><code class=\"language-text\">특정 Feature를 섞으면 다른 Feature와의 관계가 끝어져서 해당 Feature와의 모든 상호작용이 사라진다. 때문에 두 Feature간 상호작용의 영향은 두개의 Feature Importance에 중복 포함된다.</code></p>\n</li>\n<li>\n<h3>Permutation Importance의 단점</h3>\n<ul>\n<li>\n<p>특정 Feature를 무작위로 섞어서 실행시마다 Feature Importance 결과가 달라진다.</p>\n<blockquote>\n<p>섞는 횟수를 늘려 예측 에러 분산을 감소할 수 있지만 Feature 개수가 많을 경우 연살량이 증가하기 때문에 Permutation의 적절한 회수를 선택해야한다.</p>\n</blockquote>\n</li>\n<li>\n<p>Feature를 무작위로 섞기에 비현실저인 데이터 조합이 생길 수 있다.</p>\n<blockquote>\n<p>Feature간 상관관계가 높을 경우 발샐할 수 있으며 이런 데이터의 비개연성, 비현실성이 증가하면 예측값에 영향을 미칠 가능성이 있고 우리가 원하던 결과가 아니기에 이를 염두하고 해석해야한다.</p>\n</blockquote>\n<p>예로, 키와 몸무게를 랜덤하게 섞다보면 키가 2m인데 몸무게가 30kg인 데이터가 만들어 질 수도 있다.</p>\n</li>\n</ul>\n</li>\n<li>\n<h3>실행 코드</h3>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">from sklearn.inspection import permutation_importance # sklearn 22 버전부터 해당\r\nfrom sklearn.metrics import make_scorer\r\n\r\n# MAPE\r\ndef mean_absolute_percentage_error(y_test, y_pred):\r\n    y_test, y_pred = np.array(y_test), np.array(y_pred)\r\n    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\r\n\r\n# fix_model : 훈련된 모델\r\n# X_train : 훈련데이터 Feature\r\n# y_train : 훈련데이터 Target\r\n# scoring : Feature 를 Shuffler 한 뒤, 예측값과 실제값을 어떤 Metric 을 사용해 비교할지\r\n# n_repeats : 특정 Feature 를 몇번 Shuffle 할 것인지\r\n# random_state : 난수 고정\r\nresult = permutation_importance(fix_model, X_train, y_train, scoring = make_scorer(mean_absolute_percentage_error,greater_is_better=False),\r\n                            n_repeats=30,\r\n                            random_state=0)\r\n# Feature label\r\nFeature = train[['lr','lc','rc','ld','rd','lnnz','rnnz','lr*lc','lc*rc','lr*rc']] \r\n\r\n# Feature 중요도를 오름차순으로 정렬한 뒤, 해당 Feature 의 index 를 저장\r\nsorted_result = result.importances_mean.argsort()\r\n\r\n# 결과를 DataFrame 화\r\nimportances = pd.DataFrame(result.importances_mean[sorted_result], index=Feature.columns[sorted_result]).sort_values(0, ascending=False)   \r\nimportances</code></pre></div>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"hr","properties":{},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"데이터 중요도 파악"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"모델의 레이블에 영향을 주는 Feature의 중요도를 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Sklearn의 Permutation Importance"}]},{"type":"text","value":" 를 사용해 파악한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Permutation Importance"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"모델 예측시 가장 영향을 많이 주는 Feature를 파악하는 방법"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"모델의 훈련이 끝난 후 계산되며 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"모델이 특정 Feature를 안썻을때, 성능 손실에 얼마나 영향을 주는지로 그 Feature의 중요도를 파악하는 방법"}]},{"type":"text","value":" 이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"어떤 모델이든 적용 가능하다!"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Permutation Importance의 장점"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"기존에는 특정 Feature를 제거후 모델을 학습해서 중요도를 파악했지만 자원 소모가 너무 크다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"때문에 Permutation Importance는 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"특정 Feature를 무작위로 섞어 Target과의 연결 고리를 끊어 해당 Feature를 안쓰는 것처럼(노이즈)"}]},{"type":"text","value":" 만든다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그후 예측값과 실제값의 차이가 더 생겼는지로 해당 Feature의 영향력을 파악한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이러한 과정 덕분에 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"모델의 재학습이 필요없다!"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"훈련 모델과 데이터만 있으면 변수 중요도를 봅을 수 있다. 반대로 모델 학습 과정, 내부 구조 정보가 필요 없어서 어느 모델이든 적용 가능하다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h4","properties":{},"children":[{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Permutation Importance의 다른 특징은 각 Feature의 중요도에는 다른 Feature와의 상호작용도 포함된다는 것이다!"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"특정 Feature를 섞으면 다른 Feature와의 관계가 끝어져서 해당 Feature와의 모든 상호작용이 사라진다. 때문에 두 Feature간 상호작용의 영향은 두개의 Feature Importance에 중복 포함된다."}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Permutation Importance의 단점"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"특정 Feature를 무작위로 섞어서 실행시마다 Feature Importance 결과가 달라진다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"섞는 횟수를 늘려 예측 에러 분산을 감소할 수 있지만 Feature 개수가 많을 경우 연살량이 증가하기 때문에 Permutation의 적절한 회수를 선택해야한다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Feature를 무작위로 섞기에 비현실저인 데이터 조합이 생길 수 있다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Feature간 상관관계가 높을 경우 발샐할 수 있으며 이런 데이터의 비개연성, 비현실성이 증가하면 예측값에 영향을 미칠 가능성이 있고 우리가 원하던 결과가 아니기에 이를 염두하고 해석해야한다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"예로, 키와 몸무게를 랜덤하게 섞다보면 키가 2m인데 몸무게가 30kg인 데이터가 만들어 질 수도 있다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"실행 코드"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"text"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-text"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"from sklearn.inspection import permutation_importance # sklearn 22 버전부터 해당\nfrom sklearn.metrics import make_scorer\n\n# MAPE\ndef mean_absolute_percentage_error(y_test, y_pred):\n    y_test, y_pred = np.array(y_test), np.array(y_pred)\n    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n\n# fix_model : 훈련된 모델\n# X_train : 훈련데이터 Feature\n# y_train : 훈련데이터 Target\n# scoring : Feature 를 Shuffler 한 뒤, 예측값과 실제값을 어떤 Metric 을 사용해 비교할지\n# n_repeats : 특정 Feature 를 몇번 Shuffle 할 것인지\n# random_state : 난수 고정\nresult = permutation_importance(fix_model, X_train, y_train, scoring = make_scorer(mean_absolute_percentage_error,greater_is_better=False),\n                            n_repeats=30,\n                            random_state=0)\n# Feature label\nFeature = train[['lr','lc','rc','ld','rd','lnnz','rnnz','lr*lc','lc*rc','lr*rc']] \n\n# Feature 중요도를 오름차순으로 정렬한 뒤, 해당 Feature 의 index 를 저장\nsorted_result = result.importances_mean.argsort()\n\n# 결과를 DataFrame 화\nimportances = pd.DataFrame(result.importances_mean[sorted_result], index=Feature.columns[sorted_result]).sort_values(0, ascending=False)   \nimportances"}]}]}]}],"data":{"quirksMode":false}},"excerpt":"데이터 중요도 파악 모델의 레이블에 영향을 주는 Feature의 중요도를 Sklearn의 Permutation Importance 를 사용해 파악한다. Permutation Importance 모델 예측시 가장 영향을 많이 주는 Feature…","fields":{"readingTime":{"text":"5 min read"}},"frontmatter":{"title":"데이터 중요도 파악","userDate":"20 August 2021","date":"2021-08-20T10:00:00.000Z","tags":["substack","django"],"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#d8d8d8","images":{"fallback":{"src":"/static/77f233d69942df62a648b0e73584df2c/bc15a/data_importance.png","srcSet":"/static/77f233d69942df62a648b0e73584df2c/bc15a/data_importance.png 560w","sizes":"100vw"},"sources":[{"srcSet":"/static/77f233d69942df62a648b0e73584df2c/6de64/data_importance.webp 560w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5589285714285714}}},"author":[{"id":"Bosoek Kim","bio":"A.I. developer and robot engineer","avatar":{"children":[{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/05e3074d52e075301cf8995aefacaaf6/f1874/bosoek.png","srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/f31ef/bosoek.png 40w,\n/static/05e3074d52e075301cf8995aefacaaf6/8f5cc/bosoek.png 80w,\n/static/05e3074d52e075301cf8995aefacaaf6/f1874/bosoek.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/e73fe/bosoek.webp 40w,\n/static/05e3074d52e075301cf8995aefacaaf6/3e808/bosoek.webp 80w,\n/static/05e3074d52e075301cf8995aefacaaf6/4fcad/bosoek.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.9916666666666667}}]}}]}},"relatedPosts":{"totalCount":6,"edges":[{"node":{"id":"cf64aef6-0e3e-58b2-9a43-b0887413545e","excerpt":"Flask 개발 환경 구축하기 파이썬 설치를 전제로 한다. 1. 가상 환경 생성하기 파이썬 가상환경은 파이썬 프로젝트시 독립된 환경을 만들어준다.(상황에 따라 가상환경에서 하나의 데스크톱에 다른 버전의 파이썬을 설치할 수 도 있다.) cmd…","frontmatter":{"title":"Flask 개발 환경 구축하기","date":"2021-09-13T10:00:00.000Z"},"fields":{"readingTime":{"text":"3 min read"},"slug":"/flask_Setting/"}}},{"node":{"id":"93c89dc3-51b0-50e7-bc4f-5f9032d76abb","excerpt":"VSCode에서 Jupyter notebook 사용하기 Machine Learning을 공부하는 사람들 이라면 대부분이 처음에 Jupyter Notebook(Lab)을 접할테지만 자동완성, 다크모드 등을 지원하는 코랩과는 다르게 원조인 Jupyter…","frontmatter":{"title":"VSCode에서 Jupyter notebook 사용하기","date":"2021-08-22T10:00:00.000Z"},"fields":{"readingTime":{"text":"3 min read"},"slug":"/vscode_jupyter/"}}},{"node":{"id":"a8d4aace-eb70-5123-8e62-fdc1394c54ad","excerpt":"Django 개발 환경 구축하기 파이썬 설치를 전제로 한다. 1. 가상 환경 생성하기 파이썬 가상환경은 파이썬 프로젝트시 독립된 환경을 만들어준다.(상황에 따라 가상환경에서 하나의 데스크톱에 다른 버전의 파이썬을 설치할 수 도 있다.) cmd…","frontmatter":{"title":"Django 개발 환경 구축하기","date":"2021-08-20T10:00:00.000Z"},"fields":{"readingTime":{"text":"5 min read"},"slug":"/Django_Setting/"}}},{"node":{"id":"d435d9e2-c988-5d5e-bfe6-27b74f94d90a","excerpt":"Keras 모델 생성 방법 케라스의 구현 방식에는 Sequential API, Functional API, Subclassing API 총 3가지 구현 방식이 존재합니다.  1. Sequential API를 사용한 모델 생성 Sequential…","frontmatter":{"title":"Keras 모델 생성 방법","date":"2021-08-20T10:00:00.000Z"},"fields":{"readingTime":{"text":"3 min read"},"slug":"/model_Creation/"}}},{"node":{"id":"d48e4886-ae48-5c6f-99d7-4dbe38a6f7f2","excerpt":"데이터 중요도 파악 모델의 레이블에 영향을 주는 Feature의 중요도를 Sklearn의 Permutation Importance 를 사용해 파악한다. Permutation Importance 모델 예측시 가장 영향을 많이 주는 Feature…","frontmatter":{"title":"데이터 중요도 파악","date":"2021-08-20T10:00:00.000Z"},"fields":{"readingTime":{"text":"5 min read"},"slug":"/Data-Importance/"}}}]}},"pageContext":{"slug":"/Data-Importance/","prev":{"excerpt":"Keras 모델 생성 방법 케라스의 구현 방식에는 Sequential API, Functional API, Subclassing API 총 3가지 구현 방식이 존재합니다.  1. Sequential API를 사용한 모델 생성 Sequential…","frontmatter":{"title":"Keras 모델 생성 방법","tags":["substack","django"],"date":"2021-08-20T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAABlklEQVQoz3WQ3U8TQRTF97/zwUSJb0Qf/OAjERGCFv4NYxBQjNJSKm15aRN4AmqsFGlIhX4NuzxoMZKa0C0KXVp2dn5kt2wpCZ7JyZ0795ybe0fjEso9qk0vV4pUap211VW+ZbNsbmZIJhKk0+lO3dMqrkHzC92N/LstJea/BvVTC/PEwmo2UY7s6Lr1PjXHUcguOl4BGi0bs9GiaTue0X0/tlqcnNm4Htcsb/Bq3ADpSJSSndyfxv+cc2nzP2jbP+okv1dJ5NoMZ34Rzx6yvPOHZK5K7me9PaGjyB8ck9k3Ses1VnarfBZHbOybfDVqbBg1fpsW2khEcGcyz/OIYGhBMBwRjHzaYyhc5vbrXcbjutfQXbX3bZ7edwX6gyUGQiX6giX6g2WeLQhuvdphar2C5prvTRd5GhYeB+fLDM4LBkKCu28KTCwZ3pp/rXPuzxboCwlexHTGYvplNAjEDXqmCkyuVdBmUhXGFnVeuoLoFQMxg9HFPd5/OfAmtFqSQFTw8EORxx+LPOrik7kSD2bzRLcOuQDs5DQZIr/JAwAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/a69e6f199c85675db3ef070121b2ae92/799d6/keras_model.png","srcSet":"/static/a69e6f199c85675db3ef070121b2ae92/799d6/keras_model.png 462w","sizes":"100vw"},"sources":[{"srcSet":"/static/a69e6f199c85675db3ef070121b2ae92/00990/keras_model.webp 462w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4134199134199134}}},"author":[{"id":"Bosoek Kim","bio":"A.I. developer and robot engineer","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACLklEQVQ4y2P4TwFgoInmf//+/f3799+/f6RpRtPzDwyI1QxR+uXLl5OnTt+9d//v378k2Lxm3fryqprktEwzK1srO8e0zJzHT55AXIRTM0Tu4qVLhqYW2gYmRmaWFjb21naO6lq6lTV1cBdh1wyRyy8s0TMytXN0MbO2M7Wy1TO1MjS31jM0Ka+sxudsiOaevgnquoYmVnZurm72js49xRlFCeGSSupqWnp3791Dczy65g+fvszuaOzITTo+u+3G0r5z87v2Tqp3sbfz8fJ68fIVmuPRA+zvn79/D2+6taDt4ry2z9tnbWkvebR2yu1ZdXd3r/4FtgJPaIOM/Xh427MVPY9X9n3YOPXhyv4v22d/2jjl1/N7MHlcmsFyv79+/nJg+ecNk96tm/htx+yP2+f8fPvsP4a12OIZrP/n6ydf9y/7vH32h01TP26f++/3LwJRhRZyb798enf95Ie1fV/2Lnn3+ePrL58xrUbXDJG++uzx4rPHPnx+//PUlv+Prl179XzW0T2nH939hyfAIHY+/fBuzrF9808cuPL8ydF7tx6+f7f/1tWZR/bMPLrn7KN7YAv+4XT2tqvnZxzZvejUoXkn9s86tnfeiQPzTxyYdxxk3JLTh7/+/AF3IAOag7/8+LHo5KE5x/YtPHlwwcmDC08eWnDy4LwT++efOLDw5MG5J/Y/fP8G7kb0FPb84/t5Jw7MPb4fohmC5h4Haz51aPaxvTdePgWlJbBmALPEIdAkOi/aAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/05e3074d52e075301cf8995aefacaaf6/5f340/bosoek.png","srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/21474/bosoek.png 750w,\n/static/05e3074d52e075301cf8995aefacaaf6/5f340/bosoek.png 929w","sizes":"100vw"},"sources":[{"srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/1d102/bosoek.webp 750w,\n/static/05e3074d52e075301cf8995aefacaaf6/14d80/bosoek.webp 929w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.9913885898815931}}}}]},"fields":{"readingTime":{"text":"3 min read"},"layout":"","slug":"/model_Creation/"}},"next":{"excerpt":"분류 모델 성능 평가 지표 분류 모델을 만들고 나면 분류기의 예측력을 검증해야 한다. 그럼 이때 정답을 맞히거나 틀리는 경우들이 뭐가 있을까? 이때 생기는 개념이 1종 오류, 2종 오류이며 각 오류는 분류 과제 성격에 따라 검증이 다르다.…","frontmatter":{"title":"분류 모델 성능 평가 지표","tags":["substack","django"],"date":"2021-08-20T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABl0lEQVQoz22QfW/aMBCH+f6fCIlmSA0wNZaNSAJJznZsHNvhJUtIoYw1SzKtTKylff4431l+dD950L+jbdtr7bqu/4rujds4uF71fV8Uhed5hJDxeIwQwhgTQgDAdd3hcEgIwRjneX57/0++cj6fpZRCCK01QmgymSCEgiDAGDuOgxAihKxWq8vl8mHzHW3b2jwXQizDEACklNZaAFgsFsYYIcS93DSN1toYY61VSs1mM9d1HcfxvKe/zcPDaDRyHx+n02kQBLfkg+tRliVjLMsyKaXWJknifVUH6/3ucOKMGmMT/WOpirquKaX/N1/lqqo451EUxXHMON/mdvfyO9z92vzsN3leHI7iuY+L13PTyfexb1+NMeacM8aiKEaet1bZtzlNhCYEU0jmsJ76LMtUFEX3clmWaZoqpdI01VpTSrflcS4LW70Ikdp8q4pjYqvn44lz/kXs8A0AiONYqbWqG2zO2anXxtriEO4bf3M5vvbpZ7mua9/3AYBzDgCB70ulvocURLZaLhmjK7Z+ClmmlJTyJv8B9IRYC7pcuiAAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/0c8989e5082dad4a67acb7a1c50465cf/2d99a/confusion_matrix.png","srcSet":"/static/0c8989e5082dad4a67acb7a1c50465cf/2d99a/confusion_matrix.png 431w","sizes":"100vw"},"sources":[{"srcSet":"/static/0c8989e5082dad4a67acb7a1c50465cf/d8b57/confusion_matrix.webp 431w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5614849187935035}}},"author":[{"id":"Bosoek Kim","bio":"A.I. developer and robot engineer","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACLklEQVQ4y2P4TwFgoInmf//+/f3799+/f6RpRtPzDwyI1QxR+uXLl5OnTt+9d//v378k2Lxm3fryqprktEwzK1srO8e0zJzHT55AXIRTM0Tu4qVLhqYW2gYmRmaWFjb21naO6lq6lTV1cBdh1wyRyy8s0TMytXN0MbO2M7Wy1TO1MjS31jM0Ka+sxudsiOaevgnquoYmVnZurm72js49xRlFCeGSSupqWnp3791Dczy65g+fvszuaOzITTo+u+3G0r5z87v2Tqp3sbfz8fJ68fIVmuPRA+zvn79/D2+6taDt4ry2z9tnbWkvebR2yu1ZdXd3r/4FtgJPaIOM/Xh427MVPY9X9n3YOPXhyv4v22d/2jjl1/N7MHlcmsFyv79+/nJg+ecNk96tm/htx+yP2+f8fPvsP4a12OIZrP/n6ydf9y/7vH32h01TP26f++/3LwJRhRZyb798enf95Ie1fV/2Lnn3+ePrL58xrUbXDJG++uzx4rPHPnx+//PUlv+Prl179XzW0T2nH939hyfAIHY+/fBuzrF9808cuPL8ydF7tx6+f7f/1tWZR/bMPLrn7KN7YAv+4XT2tqvnZxzZvejUoXkn9s86tnfeiQPzTxyYdxxk3JLTh7/+/AF3IAOag7/8+LHo5KE5x/YtPHlwwcmDC08eWnDy4LwT++efOLDw5MG5J/Y/fP8G7kb0FPb84/t5Jw7MPb4fohmC5h4Haz51aPaxvTdePgWlJbBmALPEIdAkOi/aAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/05e3074d52e075301cf8995aefacaaf6/5f340/bosoek.png","srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/21474/bosoek.png 750w,\n/static/05e3074d52e075301cf8995aefacaaf6/5f340/bosoek.png 929w","sizes":"100vw"},"sources":[{"srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/1d102/bosoek.webp 750w,\n/static/05e3074d52e075301cf8995aefacaaf6/14d80/bosoek.webp 929w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.9913885898815931}}}}]},"fields":{"readingTime":{"text":"5 min read"},"layout":"","slug":"/Classification-performance-evaluation/"}},"primaryTag":"substack"}},
    "staticQueryHashes": []}