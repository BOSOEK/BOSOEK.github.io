{
    "componentChunkName": "component---src-templates-post-tsx",
    "path": "/Data-Importance/",
    "result": {"data":{"logo":null,"markdownRemark":{"html":"<hr>\n<h1>데이터 중요도 파악(Permutation Importance)</h1>\n<p>모델의 레이블에 영향을 주는 Feature의 중요도를 <strong>Sklearn의 Permutation Importance</strong> 를 사용해 파악한다.</p>\n<ul>\n<li>\n<h3>Permutation Importance</h3>\n<p><strong>모델 예측시 가장 영향을 많이 주는 Feature를 파악하는 방법</strong></p>\n<p>모델의 훈련이 끝난 후 계산되며 <strong>모델이 특정 Feature를 안썻을때, 성능 손실에 얼마나 영향을 주는지로 그 Feature의 중요도를 파악하는 방법</strong> 이다.</p>\n<blockquote>\n<p>어떤 모델이든 적용 가능하다!</p>\n</blockquote>\n</li>\n<li>\n<h3>Permutation Importance의 장점</h3>\n<p>기존에는 특정 Feature를 제거후 모델을 학습해서 중요도를 파악했지만 자원 소모가 너무 크다.</p>\n<p>때문에 Permutation Importance는 <strong>특정 Feature를 무작위로 섞어 Target과의 연결 고리를 끊어 해당 Feature를 안쓰는 것처럼(노이즈)</strong> 만든다.</p>\n<p>그후 예측값과 실제값의 차이가 더 생겼는지로 해당 Feature의 영향력을 파악한다.</p>\n<p>이러한 과정 덕분에 <strong>모델의 재학습이 필요없다!</strong></p>\n<blockquote>\n<p>훈련 모델과 데이터만 있으면 변수 중요도를 뽑을 수 있다. 반대로 모델 학습 과정, 내부 구조 정보가 필요 없어서 어느 모델이든 적용 가능하다.</p>\n</blockquote>\n<h4><strong>Permutation Importance의 다른 특징은 각 Feature의 중요도에는 다른 Feature와의 상호작용도 포함된다는 것이다!</strong></h4>\n<p><code class=\"language-text\">특정 Feature를 섞으면 다른 Feature와의 관계가 끝어져서 해당 Feature와의 모든 상호작용이 사라진다. 때문에 두 Feature간 상호작용의 영향은 두개의 Feature Importance에 중복 포함된다.</code></p>\n</li>\n<li>\n<h3>Permutation Importance의 단점</h3>\n<ul>\n<li>\n<p>특정 Feature를 무작위로 섞어서 실행시마다 Feature Importance 결과가 달라진다.</p>\n<blockquote>\n<p>섞는 횟수를 늘려 예측 에러 분산을 감소할 수 있지만 Feature 개수가 많을 경우 연살량이 증가하기 때문에 Permutation의 적절한 회수를 선택해야한다.</p>\n</blockquote>\n</li>\n<li>\n<p>Feature를 무작위로 섞기에 비현실적인 데이터 조합이 생길 수 있다.</p>\n<blockquote>\n<p>Feature간 상관관계가 높을 경우 발샐할 수 있으며 이런 데이터의 비개연성, 비현실성이 증가하면 예측값에 영향을 미칠 가능성이 있고 우리가 원하던 결과가 아니기에 이를 염두하고 해석해야한다.</p>\n</blockquote>\n<p>예로, 키와 몸무게를 랜덤하게 섞다보면 키가 2m인데 몸무게가 30kg인 데이터가 만들어 질 수도 있다.</p>\n</li>\n</ul>\n</li>\n<li>\n<h3>실행 코드</h3>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">from sklearn.inspection import permutation_importance # sklearn 22 버전부터 해당\r\nfrom sklearn.metrics import make_scorer\r\n\r\n# MAPE\r\ndef mean_absolute_percentage_error(y_test, y_pred):\r\n    y_test, y_pred = np.array(y_test), np.array(y_pred)\r\n    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\r\n\r\n# fix_model : 훈련된 모델\r\n# X_train : 훈련데이터 Feature\r\n# y_train : 훈련데이터 Target\r\n# scoring : Feature 를 Shuffler 한 뒤, 예측값과 실제값을 어떤 Metric 을 사용해 비교할지\r\n# n_repeats : 특정 Feature 를 몇번 Shuffle 할 것인지\r\n# random_state : 난수 고정\r\nresult = permutation_importance(fix_model, X_train, y_train, scoring = make_scorer(mean_absolute_percentage_error,greater_is_better=False),\r\n                            n_repeats=30,\r\n                            random_state=0)\r\n# Feature label\r\nFeature = train[['lr','lc','rc','ld','rd','lnnz','rnnz','lr*lc','lc*rc','lr*rc']] \r\n\r\n# Feature 중요도를 오름차순으로 정렬한 뒤, 해당 Feature 의 index 를 저장\r\nsorted_result = result.importances_mean.argsort()\r\n\r\n# 결과를 DataFrame 화\r\nimportances = pd.DataFrame(result.importances_mean[sorted_result], index=Feature.columns[sorted_result]).sort_values(0, ascending=False)   \r\nimportances</code></pre></div>\n<hr>\n<blockquote>\n<h3>만약 인간의 뇌가 우리가 이해할 수 있을 정도로 단순하다면,</h3>\n<p>if the human brain was simple enough for us to understand,</p>\n<h3>우리는 그렇게 단순할 수 없을 것이다. -에머슨 M.푸(Emerson M. Pooh)</h3>\n<p>we wouldn’t be that simple.</p>\n</blockquote>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"hr","properties":{},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"데이터 중요도 파악(Permutation Importance)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"모델의 레이블에 영향을 주는 Feature의 중요도를 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Sklearn의 Permutation Importance"}]},{"type":"text","value":" 를 사용해 파악한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Permutation Importance"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"모델 예측시 가장 영향을 많이 주는 Feature를 파악하는 방법"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"모델의 훈련이 끝난 후 계산되며 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"모델이 특정 Feature를 안썻을때, 성능 손실에 얼마나 영향을 주는지로 그 Feature의 중요도를 파악하는 방법"}]},{"type":"text","value":" 이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"어떤 모델이든 적용 가능하다!"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Permutation Importance의 장점"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"기존에는 특정 Feature를 제거후 모델을 학습해서 중요도를 파악했지만 자원 소모가 너무 크다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"때문에 Permutation Importance는 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"특정 Feature를 무작위로 섞어 Target과의 연결 고리를 끊어 해당 Feature를 안쓰는 것처럼(노이즈)"}]},{"type":"text","value":" 만든다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그후 예측값과 실제값의 차이가 더 생겼는지로 해당 Feature의 영향력을 파악한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이러한 과정 덕분에 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"모델의 재학습이 필요없다!"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"훈련 모델과 데이터만 있으면 변수 중요도를 뽑을 수 있다. 반대로 모델 학습 과정, 내부 구조 정보가 필요 없어서 어느 모델이든 적용 가능하다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h4","properties":{},"children":[{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Permutation Importance의 다른 특징은 각 Feature의 중요도에는 다른 Feature와의 상호작용도 포함된다는 것이다!"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"특정 Feature를 섞으면 다른 Feature와의 관계가 끝어져서 해당 Feature와의 모든 상호작용이 사라진다. 때문에 두 Feature간 상호작용의 영향은 두개의 Feature Importance에 중복 포함된다."}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Permutation Importance의 단점"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"특정 Feature를 무작위로 섞어서 실행시마다 Feature Importance 결과가 달라진다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"섞는 횟수를 늘려 예측 에러 분산을 감소할 수 있지만 Feature 개수가 많을 경우 연살량이 증가하기 때문에 Permutation의 적절한 회수를 선택해야한다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Feature를 무작위로 섞기에 비현실적인 데이터 조합이 생길 수 있다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Feature간 상관관계가 높을 경우 발샐할 수 있으며 이런 데이터의 비개연성, 비현실성이 증가하면 예측값에 영향을 미칠 가능성이 있고 우리가 원하던 결과가 아니기에 이를 염두하고 해석해야한다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"예로, 키와 몸무게를 랜덤하게 섞다보면 키가 2m인데 몸무게가 30kg인 데이터가 만들어 질 수도 있다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"실행 코드"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"text"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-text"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"from sklearn.inspection import permutation_importance # sklearn 22 버전부터 해당\nfrom sklearn.metrics import make_scorer\n\n# MAPE\ndef mean_absolute_percentage_error(y_test, y_pred):\n    y_test, y_pred = np.array(y_test), np.array(y_pred)\n    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n\n# fix_model : 훈련된 모델\n# X_train : 훈련데이터 Feature\n# y_train : 훈련데이터 Target\n# scoring : Feature 를 Shuffler 한 뒤, 예측값과 실제값을 어떤 Metric 을 사용해 비교할지\n# n_repeats : 특정 Feature 를 몇번 Shuffle 할 것인지\n# random_state : 난수 고정\nresult = permutation_importance(fix_model, X_train, y_train, scoring = make_scorer(mean_absolute_percentage_error,greater_is_better=False),\n                            n_repeats=30,\n                            random_state=0)\n# Feature label\nFeature = train[['lr','lc','rc','ld','rd','lnnz','rnnz','lr*lc','lc*rc','lr*rc']] \n\n# Feature 중요도를 오름차순으로 정렬한 뒤, 해당 Feature 의 index 를 저장\nsorted_result = result.importances_mean.argsort()\n\n# 결과를 DataFrame 화\nimportances = pd.DataFrame(result.importances_mean[sorted_result], index=Feature.columns[sorted_result]).sort_values(0, ascending=False)   \nimportances"}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"hr","properties":{},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"만약 인간의 뇌가 우리가 이해할 수 있을 정도로 단순하다면,"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"if the human brain was simple enough for us to understand,"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"우리는 그렇게 단순할 수 없을 것이다. -에머슨 M.푸(Emerson M. Pooh)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"we wouldn’t be that simple."}]},{"type":"text","value":"\n"}]}],"data":{"quirksMode":false}},"excerpt":"데이터 중요도 파악(Permutation Importance) 모델의 레이블에 영향을 주는 Feature의 중요도를 Sklearn의 Permutation Importance 를 사용해 파악한다. Permutation Importance…","fields":{"readingTime":{"text":"5 min read"}},"frontmatter":{"title":"데이터 중요도 파악(Permutation Importance)","userDate":"9 May 2021","date":"2021-05-09T10:00:00.000Z","tags":["ml&dl"],"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#d8d8d8","images":{"fallback":{"src":"/static/77f233d69942df62a648b0e73584df2c/bc15a/data_importance.png","srcSet":"/static/77f233d69942df62a648b0e73584df2c/bc15a/data_importance.png 560w","sizes":"100vw"},"sources":[{"srcSet":"/static/77f233d69942df62a648b0e73584df2c/6de64/data_importance.webp 560w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5589285714285714}}},"author":[{"id":"Bosoek Kim","bio":"A.I. developer and robot engineer","avatar":{"children":[{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/05e3074d52e075301cf8995aefacaaf6/f1874/bosoek.png","srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/f31ef/bosoek.png 40w,\n/static/05e3074d52e075301cf8995aefacaaf6/8f5cc/bosoek.png 80w,\n/static/05e3074d52e075301cf8995aefacaaf6/f1874/bosoek.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/e73fe/bosoek.webp 40w,\n/static/05e3074d52e075301cf8995aefacaaf6/3e808/bosoek.webp 80w,\n/static/05e3074d52e075301cf8995aefacaaf6/4fcad/bosoek.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.9916666666666667}}]}}]}},"relatedPosts":{"totalCount":7,"edges":[{"node":{"id":"21c67e3d-9650-5d9c-a621-7a0a0f0f4cd6","excerpt":"GAN으로 우주 사진 생성하기 고인물은 언젠가 썩기 마련이야 그래서 우리는 계속 흘러야만해 -성찬우","frontmatter":{"title":"GAN으로 우주 사진 생성하기","date":"2022-01-30T10:00:00.000Z"},"fields":{"readingTime":{"text":"1 min read"},"slug":"/space_image/"}}},{"node":{"id":"aeb8f9c8-4c45-5fe5-8cf6-8500b7357c3b","excerpt":"Klue Baseline 새로이 블로그를 정리하며 이전에 참여했던 말은 쉽지, 코드를 보여줘. -리누스 토르발스(Linus Torvalds) Talk is cheap. Show me the code.","frontmatter":{"title":"Klue Baseline","date":"2021-09-15T10:00:00.000Z"},"fields":{"readingTime":{"text":"1 min read"},"slug":"/klue_baseline/"}}},{"node":{"id":"e890a7b7-7d3e-5847-be74-445f60f20891","excerpt":"Numpy 튜토리얼 넘파이는 벡터(1차원 배열), 행렬(2차원 배열) 등 수치 연산을 하는 선형 대수(Linear algebra) 라이브러리이다. 목차 1. 기초개념 2. 행렬 변경 3. 데이터 복사 기초 개념 Numpy…","frontmatter":{"title":"Numpy 튜토리얼","date":"2021-08-20T10:00:00.000Z"},"fields":{"readingTime":{"text":"6 min read"},"slug":"/Numpy/"}}},{"node":{"id":"ebd7fc58-fd9f-5db8-aab5-0238ca74eab6","excerpt":"Matplotlib 튜토리얼 Matplotlib은 파이썬 기반 그래프(플롯) 시각화 라이브러리이다.\r\nmatplotlib.pyplot 모듈의 각각의 함수로 그래프를 만들고 변화를 줄수 있다. 목차 1. 기본 그래프 2. 축 레이블 및 범위 설정…","frontmatter":{"title":"Matplotlib 튜토리얼","date":"2021-08-20T10:00:00.000Z"},"fields":{"readingTime":{"text":"18 min read"},"slug":"/matplotlib/"}}},{"node":{"id":"d435d9e2-c988-5d5e-bfe6-27b74f94d90a","excerpt":"Keras 모델 생성 방법(Keras models) 케라스의 구현 방식에는 Sequential API, Functional API, Subclassing API 총 3가지 구현 방식이 존재합니다. 1. Sequential API…","frontmatter":{"title":"Keras 모델 생성 방법(Keras models)","date":"2021-07-11T10:00:00.000Z"},"fields":{"readingTime":{"text":"3 min read"},"slug":"/model_Creation/"}}}]}},"pageContext":{"slug":"/Data-Importance/","prev":{"excerpt":"분류 모델 성능 평가 지표 분류 모델을 만들고 나면 분류기의 예측력을 검증해야 한다. 이때 분류 모델이 정답을 맞히거나 틀리는 경우들은 총 4가지가 생긴다. 이때 생기는 개념이 1종 오류,…","frontmatter":{"title":"분류 모델 성능 평가 지표","tags":["ml&dl"],"date":"2021-05-03T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABl0lEQVQoz22QfW/aMBCH+f6fCIlmSA0wNZaNSAJJznZsHNvhJUtIoYw1SzKtTKylff4431l+dD950L+jbdtr7bqu/4rujds4uF71fV8Uhed5hJDxeIwQwhgTQgDAdd3hcEgIwRjneX57/0++cj6fpZRCCK01QmgymSCEgiDAGDuOgxAihKxWq8vl8mHzHW3b2jwXQizDEACklNZaAFgsFsYYIcS93DSN1toYY61VSs1mM9d1HcfxvKe/zcPDaDRyHx+n02kQBLfkg+tRliVjLMsyKaXWJknifVUH6/3ucOKMGmMT/WOpirquKaX/N1/lqqo451EUxXHMON/mdvfyO9z92vzsN3leHI7iuY+L13PTyfexb1+NMeacM8aiKEaet1bZtzlNhCYEU0jmsJ76LMtUFEX3clmWaZoqpdI01VpTSrflcS4LW70Ikdp8q4pjYqvn44lz/kXs8A0AiONYqbWqG2zO2anXxtriEO4bf3M5vvbpZ7mua9/3AYBzDgCB70ulvocURLZaLhmjK7Z+ClmmlJTyJv8B9IRYC7pcuiAAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/0c8989e5082dad4a67acb7a1c50465cf/2d99a/confusion_matrix.png","srcSet":"/static/0c8989e5082dad4a67acb7a1c50465cf/2d99a/confusion_matrix.png 431w","sizes":"100vw"},"sources":[{"srcSet":"/static/0c8989e5082dad4a67acb7a1c50465cf/d8b57/confusion_matrix.webp 431w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5614849187935035}}},"author":[{"id":"Bosoek Kim","bio":"A.I. developer and robot engineer","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACLklEQVQ4y2P4TwFgoInmf//+/f3799+/f6RpRtPzDwyI1QxR+uXLl5OnTt+9d//v378k2Lxm3fryqprktEwzK1srO8e0zJzHT55AXIRTM0Tu4qVLhqYW2gYmRmaWFjb21naO6lq6lTV1cBdh1wyRyy8s0TMytXN0MbO2M7Wy1TO1MjS31jM0Ka+sxudsiOaevgnquoYmVnZurm72js49xRlFCeGSSupqWnp3791Dczy65g+fvszuaOzITTo+u+3G0r5z87v2Tqp3sbfz8fJ68fIVmuPRA+zvn79/D2+6taDt4ry2z9tnbWkvebR2yu1ZdXd3r/4FtgJPaIOM/Xh427MVPY9X9n3YOPXhyv4v22d/2jjl1/N7MHlcmsFyv79+/nJg+ecNk96tm/htx+yP2+f8fPvsP4a12OIZrP/n6ydf9y/7vH32h01TP26f++/3LwJRhRZyb798enf95Ie1fV/2Lnn3+ePrL58xrUbXDJG++uzx4rPHPnx+//PUlv+Prl179XzW0T2nH939hyfAIHY+/fBuzrF9808cuPL8ydF7tx6+f7f/1tWZR/bMPLrn7KN7YAv+4XT2tqvnZxzZvejUoXkn9s86tnfeiQPzTxyYdxxk3JLTh7/+/AF3IAOag7/8+LHo5KE5x/YtPHlwwcmDC08eWnDy4LwT++efOLDw5MG5J/Y/fP8G7kb0FPb84/t5Jw7MPb4fohmC5h4Haz51aPaxvTdePgWlJbBmALPEIdAkOi/aAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/05e3074d52e075301cf8995aefacaaf6/5f340/bosoek.png","srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/21474/bosoek.png 750w,\n/static/05e3074d52e075301cf8995aefacaaf6/5f340/bosoek.png 929w","sizes":"100vw"},"sources":[{"srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/1d102/bosoek.webp 750w,\n/static/05e3074d52e075301cf8995aefacaaf6/14d80/bosoek.webp 929w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.9913885898815931}}}}]},"fields":{"readingTime":{"text":"5 min read"},"layout":"post","slug":"/Classification-performance-evaluation/"}},"next":{"excerpt":"Keras 모델 생성 방법(Keras models) 케라스의 구현 방식에는 Sequential API, Functional API, Subclassing API 총 3가지 구현 방식이 존재합니다. 1. Sequential API…","frontmatter":{"title":"Keras 모델 생성 방법(Keras models)","tags":["ml&dl"],"date":"2021-07-11T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAABlklEQVQoz3WQ3U8TQRTF97/zwUSJb0Qf/OAjERGCFv4NYxBQjNJSKm15aRN4AmqsFGlIhX4NuzxoMZKa0C0KXVp2dn5kt2wpCZ7JyZ0795ybe0fjEso9qk0vV4pUap211VW+ZbNsbmZIJhKk0+lO3dMqrkHzC92N/LstJea/BvVTC/PEwmo2UY7s6Lr1PjXHUcguOl4BGi0bs9GiaTue0X0/tlqcnNm4Htcsb/Bq3ADpSJSSndyfxv+cc2nzP2jbP+okv1dJ5NoMZ34Rzx6yvPOHZK5K7me9PaGjyB8ck9k3Ses1VnarfBZHbOybfDVqbBg1fpsW2khEcGcyz/OIYGhBMBwRjHzaYyhc5vbrXcbjutfQXbX3bZ7edwX6gyUGQiX6giX6g2WeLQhuvdphar2C5prvTRd5GhYeB+fLDM4LBkKCu28KTCwZ3pp/rXPuzxboCwlexHTGYvplNAjEDXqmCkyuVdBmUhXGFnVeuoLoFQMxg9HFPd5/OfAmtFqSQFTw8EORxx+LPOrik7kSD2bzRLcOuQDs5DQZIr/JAwAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/a69e6f199c85675db3ef070121b2ae92/799d6/keras_model.png","srcSet":"/static/a69e6f199c85675db3ef070121b2ae92/799d6/keras_model.png 462w","sizes":"100vw"},"sources":[{"srcSet":"/static/a69e6f199c85675db3ef070121b2ae92/00990/keras_model.webp 462w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4134199134199134}}},"author":[{"id":"Bosoek Kim","bio":"A.I. developer and robot engineer","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACLklEQVQ4y2P4TwFgoInmf//+/f3799+/f6RpRtPzDwyI1QxR+uXLl5OnTt+9d//v378k2Lxm3fryqprktEwzK1srO8e0zJzHT55AXIRTM0Tu4qVLhqYW2gYmRmaWFjb21naO6lq6lTV1cBdh1wyRyy8s0TMytXN0MbO2M7Wy1TO1MjS31jM0Ka+sxudsiOaevgnquoYmVnZurm72js49xRlFCeGSSupqWnp3791Dczy65g+fvszuaOzITTo+u+3G0r5z87v2Tqp3sbfz8fJ68fIVmuPRA+zvn79/D2+6taDt4ry2z9tnbWkvebR2yu1ZdXd3r/4FtgJPaIOM/Xh427MVPY9X9n3YOPXhyv4v22d/2jjl1/N7MHlcmsFyv79+/nJg+ecNk96tm/htx+yP2+f8fPvsP4a12OIZrP/n6ydf9y/7vH32h01TP26f++/3LwJRhRZyb798enf95Ie1fV/2Lnn3+ePrL58xrUbXDJG++uzx4rPHPnx+//PUlv+Prl179XzW0T2nH939hyfAIHY+/fBuzrF9808cuPL8ydF7tx6+f7f/1tWZR/bMPLrn7KN7YAv+4XT2tqvnZxzZvejUoXkn9s86tnfeiQPzTxyYdxxk3JLTh7/+/AF3IAOag7/8+LHo5KE5x/YtPHlwwcmDC08eWnDy4LwT++efOLDw5MG5J/Y/fP8G7kb0FPb84/t5Jw7MPb4fohmC5h4Haz51aPaxvTdePgWlJbBmALPEIdAkOi/aAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/05e3074d52e075301cf8995aefacaaf6/5f340/bosoek.png","srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/21474/bosoek.png 750w,\n/static/05e3074d52e075301cf8995aefacaaf6/5f340/bosoek.png 929w","sizes":"100vw"},"sources":[{"srcSet":"/static/05e3074d52e075301cf8995aefacaaf6/1d102/bosoek.webp 750w,\n/static/05e3074d52e075301cf8995aefacaaf6/14d80/bosoek.webp 929w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.9913885898815931}}}}]},"fields":{"readingTime":{"text":"3 min read"},"layout":"","slug":"/model_Creation/"}},"primaryTag":"ml&dl"}},
    "staticQueryHashes": ["3170763342","3229353822"]}