{
    "componentChunkName": "component---src-templates-post-tsx",
    "path": "/attention/",
    "result": {"data":{"logo":null,"markdownRemark":{"html":"<h1>Attention</h1>\n<p>본 포스팅을 이해하기 위해서는 다음 글에 대한 이해가 선행되는 것이 좋습니다.</p>\n<ul>\n<li><a href=\"https://sooftware.io/rnn/\">RNN (Recurrent Neural Network)</a></li>\n<li><a href=\"https://sooftware.io/lstm_gru/\">LSTM &#x26; GRU (Long Short Term Memory &#x26; Gated Recurrent Unit)</a></li>\n<li><a href=\"https://sooftware.io/seq2seq/\">Seq2seq (sequence to sequence)</a></li>\n</ul>\n<hr>\n<h2>Seq2seq의 한계</h2>\n<img src=\"https://user-images.githubusercontent.com/42150335/147275988-a5eca2d8-18d0-4a23-b7f0-79ccf4c4a416.png\" width=\"500\">\n<p>기본적인 Seq2seq 모델은 간단한 구조라는 장점이 있었지만, 크게 2가지의 문제점이 존재한다.</p>\n<ol>\n<li>하나의 고정된 크기의 벡터에 모든 정보를 압축하다보니 정보 손실이 발생한다.</li>\n<li>RNN의 고질적인 문제인 <strong>Vanishing Gradient Problem</strong>이 존재한다.</li>\n</ol>\n<p>이러한 문제점들은 입력 데이터가 길어지면 성능이 크게 저하되는 현상으로 이어지게 된다. 이를 위한 기법으로 입력 데이터가 길어지더라도, 정확도가 떨어지는 것을 보정해주기 위해 등장한 방법이 <strong>어텐션(Attention)</strong> 기법이다.</p>\n<h2>Seq2seq의 문제점</h2>\n<img src=\"https://user-images.githubusercontent.com/42150335/147275994-360a8692-5525-41f3-b110-d3a0b2572271.png\" width=\"500\">  \n<p>그렇다면 Seq2seq 구조에서 어떤 부분이 문제였는지를 살펴보자. Seq2seq의 구조를 살펴보면, Encoder에서 계산한 여러 Hidden State 중 마지막 Hidden State만을 Decoder에서 사용하게 된다.</p>\n<p>즉, 마지막 Encoder의 RNN 셀의 마지막 Hidden State를 제외하고는 사용되지 않는다.</p>\n<p>어텐션 매커니즘은 바로 이 사용되지 않은 Hidden State를 이용한 아이디어이다.</p>\n<p>어텐션의 기본 아이디어는 Decoder에서 출력 결과를 예측하는 매 시점(time step)마다, Encoder의 Hidden State를 다시 한 번 참고한다는 아이디어다.</p>\n<p>그리고 이 참고하는 비율을, 해당 시점에서 예측해야하는 결과와 연관이 있는 부분을 판단하여 좀 더 집중 (Attention) 하여 본다고 하여 Attention Mechanism이라고 부른다.</p>\n<h2>Attention의 직관적인 설명</h2>\n<p>그렇다면 이 Attention Mechanism이 왜 효과가 있을지를 먼저 생각해보자.</p>\n<img src=\"https://user-images.githubusercontent.com/42150335/147276029-26d22b53-0045-4794-ae20-fd8d907e81dc.png\" width=\"300\">\n<p>위와 같은 영어 문제가 있다고 해보자. 우리는 위의 영어 문제를 해석할 때, 처음부터 끝까지 혹은, 처음부터 한 문장이 끝날 때까지 모두 읽고 해석한다면 해석하기 쉽지 않을 것이다.</p>\n<img src=\"https://user-images.githubusercontent.com/42150335/147276036-a69e28bd-c039-4c0f-a9e6-1abf10dd0e9e.png\" width=\"400\">  \n<p>이 보다는 위의 □ 부분과 같이 부분부분 끊어서 해석하는 편이 더 나은 결과를 도출할 것이다.</p>\n<h3>Encoder of Seq2seq</h3>\n<img src=\"https://user-images.githubusercontent.com/42150335/147276041-b9831d3b-2971-4bd8-89b6-343372b566b6.png\" width=\"400\">  \n<p>그럼 다시 Seq2seq의 Encoder에 주목해보자. 시각별 RNN 셀의 Hidden State에는 당연히 직전에 입력된 단어에 대한 정보가 많이 포함되어 있을 것이다.</p>\n<p>예를 들면 “Sooft”라는 단어가 들어간 RNN 셀의 Hidden State는 “Sooft”의 성분이 많이들어간 벡터라고 생각할 수 있다.</p>\n<p>어텐션의 아이디어는 여기서 시작된다.</p>\n<h2>Attention Mechanism</h2>\n<img src=\"https://user-images.githubusercontent.com/42150335/147276107-8d3b8047-82be-42be-aebd-a6f1690cf050.png\" width=\"500\">  \n<p>위 그림은 디코더의 세 번째 RNN 셀에서 출력 단어를 예측할 때, 어텐션 매커니즘을 사용하는 모습이다. 그럼 어텐션 매커니즘이 어떻게 적용되는지를 살펴보자.</p>\n<h3>Attention Score</h3>\n<img src=\"https://user-images.githubusercontent.com/42150335/147276113-12444d0c-c63f-486d-a1de-c1bbea208a5b.png\" width=\"500\">  \n<p>어텐션 매커니즘은 디코더에서 출력 결과를 예측할 때, 인코더의 Hidden State들을 다시 한 번 참고해주는 방법이라고 했다.</p>\n<p>이 때 어느 인코더의 Hidden State를 얼마나 참고할지를 결정해야 한다.</p>\n<p>이 때, 현재 예측에 필요한 정도라고 판단되는 점수를 어텐션 스코어 (Attention Score)라고 한다.</p>\n<p>이러한 어텐션 스코어를 구하기 위해, 현 시점의 디코더의 Hidden State (s<sub>t</sub>)와 인코더의 모든 Hidden State들과 각각 내적을 수행한다.</p>\n<p>※ 벡터의 내적의 결과는 스칼라가 나온다 ※</p>\n<h3>Attention Distribution</h3>\n<img src=\"https://user-images.githubusercontent.com/42150335/147276123-ad9bf1a0-60fa-4fab-a32e-dedd08e132a2.png\" width=\"400\">  \n<p>앞에서 각 인코더와 디코더의 현재 Hidden State를 내적한 값은 스칼라로 나오기 때문에 이를 소프트맥스 함수를 적용해서 어텐션 분포를 구한다.</p>\n<p>※ 소프트맥스 함수는 입력받는 값을 모두 0 ~ 1 사이의 값으로 정규화하며 총합은 항상 1이 된다 ※</p>\n<p>이렇게 구한 어텐션 분포(Attention Distribution)는 각 인코더 Hidden State의 중요도라고 볼 수 있다.</p>\n<h3>Attention Distribution X Encoder Hidden State</h3>\n<img src=\"https://user-images.githubusercontent.com/42150335/147276182-aa176c23-bd20-4c99-81b0-88c65f244752.png\" width=\"500\">  \n<p>소프트맥스를 통해 얻은 어텐션 분포를 각 인코더 Hidden State와 곱해준다.(Broadcasing)</p>\n<h3>Weight Sum</h3>\n<img src=\"https://user-images.githubusercontent.com/42150335/147276190-edfc16a9-4f0d-4a2e-927d-4aac3175c025.png\" width=\"400\">\n<p>각 어텐션 분포와의 곱을 통해 얻어진 Hidden State들을 전부 더해준다. (element-wise)</p>\n<p>이렇게 얻은 벡터를 인코더의 문맥을 포함하고 있다하여 컨텍스트 벡터(Context Vector)라고도 부른다.<br>\n기본적인 Seq2seq에서 Encoder의 마지막 Hidden State를 컨텍스트 벡터라고 부른 것과 대조된다.</p>\n<ul>\n<li>※ 이해를 돕기 위한 예시 ※</li>\n</ul>\n<img src=\"https://user-images.githubusercontent.com/42150335/147276201-1a35def6-66a3-4911-8e7e-45aa9da2121e.png\" width=\"500\">\n<h3>Concatenating to s<sub>t</sub></h3>\n<img src=\"https://user-images.githubusercontent.com/42150335/147276294-abdbad76-1890-440e-b605-b815225e508a.png\" width=\"500\">\n<p>그렇게 구한 컨텍스트 벡터와 현 시점의 디코더 셀의 Hidden State와 연결해준다. (여기서는 concatenate라는 방법을 사용했지만 평균을 내서 사용하는 방법도 있다)</p>\n<img src=\"https://user-images.githubusercontent.com/42150335/147276300-463fb022-c9ab-4903-8217-3b4c1218b47b.png\" width=\"500\">  \n<p>그리고 이렇게 구한 벡터를 이용해서 최종 예측 값을 구하게 된다.</p>\n<p>이상이 가장 기본적인 어텐션인 <strong>Dot-Product Attention</strong>의 설명이다.</p>\n<p>어텐션 스코어를 구할 때 Dot-Product를 한다고 해서 Dot-Product Attention이라고 한다.</p>\n<h2>다양한 종류의 어텐션</h2>\n<img src=\"https://user-images.githubusercontent.com/42150335/147276306-65d644fc-f2a2-4a43-a10c-e79679738f6b.png\" width=\"450\">  \n<p>어텐션은 그 효과가 검증된 만큼, 많은 종류의 기법이 존재한다. 하지만 다른 어텐션들과의 차이는 어텐션 스코어를 구하는 중간 수식의 차이일 뿐이지, 크게 개념을 벗어나지 않는다.</p>\n<p>위의 표처럼 다양한 어텐션의 종류가 있으며, 어떤 어텐션을 적용하느냐도 모델의 성능을 좌우할 것이다.</p>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Attention"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"본 포스팅을 이해하기 위해서는 다음 글에 대한 이해가 선행되는 것이 좋습니다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://sooftware.io/rnn/"},"children":[{"type":"text","value":"RNN (Recurrent Neural Network)"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://sooftware.io/lstm_gru/"},"children":[{"type":"text","value":"LSTM & GRU (Long Short Term Memory & Gated Recurrent Unit)"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://sooftware.io/seq2seq/"},"children":[{"type":"text","value":"Seq2seq (sequence to sequence)"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"hr","properties":{},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Seq2seq의 한계"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/147275988-a5eca2d8-18d0-4a23-b7f0-79ccf4c4a416.png","width":500},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"기본적인 Seq2seq 모델은 간단한 구조라는 장점이 있었지만, 크게 2가지의 문제점이 존재한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"하나의 고정된 크기의 벡터에 모든 정보를 압축하다보니 정보 손실이 발생한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"RNN의 고질적인 문제인 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Vanishing Gradient Problem"}]},{"type":"text","value":"이 존재한다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이러한 문제점들은 입력 데이터가 길어지면 성능이 크게 저하되는 현상으로 이어지게 된다. 이를 위한 기법으로 입력 데이터가 길어지더라도, 정확도가 떨어지는 것을 보정해주기 위해 등장한 방법이 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"어텐션(Attention)"}]},{"type":"text","value":" 기법이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Seq2seq의 문제점"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/147275994-360a8692-5525-41f3-b110-d3a0b2572271.png","width":500},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그렇다면 Seq2seq 구조에서 어떤 부분이 문제였는지를 살펴보자. Seq2seq의 구조를 살펴보면, Encoder에서 계산한 여러 Hidden State 중 마지막 Hidden State만을 Decoder에서 사용하게 된다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"즉, 마지막 Encoder의 RNN 셀의 마지막 Hidden State를 제외하고는 사용되지 않는다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"어텐션 매커니즘은 바로 이 사용되지 않은 Hidden State를 이용한 아이디어이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"어텐션의 기본 아이디어는 Decoder에서 출력 결과를 예측하는 매 시점(time step)마다, Encoder의 Hidden State를 다시 한 번 참고한다는 아이디어다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그리고 이 참고하는 비율을, 해당 시점에서 예측해야하는 결과와 연관이 있는 부분을 판단하여 좀 더 집중 (Attention) 하여 본다고 하여 Attention Mechanism이라고 부른다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Attention의 직관적인 설명"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그렇다면 이 Attention Mechanism이 왜 효과가 있을지를 먼저 생각해보자."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/147276029-26d22b53-0045-4794-ae20-fd8d907e81dc.png","width":300},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"위와 같은 영어 문제가 있다고 해보자. 우리는 위의 영어 문제를 해석할 때, 처음부터 끝까지 혹은, 처음부터 한 문장이 끝날 때까지 모두 읽고 해석한다면 해석하기 쉽지 않을 것이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/147276036-a69e28bd-c039-4c0f-a9e6-1abf10dd0e9e.png","width":400},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이 보다는 위의 □ 부분과 같이 부분부분 끊어서 해석하는 편이 더 나은 결과를 도출할 것이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Encoder of Seq2seq"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/147276041-b9831d3b-2971-4bd8-89b6-343372b566b6.png","width":400},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그럼 다시 Seq2seq의 Encoder에 주목해보자. 시각별 RNN 셀의 Hidden State에는 당연히 직전에 입력된 단어에 대한 정보가 많이 포함되어 있을 것이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"예를 들면 “Sooft”라는 단어가 들어간 RNN 셀의 Hidden State는 “Sooft”의 성분이 많이들어간 벡터라고 생각할 수 있다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"어텐션의 아이디어는 여기서 시작된다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Attention Mechanism"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/147276107-8d3b8047-82be-42be-aebd-a6f1690cf050.png","width":500},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"위 그림은 디코더의 세 번째 RNN 셀에서 출력 단어를 예측할 때, 어텐션 매커니즘을 사용하는 모습이다. 그럼 어텐션 매커니즘이 어떻게 적용되는지를 살펴보자."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Attention Score"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/147276113-12444d0c-c63f-486d-a1de-c1bbea208a5b.png","width":500},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"어텐션 매커니즘은 디코더에서 출력 결과를 예측할 때, 인코더의 Hidden State들을 다시 한 번 참고해주는 방법이라고 했다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이 때 어느 인코더의 Hidden State를 얼마나 참고할지를 결정해야 한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이 때, 현재 예측에 필요한 정도라고 판단되는 점수를 어텐션 스코어 (Attention Score)라고 한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이러한 어텐션 스코어를 구하기 위해, 현 시점의 디코더의 Hidden State (s"},{"type":"element","tagName":"sub","properties":{},"children":[{"type":"text","value":"t"}]},{"type":"text","value":")와 인코더의 모든 Hidden State들과 각각 내적을 수행한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"※ 벡터의 내적의 결과는 스칼라가 나온다 ※"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Attention Distribution"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/147276123-ad9bf1a0-60fa-4fab-a32e-dedd08e132a2.png","width":400},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"앞에서 각 인코더와 디코더의 현재 Hidden State를 내적한 값은 스칼라로 나오기 때문에 이를 소프트맥스 함수를 적용해서 어텐션 분포를 구한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"※ 소프트맥스 함수는 입력받는 값을 모두 0 ~ 1 사이의 값으로 정규화하며 총합은 항상 1이 된다 ※"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이렇게 구한 어텐션 분포(Attention Distribution)는 각 인코더 Hidden State의 중요도라고 볼 수 있다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Attention Distribution X Encoder Hidden State"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/147276182-aa176c23-bd20-4c99-81b0-88c65f244752.png","width":500},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"소프트맥스를 통해 얻은 어텐션 분포를 각 인코더 Hidden State와 곱해준다.(Broadcasing)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Weight Sum"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/147276190-edfc16a9-4f0d-4a2e-927d-4aac3175c025.png","width":400},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"각 어텐션 분포와의 곱을 통해 얻어진 Hidden State들을 전부 더해준다. (element-wise)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이렇게 얻은 벡터를 인코더의 문맥을 포함하고 있다하여 컨텍스트 벡터(Context Vector)라고도 부른다."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n기본적인 Seq2seq에서 Encoder의 마지막 Hidden State를 컨텍스트 벡터라고 부른 것과 대조된다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"※ 이해를 돕기 위한 예시 ※"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/147276201-1a35def6-66a3-4911-8e7e-45aa9da2121e.png","width":500},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Concatenating to s"},{"type":"element","tagName":"sub","properties":{},"children":[{"type":"text","value":"t"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/147276294-abdbad76-1890-440e-b605-b815225e508a.png","width":500},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그렇게 구한 컨텍스트 벡터와 현 시점의 디코더 셀의 Hidden State와 연결해준다. (여기서는 concatenate라는 방법을 사용했지만 평균을 내서 사용하는 방법도 있다)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/147276300-463fb022-c9ab-4903-8217-3b4c1218b47b.png","width":500},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그리고 이렇게 구한 벡터를 이용해서 최종 예측 값을 구하게 된다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이상이 가장 기본적인 어텐션인 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Dot-Product Attention"}]},{"type":"text","value":"의 설명이다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"어텐션 스코어를 구할 때 Dot-Product를 한다고 해서 Dot-Product Attention이라고 한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"다양한 종류의 어텐션"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/147276306-65d644fc-f2a2-4a43-a10c-e79679738f6b.png","width":450},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"어텐션은 그 효과가 검증된 만큼, 많은 종류의 기법이 존재한다. 하지만 다른 어텐션들과의 차이는 어텐션 스코어를 구하는 중간 수식의 차이일 뿐이지, 크게 개념을 벗어나지 않는다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"위의 표처럼 다양한 어텐션의 종류가 있으며, 어떤 어텐션을 적용하느냐도 모델의 성능을 좌우할 것이다."}]}],"data":{"quirksMode":false}},"excerpt":"Attention 본 포스팅을 이해하기 위해서는 다음 글에 대한 이해가 선행되는 것이 좋습니다. RNN (Recurrent Neural Network) LSTM & GRU (Long Short Term Memory & Gated Recurrent…","fields":{"readingTime":{"text":"8 min read"}},"frontmatter":{"title":"Attention Mechanism (어텐션 메커니즘)","userDate":"26 January 2020","date":"2020-01-26T10:00:00.000Z","tags":["nlp"],"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/a9c3aa2f1074a9ebdde0b36f5881c273/e7aa3/attention.png","srcSet":"/static/a9c3aa2f1074a9ebdde0b36f5881c273/ea5bc/attention.png 750w,\n/static/a9c3aa2f1074a9ebdde0b36f5881c273/e7aa3/attention.png 773w","sizes":"100vw"},"sources":[{"srcSet":"/static/a9c3aa2f1074a9ebdde0b36f5881c273/2a863/attention.webp 750w,\n/static/a9c3aa2f1074a9ebdde0b36f5881c273/99eab/attention.webp 773w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.351875808538163}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"children":[{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#181818","images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/2584f/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/2456b/soohwan.png 40w,\n/static/a2699b4a2f164aa71106535e018ceafc/ab12d/soohwan.png 80w,\n/static/a2699b4a2f164aa71106535e018ceafc/2584f/soohwan.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65256/soohwan.webp 40w,\n/static/a2699b4a2f164aa71106535e018ceafc/c6b8d/soohwan.webp 80w,\n/static/a2699b4a2f164aa71106535e018ceafc/03d15/soohwan.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.25}}]}}]}},"relatedPosts":{"totalCount":30,"edges":[{"node":{"id":"06ac0e32-0688-50f0-810d-134ef8b168ab","excerpt":"Decoding Strategy (디코딩 전략) 이번 포스팅에서는 자연어처리 모델의 디코딩 전략에 관해서 다뤄보려고 합니다. 디코딩이란 말처럼 디코딩은 디코더에서\n수행하는 작업입니다. 즉, BERT와 같은 인코더 모델에서 사용하는게 아니라 GPT…","frontmatter":{"title":"Decoding Strategy (디코딩 전략)","date":"2022-01-15T10:00:00.000Z"},"fields":{"readingTime":{"text":"9 min read"},"slug":"/generate/"}}},{"node":{"id":"db36f120-4fb0-5bf7-af53-16447fe6cdd4","excerpt":"Generation with Retrieval 이번에 딥마인드에서 RETRO(Retrieval-Enhanced Transformer) 라는 모델을 내놓았습니다. 문서 retrieval + GPT 기반 모델인데,\n7B 모델임에도 불구하고 2…","frontmatter":{"title":"Generation with Retrieval","date":"2022-01-04T23:00:00.000Z"},"fields":{"readingTime":{"text":"6 min read"},"slug":"/fid_and_rag/"}}},{"node":{"id":"3b4040eb-d53d-5064-beec-cfbf7a7a0fe2","excerpt":"Fine-grained Post-training for Improving Retrieval-based Dialogue Systems Paper Review Paper: https://aclanthology.org/2021.naacl-main.12…","frontmatter":{"title":"Fine-grained Post-training for Improving Retrieval-based Dialogue Systems Paper Review","date":"2021-12-18T10:00:00.000Z"},"fields":{"readingTime":{"text":"2 min read"},"slug":"/bert_fp/"}}},{"node":{"id":"78976688-33d9-53c4-8489-5099082b9972","excerpt":"GPT (Generative Pre-trained Transformer) 1 gpt1 먼저 알아보고, gpt2에 대해 알아보겠습니다. GPT1 Improving Language Understanding by Generative Pre-Training…","frontmatter":{"title":"GPT (Generative Pre-trained Transformer)","date":"2021-11-23T11:00:00.000Z"},"fields":{"readingTime":{"text":"13 min read"},"slug":"/gpt/"}}},{"node":{"id":"ad5b0c9b-8199-5f10-bfc9-6bb05942e164","excerpt":"Large Scale LM (2) Distributed Programming (작성중) 이 자료는 [해당 link…","frontmatter":{"title":"Large Scale LM (2) Distributed Programming","date":"2021-11-22T11:00:00.000Z"},"fields":{"readingTime":{"text":"17 min read"},"slug":"/big-model2/"}}}]}},"pageContext":{"slug":"/attention/","prev":{"excerpt":"Seq2seq (Sequence to sequence) 본 포스팅을 이해하기 위해서는 다음 글에 대한 이해가 선행되는 것이 좋습니다. RNN (Recurrent Neural Network) LSTM & GRU (Long Short Term Memory…","frontmatter":{"title":"Seq2seq (Sequence to sequence)","tags":["nlp"],"date":"2020-01-25T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAACYElEQVQoz6WTy0tUcRTHf/0BPZZB64iiXbQIXVUSLtxItgkqKmgTGElFFmWhiKGUEmkRKVhCgtEDF0oUmDO+8K3N3NFxnDvO6851nGacuXfmPj4xGmO1CKQvfDic7+LAOXyPsG2b7ZCXrmdZWvKxuOhFVaJEQiv4ZRlZlhEUZP/Fv5XL6ViGRiyVwaMkwcqSM7KInGEQXzeI6/zJukk8sc5qIo2eSmNnNLRUeqPP+6mUiaXD94DB5/kMZOFHMoeQoynmnV8JfmrE/6EJ+WMT8vtHyFOD+CNJgiGVl9MKt74F6ZqLEQ6ryKEE474xel1d9End9Etv6fN0M+aeRciqTrKtDKoE3N8NNXvgmoCuisJ6JxwZRO0g52a3TtEhX6J67gD1UjH17mLuuvbT421AyDENteUU1O7DbC/HfFWO9WAv6WclBGMJYsEARX1RRN0AZwbjZNQIfjnEk7nTNLhO8sZXRedSJXWuIl67ahCBWIb401JoPoLVcgy79Tg0HkZrLSGsJkgoYYr7FcTDL1Q41siuRpFXQjyXLtDmPcuLxfO0L12hebGMLncNYlnRiHZcxr6xg2z1TnJ3dpG9LjDfXS2sV+rMIB5PcnFCL3idvkpuThzk3vTRDW7PHKLH3YwIKkmmZjx4J0eQJkaQxkfwjA/h8fiQlmMs+CIMuCP0ulUcUmSj9/gUZrwLOKRhhqRRnNIow55RJlze33MIMyo4Qxb/I5EPv2maGDmdtWSaWCJFTs9gGsZm3G0by7Yxf9Wtr7GwbBNro26S98XmK+moqooSjRIOBQkEAmiaVhi4HX4CuGdQpVTBy/kAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/3f604bd7e174e888d547ccba99e0fccb/a6e9f/seq2seq.png","srcSet":"/static/3f604bd7e174e888d547ccba99e0fccb/4a1e8/seq2seq.png 750w,\n/static/3f604bd7e174e888d547ccba99e0fccb/a6e9f/seq2seq.png 773w","sizes":"100vw"},"sources":[{"srcSet":"/static/3f604bd7e174e888d547ccba99e0fccb/f9860/seq2seq.webp 750w,\n/static/3f604bd7e174e888d547ccba99e0fccb/c53c5/seq2seq.webp 773w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5808538163001293}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,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"},"images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.2462962962962962}}}}]},"fields":{"readingTime":{"text":"10 min read"},"layout":"","slug":"/seq2seq/"}},"next":{"excerpt":"Teacher Forcing 본 포스팅을 이해하기 위해서는 다음 글에 대한 이해가 선행되는 것이 좋습니다. RNN (Recurrent Neural Network) LSTM & GRU (Long Short Term Memory & Gated…","frontmatter":{"title":"Teacher Forcing","tags":["nlp"],"date":"2020-01-31T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA6klEQVQoz22ShwoEMQhE8/+/Gdhle+/F4w14hOMGJCbqOCYJ27bZeZ6W57ld12XzPMu/79ve95WBZVlsGAb5dV3buq6KZVlmx3HonH2ADCKIWUkkwZMcxCF9nkcre5pO06Q6bxzatlVHDL9pGivL0vq+FylFAHWurCgKxZmmqiqRurBAN5K6rlMCPsUoQA3mIxN3f993+RC7Oo1MAIOELhRBzpmrA5xTDMZx/KqPMarO94FEEnwEFEKWqnMFgBj5XA0iGBNCf0SNTBBVrOxTpC9NEU25Q7/PXwT7AydJ7wagmAfjITD/Rmn+B9gFb7kmMu2EAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/43c1417fedd352e3d13e64f0a4ceec5b/e46c1/teacher_forcing.png","srcSet":"/static/43c1417fedd352e3d13e64f0a4ceec5b/436bd/teacher_forcing.png 750w,\n/static/43c1417fedd352e3d13e64f0a4ceec5b/e46c1/teacher_forcing.png 773w","sizes":"100vw"},"sources":[{"srcSet":"/static/43c1417fedd352e3d13e64f0a4ceec5b/a51c3/teacher_forcing.webp 750w,\n/static/43c1417fedd352e3d13e64f0a4ceec5b/10f41/teacher_forcing.webp 773w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.37516170763260026}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAZCAYAAAAxFw7TAAAACXBIWXMAAAsTAAALEwEAmpwYAAAGuUlEQVQ4yy2RaUzbhxnG/5+rqVLWcPj62xwJEBJIIEAJJNxgG7CNMeYKtsEcMYe5YsAGwlXGnWAgFxCOADlAEHIqyUiqJE2zNlu3rp12NI20fcikTaq2Tpr2YdJvItojvdKj58NPj95HMGTGoEuPJeN4NCnHYjgRF8eJxCRSUjLIzTFQUVZGlc1GlbWS1oZWPukbYcp7haWlTa6vbTPtnaXT3YfjVC1lhSUIuelHKchOpMSQSlFuGrqsZDJSkklKSiYnO5fqMgu1FXaqKx142s4w5Z3n5uYzvvzVn3nz3V/Z2fkFM95FXM1uykusCHXWbErzUijNS8eSr8FWkIOtKI9iUx4mg5GKklKclZU0nGqg98wg8/M32Hn2DT/867/s6vff/Z3lq3focvdTYalE8A7YmeyvZKjDhqe+hEa7mfryIhrsJ2lxVFJfWUFbbS0DHg+T4xMsL6zy6dPPePv2Hf/453948fotFy7doM3VjeVkOcLVmRZuzrazMe9h62oPWyv9bCwOsHp5gNY6OwZ9Pga9mQpbNW0uN2fHvWzeXOf2rfvcufuMheUtevpGqXU4MRnNCJ/enebF41k+f7LAl8/X+Ob1Lb7/3UO62x3ExsajyVBjN5vorC2n3+XkjMdDX+8wkxNexka99PQOUudwUmG1k59nQpgbr+PetUG+eLrAH369zY9/e82TB8uEhISTk3qCkRoTc6fLWOisZLbbwVh7A21NTbS1tDM7MUqrsxGzqQS9IR/jLnC8p5ThdhNTfRbmJhzsbA3T0WwjPDScPouW5eYC1jxWrnbauOKp5ILbwZnGGizWCn7zZId3j+/x2cO79DY4SU9OQ9hY6qG9Nht3fS4dtbl80momO+M42oQYhsq1nK3Sc81dxkZvFYOOUpptxbTVWCgyF3JneQHevXm/9o/3H3G28CTC5o0RBgZO0VBXQG2VkZ6OcnLVKRQkx1FvzKTJpOWSs4g1dzmD1cV0lRfRYSuiRK/jXGsjXyzM8O3dLX67coOlxgaEnUcX2dg6x+jYaa7MD/L5q3W6u5zY1Ql0FatpN2s4X63jQnUukzUm6k3ZeE7qaSw2ckqXxfUOLYN2A/Pddlb7LAj3tidYWR1koL+O2cu9vHx5nbExN67CVMZtmQxb1EzbsxgpTedcuZb5ujzGq/S4SvNYnKhi8WcF2LLjOdtp5kqvAWF7c5TF5X48bjuXLnTz6OEsY+Pt9JRrWG/UcMtlYMmh4bI9h2lrFustRqardLiKdHy108Wr9RZaLEZGuk4z0dWAsL0xzNxcF20uCxfPd3Jne5qJSQ/eTisrtRnc7jAy79AwVaHlvF3DWlMeU1XZlGenUF1qpLUsH6shm8JcNaX5OQgb1weYmmqlob4A7zkXqyuDDA434x1zcrk6hWVnDlPWDC7ZtAyZ05ipUjNZqSU17ij7Qw6yPyCEA/tCiYo4THx0DMLzx14e3B7j2nIfP78/xbOdizy4PcmL50t4nXrWnGpmSlI5p09lsjCNq04dNdrjBAWFEB8dxYkjUYQEBhMRdoDYyEiEt18v86evFnnz9Spvv73BX/64ybvv7/DvH54xPdZCdeYh1l06bnXks9KkpyYngbCQUA6HH0IpVxKmCmSfKpDQoCDioyMRfvlkglePxnl6e5jt1V5WL7Uzd7aZ+clmmmvNyEWRjI8jKEqPJSEqAqkqmNiwUOrzMyk0aIk+EkX4vn2kJMSREHMEQa8+ijopktRjh8hKjcaUm0i1RY21VI0+N4342EhkqkB8pCK+UpGkwwdp1x+j03iUGlMaGm0OWRnp6LJSORAciJBy/AAlxgTaGvIY6q3gjMeKTp/Eochw9oWG0lSQwKAlheK0aFrzEthy7f41i5NJB5FK/FCpAjgcGYlGnYkuR4Mw1FXMhdEqet1WsjITEQNUfCSRIapUyJRKEqPCuNas5uWQmZvtOgYsyWg+PoBCoUCpVKEURYIDA4mOiqKmphphffY0fe4ypDJ/fP39CTh0EHlQMAqVioDAIHylSnISI5hr1hC2P5C9/nIkMjkKUY4oKhBFJcFBQURGRpCcnIxwd7WH+GPhfLjnJ4gBCkJjolAE70cREIByt6VcJDg4gLjDIfhJZYhKEZVKiSjKkYsy5ArFe3BwcBBBQYEIMyP1+Ej34Cf7KX4KCX4KKVKVAplKiUxUvG8ilUvxk0qQi/L3mfj/3F8mwc9fgkTij0wqQSqVINgtaj7Y8wG+Ch985H74iBJ8lVL8RRkShQSpXIJE5o9ELkWq2IXLkL33Uj7y9WXPXh/2+uzeXnx8ffgf1pY7pVRokdcAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.2462962962962962}}}}]},"fields":{"readingTime":{"text":"5 min read"},"layout":"","slug":"/teacher_forcing/"}},"primaryTag":"nlp"}},
    "staticQueryHashes": ["3170763342","3229353822"]}