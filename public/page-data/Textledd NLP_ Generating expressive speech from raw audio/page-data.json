{
    "componentChunkName": "component---src-templates-post-tsx",
    "path": "/Textledd NLP_ Generating expressive speech from raw audio/",
    "result": {"data":{"logo":null,"markdownRemark":{"html":"<h1>Textless NLP: Generating expressive speech from raw audio</h1>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2102.01192\">paper</a> / <a href=\"https://github.com/pytorch/fairseq/tree/master/examples/textless_nlp/gslm\">code / pre-train model</a> / <a href=\"https://ai.facebook.com/blog/textless-nlp-generating-expressive-speech-from-raw-audio\">blog</a></li>\n<li>Name: Generative Spoken Language Model (GSLM)</li>\n</ul>\n<h2>Intro</h2>\n<ul>\n<li>BERT, RoBERTa, GPT-3 등 최근 몇 년간 <code class=\"language-text\">텍스트</code>에 집중된 NLP 모델들이 발전되어 왔음.</li>\n<li>이건 분명한 한계다. 텍스트에 대한 디펜던시를 깨야한다.</li>\n<li>언어 == 문자가 아니다. speech가 있다.</li>\n<li>그래서 우리 GSLM이 텍스트에 대한 디펜던시를 깰 수 있는 가능성을 보였다.</li>\n<li>음성 프롬프트 시대의 시작을 알린다.</li>\n<li>음성을 프롬프트로 주면 뒤이어서 인공지능이 말을 계속 이어서 말하는 모델의 등장!</li>\n</ul>\n<h2>Background</h2>\n<ul>\n<li>음성을 입력으로 하는 NLP 어플리케이션들은 ASR => NLP를 거쳐야 했음.</li>\n<li>ASR의 정확도가 100%가 아니기 때문에 분명한 정보의 오류가 존재함.</li>\n<li>우리는 여기서 ASR + NLP 구조가 아닌 Speech to Speech로 간다.</li>\n<li>Text나 label 없이 only 음성만으로 학습한다.</li>\n</ul>\n<h2>Textless NLP’s benefits</h2>\n<ul>\n<li>언어 상관없이 학습이 가능해질 가능성이 높아짐</li>\n<li>텍스트로 표현이 안되는 말의 뉘앙스, 감정 등의 정보를 반영할 수 있음</li>\n<li>텍스트 레이블링 혹은 ASR 학습 없이 모델을 학습할 수 있음</li>\n<li>유아들이 어떻게 언어를 배우고 말을 시작하는지를 알 수 있다(? 과연?)</li>\n<li>처음으로 텍스트 없이 audio to audio 번역 시스템이 가능해졌다!</li>\n</ul>\n<h2>Data</h2>\n<ul>\n<li>6,000시간의 Libri-Light와 LibriSpeech 데이터셋 (인코더 학습)</li>\n<li>LibriSpeech and LJSpeech (디코더(TTS System) 학습)</li>\n</ul>\n<h2>Model</h2>\n<img src=\"https://user-images.githubusercontent.com/42150335/134018698-f46507a0-c375-4f6f-a67f-63e6ca2a9240.png\" width=\"600\">  \n<ul>\n<li>Encoder (S2u)\n<ul>\n<li>Speech를 인풋으로 받아서 discrete unit(pseudo-text라고 부름)으로 인코딩</li>\n<li>unit은 k-means clustering으로 나눔.</li>\n<li>인코더로는 CPC, wav2vec 2.0, HuBERT를 사용 (좋은 acoustic encoder들이라고 보시면 됨)</li>\n</ul>\n</li>\n<li>uLM\n<ul>\n<li>unit sequence를 생성</li>\n</ul>\n</li>\n<li>Decoder (u2S)\n<ul>\n<li>TTS System (Tacotron2 사용)</li>\n</ul>\n</li>\n<li>여기서 unit(pseudo-text)은 letter or phoneme과 매핑되지는 않음.</li>\n<li>100 이상의 유닛일 때 좋은 성능을 보였으며 unit은 보통 음소보다 짧은 단위를 인코딩했음.</li>\n</ul>\n<img src=\"https://scontent-gmp1-1.xx.fbcdn.net/v/t39.2365-6/241223788_398469455180920_2630499539056655858_n.jpg?_nc_cat=107&amp;ccb=1-5&amp;_nc_sid=ad8a9d&amp;_nc_ohc=rfiDlgtmTcYAX-EraG5&amp;_nc_ht=scontent-gmp1-1.xx&amp;oh=1c96a38f6af0ada3774380e4fd6110e6&amp;oe=61489C23\" width=\"600\">\n<ul>\n<li>생성한 음성은 pre-trained ASR 모델로 인식해서 성능 측정</li>\n<li>Pre-trained LM으로 텍스트 성능 측정</li>\n</ul>\n<h2>Result</h2>\n<img src=\"https://scontent-gmp1-1.xx.fbcdn.net/v/t39.2365-6/241364732_225715579507676_6485051182702467200_n.jpg?_nc_cat=108&amp;ccb=1-5&amp;_nc_sid=ad8a9d&amp;_nc_ohc=h45PImsz8SkAX-kM1rz&amp;_nc_ht=scontent-gmp1-1.xx&amp;oh=88949e5b3a057a6e42b8266d03171ac7&amp;oe=61492788\" width=\"600\">\n<ul>\n<li>Unit의 수가 모델 성능에 큰 영향을 미침.</li>\n<li>Unit 수가 커질수록 Acoustic의 성능은 좋아졌음. (PER이 낮아졌다)</li>\n<li>LM 점수도 비슷한 경향이었으나, 너무 많은 unit을 사용하면 오히려 안 좋았음. (NLP에서 vocab의 적당한 사이즈가 좋은 이유와 비슷한 것 같음)</li>\n<li>어떤 인코더 모델이냐에 따라 다른 결과가 나옴. HuBERT 성능이 가장 좋았음.</li>\n<li>이렇게 자동으로 측정한 성능이 사람이 평가했을 때와 correlation이 높았음. (좋은 성능 지표)</li>\n</ul>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Textless NLP: Generating expressive speech from raw audio"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/2102.01192"},"children":[{"type":"text","value":"paper"}]},{"type":"text","value":" / "},{"type":"element","tagName":"a","properties":{"href":"https://github.com/pytorch/fairseq/tree/master/examples/textless_nlp/gslm"},"children":[{"type":"text","value":"code / pre-train model"}]},{"type":"text","value":" / "},{"type":"element","tagName":"a","properties":{"href":"https://ai.facebook.com/blog/textless-nlp-generating-expressive-speech-from-raw-audio"},"children":[{"type":"text","value":"blog"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Name: Generative Spoken Language Model (GSLM)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Intro"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"BERT, RoBERTa, GPT-3 등 최근 몇 년간 "},{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"텍스트"}]},{"type":"text","value":"에 집중된 NLP 모델들이 발전되어 왔음."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"이건 분명한 한계다. 텍스트에 대한 디펜던시를 깨야한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"언어 == 문자가 아니다. speech가 있다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"그래서 우리 GSLM이 텍스트에 대한 디펜던시를 깰 수 있는 가능성을 보였다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"음성 프롬프트 시대의 시작을 알린다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"음성을 프롬프트로 주면 뒤이어서 인공지능이 말을 계속 이어서 말하는 모델의 등장!"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Background"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"음성을 입력으로 하는 NLP 어플리케이션들은 ASR => NLP를 거쳐야 했음."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ASR의 정확도가 100%가 아니기 때문에 분명한 정보의 오류가 존재함."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"우리는 여기서 ASR + NLP 구조가 아닌 Speech to Speech로 간다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Text나 label 없이 only 음성만으로 학습한다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Textless NLP’s benefits"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"언어 상관없이 학습이 가능해질 가능성이 높아짐"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"텍스트로 표현이 안되는 말의 뉘앙스, 감정 등의 정보를 반영할 수 있음"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"텍스트 레이블링 혹은 ASR 학습 없이 모델을 학습할 수 있음"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"유아들이 어떻게 언어를 배우고 말을 시작하는지를 알 수 있다(? 과연?)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"처음으로 텍스트 없이 audio to audio 번역 시스템이 가능해졌다!"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Data"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"6,000시간의 Libri-Light와 LibriSpeech 데이터셋 (인코더 학습)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"LibriSpeech and LJSpeech (디코더(TTS System) 학습)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Model"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134018698-f46507a0-c375-4f6f-a67f-63e6ca2a9240.png","width":600},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Encoder (S2u)\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Speech를 인풋으로 받아서 discrete unit(pseudo-text라고 부름)으로 인코딩"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"unit은 k-means clustering으로 나눔."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"인코더로는 CPC, wav2vec 2.0, HuBERT를 사용 (좋은 acoustic encoder들이라고 보시면 됨)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"uLM\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"unit sequence를 생성"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Decoder (u2S)\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"TTS System (Tacotron2 사용)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"여기서 unit(pseudo-text)은 letter or phoneme과 매핑되지는 않음."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"100 이상의 유닛일 때 좋은 성능을 보였으며 unit은 보통 음소보다 짧은 단위를 인코딩했음."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://scontent-gmp1-1.xx.fbcdn.net/v/t39.2365-6/241223788_398469455180920_2630499539056655858_n.jpg?_nc_cat=107&ccb=1-5&_nc_sid=ad8a9d&_nc_ohc=rfiDlgtmTcYAX-EraG5&_nc_ht=scontent-gmp1-1.xx&oh=1c96a38f6af0ada3774380e4fd6110e6&oe=61489C23","width":600},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"생성한 음성은 pre-trained ASR 모델로 인식해서 성능 측정"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Pre-trained LM으로 텍스트 성능 측정"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Result"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://scontent-gmp1-1.xx.fbcdn.net/v/t39.2365-6/241364732_225715579507676_6485051182702467200_n.jpg?_nc_cat=108&ccb=1-5&_nc_sid=ad8a9d&_nc_ohc=h45PImsz8SkAX-kM1rz&_nc_ht=scontent-gmp1-1.xx&oh=88949e5b3a057a6e42b8266d03171ac7&oe=61492788","width":600},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Unit의 수가 모델 성능에 큰 영향을 미침."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Unit 수가 커질수록 Acoustic의 성능은 좋아졌음. (PER이 낮아졌다)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"LM 점수도 비슷한 경향이었으나, 너무 많은 unit을 사용하면 오히려 안 좋았음. (NLP에서 vocab의 적당한 사이즈가 좋은 이유와 비슷한 것 같음)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"어떤 인코더 모델이냐에 따라 다른 결과가 나옴. HuBERT 성능이 가장 좋았음."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"이렇게 자동으로 측정한 성능이 사람이 평가했을 때와 correlation이 높았음. (좋은 성능 지표)"}]},{"type":"text","value":"\n"}]}],"data":{"quirksMode":false}},"excerpt":"Textless NLP: Generating expressive speech from raw audio paper / code / pre-train model / blog Name: Generative Spoken Language Model (GSLM…","fields":{"readingTime":{"text":"4 min read"}},"frontmatter":{"title":"Textless NLP","userDate":"19 September 2021","date":"2021-09-19T10:00:00.000Z","tags":["speech","nlp","paper"],"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/b91fe939e42bcc0b6f0c076dca98fcc8/afa5c/gslm.png","srcSet":"/static/b91fe939e42bcc0b6f0c076dca98fcc8/0dee1/gslm.png 750w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/8beaa/gslm.png 1080w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/d079a/gslm.png 1366w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/afa5c/gslm.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/b91fe939e42bcc0b6f0c076dca98fcc8/a66aa/gslm.webp 750w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/65dd5/gslm.webp 1080w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/4fad6/gslm.webp 1366w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/c512e/gslm.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"children":[{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#181818","images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/2584f/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/2456b/soohwan.png 40w,\n/static/a2699b4a2f164aa71106535e018ceafc/ab12d/soohwan.png 80w,\n/static/a2699b4a2f164aa71106535e018ceafc/2584f/soohwan.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65256/soohwan.webp 40w,\n/static/a2699b4a2f164aa71106535e018ceafc/c6b8d/soohwan.webp 80w,\n/static/a2699b4a2f164aa71106535e018ceafc/03d15/soohwan.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.25}}]}}]}},"relatedPosts":{"totalCount":20,"edges":[{"node":{"id":"64e39e81-9c08-53ad-967e-f53e0ffd1d51","excerpt":"한국어 Tacotron2 이번 포스팅에서는 Tacotron2 아키텍처로 한국어 TTS 시스템을 만드는 방법에 대해 다루겠습니다. Tacotron2 Tacotron2는 17년 12월 구글이 NATURAL TTS SYNTHESIS BY…","frontmatter":{"title":"한국어 Tacotron2","date":"2021-10-10T10:00:00.000Z"},"fields":{"readingTime":{"text":"11 min read"},"slug":"/korean_tacotron2/"}}},{"node":{"id":"8609f7b7-4942-59fe-bfaa-5f82c648649e","excerpt":"Textless NLP: Generating expressive speech from raw audio paper / code / pre-train model / blog Name: Generative Spoken Language Model (GSLM…","frontmatter":{"title":"Textless NLP","date":"2021-09-19T10:00:00.000Z"},"fields":{"readingTime":{"text":"4 min read"},"slug":"/Textledd NLP_ Generating expressive speech from raw audio/"}}},{"node":{"id":"75998e15-7d74-5d05-af5b-1112437e067d","excerpt":"Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition Yu Zhang et al., 2020 Google Research, Brain Team Reference…","frontmatter":{"title":"Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition Paper Review","date":"2021-03-17T10:00:00.000Z"},"fields":{"readingTime":{"text":"3 min read"},"slug":"/Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition/"}}},{"node":{"id":"feb53e83-51f2-5350-ae0e-58157d8dfd22","excerpt":"PORORO Text-To-Speech (TTS) 얼마전에 저희 팀에서 공개한 PORORO: Platform Of neuRal mOdels for natuRal language prOcessing 라이브러리에 제가 공들여만든 TTS…","frontmatter":{"title":"PORORO Text-To-Speech (TTS)","date":"2021-02-16T10:00:00.000Z"},"fields":{"readingTime":{"text":"1 min read"},"slug":"/pororo-tts/"}}},{"node":{"id":"77bed2d4-fc96-5bff-9808-9b9cb45369f3","excerpt":"EMNLP Paper Review: Speech Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al) Incremental Text-to-Speech…","frontmatter":{"title":"EMNLP Paper Review: Speech","date":"2020-12-08T10:00:00.000Z"},"fields":{"readingTime":{"text":"4 min read"},"slug":"/2020 EMNLP Speech Paper Review/"}}}]}},"pageContext":{"slug":"/Textledd NLP_ Generating expressive speech from raw audio/","prev":{"excerpt":"이번에 저희 튜닙에서 공들여 만든 TUNiB Electra 모델을 공개했습니다 !! 🎉 🎉 이번 공개에서는 한-영 bilingual 모델과 한국어 모델을 각각 Small/Base 사이즈로 공개했으며, HuggingFace transformers…","frontmatter":{"title":"TUNiB Electra 공개","tags":["huggingface","nlp","record"],"date":"2021-09-18T15:11:55.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABY0lEQVQoz02SacuCUBCF/f+/qO9BGFnaSqVp0UIl7aWtnpdn4MIrXObO3HPObHpVVen7/er3++n1eunz+ej5fOrxeKgsSx2PRw2HQ/N5x7/dbrper7pcLmbhvN9voeVJ0m6302az0Ww202KxUJZlut/vJgwBkeVyqfl8bj6fK4I4CeHweSgnSWKiBBGG2Gg0VKvV1O12dTqdtF6vtd1uNRgM5Pu+6vW6RqOR4eM41nQ6tUo9sqxWKwMj5IQRSNPUKj6fz0akGtqleizFgEMYUbSsZQi0QiUAD4eDtUtbzI47mP1+bxhmyXyLolCe51YEHGsZAR4hAeCOCAIuERjeqQxBtxAOPniX2KNU5sJgmddkMrF7v983Szu8s7D/8V6vp/F4rDAMzcJlJB4OIAAEW62W2u22CWHdaTabiqLI3judjvngiXEnzg5MMAgCE4UImKxYwCzD/VbM0B1iWJbJUvEZxR8WlJe1e/a3LQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/7ccdb9951c9d362c8a3548e8c2a87231/59ccb/electra.png","srcSet":"/static/7ccdb9951c9d362c8a3548e8c2a87231/c68af/electra.png 750w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/87f65/electra.png 1080w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/d464a/electra.png 1366w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/59ccb/electra.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ccdb9951c9d362c8a3548e8c2a87231/9fb02/electra.webp 750w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/cd76f/electra.webp 1080w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/b7397/electra.webp 1366w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/507b8/electra.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4479166666666667}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAZCAYAAAAxFw7TAAAACXBIWXMAAAsTAAALEwEAmpwYAAAGs0lEQVQ4yx2RaUzUiRmH/583TRO7csw9HAqIAoKgCMoNw8wwM8AwXDIzMAw4AwyXwzGAXEu5lQEWFZBDwAMC4hm16EZd1911u+12t+mxrkn7wSZtsmm3SdMPTZ4G3uT58n548vu9r2DIjEWXHkfGqRhSTsZy+vhxTicmkZKSQY7WQEVZGXarFbulkua6Zj7qHWbSe5WlpU1urG0z5Z2lo70Xx1knZYUlCDnpxyjQJFJiSKUoJw1dVjIZKckkJSWj1eRQVWbGWWGjqtKBp+U8k955bm0+58tf/4W33/+NnZ3PmfYu4m5qp7zEglBj0VCam0Jpbjrm/GysBVqsRbkUG3MxGvKwlZTiqqyk7mwdvecHmJ+/yc7zb/nx3/9jd/7w/T9YvnaXrvY+KsyVCN5+GxN9lQy2WfHUllBvM1FbXkSdrYwmRyW1lRW0OJ30ezxMjI2zvLDKJ88+5d279/zzX//l5Zt3zFy+SYu7C/OZcoRr003cmm1lY97D1rVutlb62FjsZ/VKP801Ngz6fAx6ExXWKlrc7VwY87J5a507tx9w995zFpa36O4dwelwYcwzIXxyb4qXT2b57OkCX75Y49s3t/nh94/oanUQFxdPdoYKm8lIh7OcPreL8x4PvT1DTIx7GR3x0t0zQI3DRYXFRn6uEWFurIb71wf44tkCf/zNNj/9/Q1PHy4TGhKONvU0w9VG5s6VsdBRyWyXg9HWOloaGmhpamV2fIRmVz0mYwl6Qz55u8Kx7lKGWo1M9pqZG3ewszVEW6OV8NBwes1qlhsLWPNYuNZh5aqnkpl2B+frqzFbKvjt0x3eP7nPp4/u0VPnIj05DWFjqZtWp4a22hzanDl81GxCk3EKdUIsg+VqLtj1XG8vY6PHzoCjlEZrMS3VZopMhdxdXoD3b/e+/dODx1woPIOweXOY/v6z1NUU4LTn0d1WjlaVQkHyCWrzMmkwqrnsKmKtvZyBqmI6y4tosxZRotdxsbmeLxam+e7eFr9buclSfR3CzuNLbGxdZGT0HFfnB/js9TpdnS5sqgQ6i1W0mrKZqdIxU5XDRLWRWqMGzxkd9cV5nNVlcaNNzYDNwHyXjdVeM8L97XFWVgfo76th9koPr17dYHS0HXdhKmPWTIbMKqZsWQyXpnOxXM18TS5jdj3u0lwWx+0s/rIAqyaeCx0mrvYYELY3R1hc7sPTbuPyTBePH80yOtZKd3k26/XZ3HYbWHJkc8WmZcqSxXpTPlN2He4iHV/vdPJ6vYkmcx7DnecY76xD2N4YYm6ukxa3mUsfd3B3e4rxCQ/eDgsrzgzutOUx71AzadPwsS2btYZcJu0ayjUpVJXm0VyWj8WgoTBHRWm+FmHjRj+Tk83U1RbgvehmdWWAgaFGvKMurlSlsOzSMGnJ4LJVzaApjWm7iolKNanHj3Ew5DAHA0I4dCCU6Igo4mNiEV488fLwzijXl3v51YNJnu9c4uGdCV6+WMLr0rPmUjFdkspFfSoThWlcc+moVp8iKCiE+JhoTh+NJiQwmIiwQ8RFRiK8+2aZP3+9yNtvVnn33U3++qdN3v9wl//8+Jyp0SaqMo+w7tZxuy2flQY91doEwkJCiQo/gkKqIEwZyAFlIKFBQcTHRCJ89XSc14/HeHZniO3VHlYvtzJ3oZH5iUYanSakcjkZJyIoSo8jIToCsTKYuLBQavMzKTSoiTkaTfiBA6QkHCch9iiCXnUMVVIkqSePkJUagzEnkSqzCkupCr02jfi4SKTKQHzEcnzFcpKiDtOqP0lH3jGqjWlkq7VkZaSjy0rlUHAgQsqpQ5TkJdBSl8tgTwXnPRZ0+iSORIZzIDSUhoIEBswpFKfF0JybwJZ7965ZnEk6jFjkR4AygKjISNSqTHTabITBzmJmRuz0tFvIykxEHqDkQ5EEuVKBRKEgMTqM640qXg2auNWqo9+cTPaJQ8hkMhQKJQq5nODAQGKio6murkJYnz1Hb3sZYok/fv4iAo4cRhoUjEypJCAwCF+xAm1iBPON2YQdDMTHX4pIIkUu30WGQq4gOCiIqMgIkpOTEe6tdhN/Mpyf7/sZ8gAZobHRyIIOIgsIQKFUIpXKCQ4O4HhUKH5iCQqFHKVSsSeUyiVIZTLkuymDg/bEwvRwLT7iffhJfoGfTISfTIxYKUOyW1kuQyaXIpaK8ReLkO5JZHvJdvf+EtFeK5HIH7FYtIdgM6v4YN8H+Mp88JH64SMX4asQ4y8XI5KJEEtFiCT+iKRiJLJduQSJVIxYJuZDX1/27fdhv88u+/Hx9eH/E3w7u01Rad8AAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.2462962962962962}}}}]},"fields":{"readingTime":{"text":"2 min read"},"layout":"post","slug":"/tunib_electra/"}},"next":{"excerpt":"React 기반 개인 웹페이지 배포하기 이번 글에서는 react…","frontmatter":{"title":"React 기반 개인 웹페이지 배포하기 (gatsby)","tags":["toolkit","web"],"date":"2021-09-22T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC6klEQVQozzWSS28TdxTF//bMeMav+IntseM3JrYnDTGx0yR2ksaJDQk2bh0c5UETxSGQgBCF0BD1QVFTIEVCgFiAhIQECxatuqvUfoAuuugH6Lf5VbbUxdG9V7o695yjK+4f3mG1s8y5kQIDNjexYByvJ4SiOJBVB0LSSOhBnh12WbkwgxAydrsb16lB/JkiT9+958ruDRTNicXpRay2GqRCca5e/pxGrU46kcWmubDbPUiyFZNipT6a4ZefbvJwrU7S7eBUbIhC+TwmW4DiZ5d4/v5X0sMlNKcf0Vlf4YcHd7l1bZXS2KfEk1mcNg+a2lPoRJisXMyn+fftMX8/vcek7iNTmuHc1ByOdJnt43e8+PCRxuouQkiIu7e32d9YIRHSSYd1XFYbI4ZBJn2GpfESs5UKP17d4PfH9/nz4S1a2QSnZxrEcwUGgkmad4558Pw1sXIHi55FzBfztM7P8uHNCW9ePqaxVCOXzyKEmePuGr+dHPHzwTX+eHLAX9/vU02F8X4yhSuc6isqNtdZ+vYV3vkNQuN1xHeHexx+9WU/wxtb6xzd3qI+W0FWnJxstfnn2T32W00WiwbXFyawqlacwSguTwhJ1vClctTam+zt7nBzfw9RLxf55uttHh10qZ41OD0YRQ/GMEsOjq50eNTt4A/GEEKj0fqCVDKDWajYbR4kzYHfF6AyMU2rucb1zR3E5qUaY4k0zfocO4s1JjM5goEIimInP5TvLw8bhb695XaHqckKQgg8Az78viBexwDTo2NcmGuzXJ1HlIyzrC1WGQoM0i4Ms16dJu33Y7XY+z/Xy1KSNGTFhmzWUBU7qsVBIhLH4/Ti9YeYToQxvA4uT40i8tEkCxPjHLQv0l0oszJXwUieQe6RSFYkk4oi2/rozT30epOw9KvLrxPVA9hUlXAkgiimk0xmkmxWCizkktRG8owmYhipFFFd71vtKfufrHfIbFKRzCoWxUrQ7cNwe8lEI+QiIf4DVOxddpZZefQAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/ddaa4cb6857e989e32ffc466cf76e8a5/7c984/gatsby.png","srcSet":"/static/ddaa4cb6857e989e32ffc466cf76e8a5/5b584/gatsby.png 750w,\n/static/ddaa4cb6857e989e32ffc466cf76e8a5/c1f05/gatsby.png 1080w,\n/static/ddaa4cb6857e989e32ffc466cf76e8a5/7c984/gatsby.png 1123w","sizes":"100vw"},"sources":[{"srcSet":"/static/ddaa4cb6857e989e32ffc466cf76e8a5/73e0d/gatsby.webp 750w,\n/static/ddaa4cb6857e989e32ffc466cf76e8a5/9fede/gatsby.webp 1080w,\n/static/ddaa4cb6857e989e32ffc466cf76e8a5/d4610/gatsby.webp 1123w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5253784505788067}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,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"},"images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.2462962962962962}}}}]},"fields":{"readingTime":{"text":"15 min read"},"layout":"","slug":"/react_homepage/"}},"primaryTag":"speech"}},
    "staticQueryHashes": ["3170763342","3229353822"]}