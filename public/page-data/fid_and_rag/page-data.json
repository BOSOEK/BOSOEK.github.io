{
    "componentChunkName": "component---src-templates-post-tsx",
    "path": "/fid_and_rag/",
    "result": {"data":{"logo":null,"markdownRemark":{"html":"<h1>Generation with Retrieval</h1>\n<p>이번에 딥마인드에서 <a href=\"https://deepmind.com/research/publications/2021/improving-language-models-by-retrieving-from-trillions-of-tokens\">RETRO(Retrieval-Enhanced Transformer)</a> 라는 모델을 내놓았습니다. 문서 retrieval + GPT 기반 모델인데,\n7B 모델임에도 불구하고 25배나 큰 모델과 비견될만한 성능을 보여줬습니다. 요즘 트렌드는 검색 + GPT로 가는 것 같습니다.</p>\n<p>언어모델이 아무리 크고 많은 데이터를 봤다고 하더라도 세상의 모든 지식을 담을 수는 없습니다.\n그리고 새롭게 생긴 지식이라면 더더욱 언어모델 입장에서는 알 수가 없습니다. 이런 문제를 검색과 결합해서\n풀어보려는 시도가 많이 있었고, 이번 포스팅에서는 그 기반이 된 개념인 <strong>Fusion-in-Decoder(FID)</strong> 와 <strong>Retrieval-Augmented Generation(RAG)</strong>\n를 다뤄보겠습니다.</p>\n<h2>Fusion-in-Decoder (FiD)</h2>\n<p><strong>Fusion-in-Decoder(FID)</strong> 는 생성 모델 입력에 검색 결과를 넣어서 활용합니다.\n아래 그림과 같이 어떤 쿼리가 들어왔을 때 적절한 N개의 문서를 가져오고 이 결과를 언어모델의 인코더에 넣어줍니다.\n그리고 디코더는 이 결과를 활용해서 적절한 응답을 생성하는 방식입니다.</p>\n<img src=\"https://user-images.githubusercontent.com/42150335/148075563-977db2da-5297-41f1-9f11-cfd54f9ffe4a.png\" width=\"300\">  \n<p>FiD 본 논문에서 검색 모델은 BM25, DPR(Dense Passage Retrieval )을 활용했습니다. 생성 모델로는 위에 설명한 바와 같이\n인코더와 디코더가 필요하기 때문에 T5, Bart와 같은 Seq2seq (Sequence-to-Sequence) 기반의 모델을 사용했습니다.</p>\n<p>FiD는 이름은 거창하지만 방식 자체는 어렵지 않습니다. 아래 2개의 개념만 알면 됩니다.</p>\n<ol>\n<li>FiD의 인코더 입력 형식</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Question:  Where was Alan Turing born? \nContext: Alan Turing was a British computer scientist. Born in Maida Vale, London.</code></pre></div>\n<ol start=\"2\">\n<li>FiD의 디코더 입력 형식</li>\n</ol>\n<img src=\"https://user-images.githubusercontent.com/42150335/148076695-0fd48602-36dc-4d95-b579-b3c720a32c7d.png\" width=\"450\">\n<p>위 그림과 같이 N개 문서에 대한 각 인코더 아웃풋 벡터를 이어붙여서(concat) 디코더에 넣고 답변을 생성합니다.</p>\n<p>FiD 본 논문에서는 프리트레이닝 된 T5 모델로 Question-Answer pair 데이터로 파인튜닝해서 모델을 만들었습니다.\n검색 모델(BM25, DPR)은 따로 학습하지 않았다고 합니다.</p>\n<h2>Retrieval Augmented Generation (RAG)</h2>\n<img src=\"https://user-images.githubusercontent.com/42150335/148077292-38acd9d7-e6b7-46aa-821a-4a918ca0f7d8.png\" width=\"450\">\n<p><strong>Retrieval-Augmented Generation(RAG)</strong> 역시 생성시에 검색 결과를 활용합니다.\nFiD와의 차이점으로는 검색 모델을 따로 학습하지 않은 FiD와는 달리 RAG는 검색 모델 역시 학습한다는 차이가 있습니다.\n(RAG는 Retriever로 bi-encoder 기반의 DPR, Generator로 BART를 사용했습니다.)</p>\n<p>RAG는 <code class=\"language-text\">RAG-Sequence</code>와 <code class=\"language-text\">RAG-Token</code>라는 2가지의 변형 알고리즘을 만들었습니다.\n둘은 계산을 행하는 단위가 문장 전체냐, 토큰이냐의 차이를 가지고 있습니다.</p>\n<h3>RAG-Sequence</h3>\n<img src=\"https://user-images.githubusercontent.com/42150335/148079083-bbe3b655-665f-4e46-b76f-7ae91c2ee3a1.png\" width=\"250\">\n<ol>\n<li>Retriever로 쿼리와 관련된 K개의 문서를 찾는다.</li>\n<li>K개 문서 각각을 프롬프트로 하는 시퀀스를 K개 생성한다.</li>\n<li>2에서 구한 K개의 시퀀스의 확률 분포를 모두 합친다.</li>\n</ol>\n<p>위 그림과 같이 관련 있는 문서 K개에 대하여 시퀀스 길이 N까지 예측한 확률 분포 시퀀스를 모두 더한 뒤,\n각 위치에서 가장 높은 확률을 갖는 토큰들을 뽑아내면 됩니다.\n여러개의 생성 모델로 예측한 뒤 합쳐서 토큰을 뽑아내는 앙상블 방식과 유사하다는 생각이 듭니다.</p>\n<h3>RAG-Token</h3>\n<img src=\"https://user-images.githubusercontent.com/42150335/148079562-daff56f3-1fbe-4e33-a66a-6fa649ddade5.png\" width=\"250\">\n<ol>\n<li>Retriever로 쿼리와 관련된 K개의 문서를 찾는다.</li>\n<li>다음 토큰을 생성할 때 K개 문서 각각에 대해서 구한다.</li>\n<li>2에서 구한 확률 분포를 합쳐서 다음 토큰을 결정한다.</li>\n<li>이를 시퀀스 길이 N만큼 반복한다.</li>\n</ol>\n<p>방식 자체는 RAG-Sequence와 크게 다르지 않습니다.\n단지 확률 분포를 언제 합치느냐만 다릅니다.\n다음 토큰을 예측할 때 Acoustic 모델과 Language 모델 2개의 확률분포를 합쳐서 결정하는\n음성인식 시스템과 유사한 방식이라는 생각이 듭니다.</p>\n<p>주의할 점은 학습 대상은 DPR의 쿼리인코더와 Generator인 BART이며, DPR의 문서 인코더는 고정해 두었습니다. (bi-encoder 구조 참고!)</p>\n<p>그리고 “Retrieval Augmentation Reduces Hallucination in Conversation” 논문에 따르면 RAG로 학습한 검색 모델을\nFiD의 검색 모델로 사용시 FiD의 성능을 높일 수 있다고 합니다 :)</p>\n<h2>Reference</h2>\n<ul>\n<li><a href=\"https://ratsgo.github.io/insight-notes/docs/qa/answerer\">ratsgo님 블로그</a></li>\n<li><a href=\"https://arxiv.org/pdf/2007.01282.pdf\">Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering</a></li>\n<li><a href=\"https://arxiv.org/pdf/2005.11401.pdf\">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a></li>\n<li><a href=\"https://arxiv.org/pdf/2104.07567.pdf\">Retrieval Augmentation Reduces Hallucination in Conversation</a></li>\n</ul>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Generation with Retrieval"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"이번에 딥마인드에서 "},{"type":"element","tagName":"a","properties":{"href":"https://deepmind.com/research/publications/2021/improving-language-models-by-retrieving-from-trillions-of-tokens"},"children":[{"type":"text","value":"RETRO(Retrieval-Enhanced Transformer)"}]},{"type":"text","value":" 라는 모델을 내놓았습니다. 문서 retrieval + GPT 기반 모델인데,\n7B 모델임에도 불구하고 25배나 큰 모델과 비견될만한 성능을 보여줬습니다. 요즘 트렌드는 검색 + GPT로 가는 것 같습니다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"언어모델이 아무리 크고 많은 데이터를 봤다고 하더라도 세상의 모든 지식을 담을 수는 없습니다.\n그리고 새롭게 생긴 지식이라면 더더욱 언어모델 입장에서는 알 수가 없습니다. 이런 문제를 검색과 결합해서\n풀어보려는 시도가 많이 있었고, 이번 포스팅에서는 그 기반이 된 개념인 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Fusion-in-Decoder(FID)"}]},{"type":"text","value":" 와 "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Retrieval-Augmented Generation(RAG)"}]},{"type":"text","value":"\n를 다뤄보겠습니다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Fusion-in-Decoder (FiD)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Fusion-in-Decoder(FID)"}]},{"type":"text","value":" 는 생성 모델 입력에 검색 결과를 넣어서 활용합니다.\n아래 그림과 같이 어떤 쿼리가 들어왔을 때 적절한 N개의 문서를 가져오고 이 결과를 언어모델의 인코더에 넣어줍니다.\n그리고 디코더는 이 결과를 활용해서 적절한 응답을 생성하는 방식입니다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/148075563-977db2da-5297-41f1-9f11-cfd54f9ffe4a.png","width":300},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"FiD 본 논문에서 검색 모델은 BM25, DPR(Dense Passage Retrieval )을 활용했습니다. 생성 모델로는 위에 설명한 바와 같이\n인코더와 디코더가 필요하기 때문에 T5, Bart와 같은 Seq2seq (Sequence-to-Sequence) 기반의 모델을 사용했습니다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"FiD는 이름은 거창하지만 방식 자체는 어렵지 않습니다. 아래 2개의 개념만 알면 됩니다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"FiD의 인코더 입력 형식"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"text"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-text"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"Question:  Where was Alan Turing born? \nContext: Alan Turing was a British computer scientist. Born in Maida Vale, London."}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ol","properties":{"start":2},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"FiD의 디코더 입력 형식"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/148076695-0fd48602-36dc-4d95-b579-b3c720a32c7d.png","width":450},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"위 그림과 같이 N개 문서에 대한 각 인코더 아웃풋 벡터를 이어붙여서(concat) 디코더에 넣고 답변을 생성합니다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"FiD 본 논문에서는 프리트레이닝 된 T5 모델로 Question-Answer pair 데이터로 파인튜닝해서 모델을 만들었습니다.\n검색 모델(BM25, DPR)은 따로 학습하지 않았다고 합니다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Retrieval Augmented Generation (RAG)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/148077292-38acd9d7-e6b7-46aa-821a-4a918ca0f7d8.png","width":450},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Retrieval-Augmented Generation(RAG)"}]},{"type":"text","value":" 역시 생성시에 검색 결과를 활용합니다.\nFiD와의 차이점으로는 검색 모델을 따로 학습하지 않은 FiD와는 달리 RAG는 검색 모델 역시 학습한다는 차이가 있습니다.\n(RAG는 Retriever로 bi-encoder 기반의 DPR, Generator로 BART를 사용했습니다.)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"RAG는 "},{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"RAG-Sequence"}]},{"type":"text","value":"와 "},{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"RAG-Token"}]},{"type":"text","value":"라는 2가지의 변형 알고리즘을 만들었습니다.\n둘은 계산을 행하는 단위가 문장 전체냐, 토큰이냐의 차이를 가지고 있습니다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"RAG-Sequence"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/148079083-bbe3b655-665f-4e46-b76f-7ae91c2ee3a1.png","width":250},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Retriever로 쿼리와 관련된 K개의 문서를 찾는다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"K개 문서 각각을 프롬프트로 하는 시퀀스를 K개 생성한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"2에서 구한 K개의 시퀀스의 확률 분포를 모두 합친다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"위 그림과 같이 관련 있는 문서 K개에 대하여 시퀀스 길이 N까지 예측한 확률 분포 시퀀스를 모두 더한 뒤,\n각 위치에서 가장 높은 확률을 갖는 토큰들을 뽑아내면 됩니다.\n여러개의 생성 모델로 예측한 뒤 합쳐서 토큰을 뽑아내는 앙상블 방식과 유사하다는 생각이 듭니다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"RAG-Token"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/148079562-daff56f3-1fbe-4e33-a66a-6fa649ddade5.png","width":250},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Retriever로 쿼리와 관련된 K개의 문서를 찾는다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"다음 토큰을 생성할 때 K개 문서 각각에 대해서 구한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"2에서 구한 확률 분포를 합쳐서 다음 토큰을 결정한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"이를 시퀀스 길이 N만큼 반복한다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"방식 자체는 RAG-Sequence와 크게 다르지 않습니다.\n단지 확률 분포를 언제 합치느냐만 다릅니다.\n다음 토큰을 예측할 때 Acoustic 모델과 Language 모델 2개의 확률분포를 합쳐서 결정하는\n음성인식 시스템과 유사한 방식이라는 생각이 듭니다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"주의할 점은 학습 대상은 DPR의 쿼리인코더와 Generator인 BART이며, DPR의 문서 인코더는 고정해 두었습니다. (bi-encoder 구조 참고!)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"그리고 “Retrieval Augmentation Reduces Hallucination in Conversation” 논문에 따르면 RAG로 학습한 검색 모델을\nFiD의 검색 모델로 사용시 FiD의 성능을 높일 수 있다고 합니다 :)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Reference"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://ratsgo.github.io/insight-notes/docs/qa/answerer"},"children":[{"type":"text","value":"ratsgo님 블로그"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/pdf/2007.01282.pdf"},"children":[{"type":"text","value":"Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/pdf/2005.11401.pdf"},"children":[{"type":"text","value":"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/pdf/2104.07567.pdf"},"children":[{"type":"text","value":"Retrieval Augmentation Reduces Hallucination in Conversation"}]}]},{"type":"text","value":"\n"}]}],"data":{"quirksMode":false}},"excerpt":"Generation with Retrieval 이번에 딥마인드에서 RETRO(Retrieval-Enhanced Transformer) 라는 모델을 내놓았습니다. 문서 retrieval + GPT 기반 모델인데,\n7B 모델임에도 불구하고 2…","fields":{"readingTime":{"text":"6 min read"}},"frontmatter":{"title":"Generation with Retrieval","userDate":"4 January 2022","date":"2022-01-04T23:00:00.000Z","tags":["nlp","paper"],"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/37530fc680166ef6d64a040fedb23876/7eb21/fid.png","srcSet":"/static/37530fc680166ef6d64a040fedb23876/41321/fid.png 750w,\n/static/37530fc680166ef6d64a040fedb23876/22692/fid.png 1080w,\n/static/37530fc680166ef6d64a040fedb23876/7eb21/fid.png 1344w","sizes":"100vw"},"sources":[{"srcSet":"/static/37530fc680166ef6d64a040fedb23876/3df03/fid.webp 750w,\n/static/37530fc680166ef6d64a040fedb23876/cd184/fid.webp 1080w,\n/static/37530fc680166ef6d64a040fedb23876/2e84a/fid.webp 1344w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6607142857142857}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"children":[{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#181818","images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/2584f/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/2456b/soohwan.png 40w,\n/static/a2699b4a2f164aa71106535e018ceafc/ab12d/soohwan.png 80w,\n/static/a2699b4a2f164aa71106535e018ceafc/2584f/soohwan.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65256/soohwan.webp 40w,\n/static/a2699b4a2f164aa71106535e018ceafc/c6b8d/soohwan.webp 80w,\n/static/a2699b4a2f164aa71106535e018ceafc/03d15/soohwan.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.25}}]}}]}},"relatedPosts":{"totalCount":30,"edges":[{"node":{"id":"06ac0e32-0688-50f0-810d-134ef8b168ab","excerpt":"Decoding Strategy (디코딩 전략) 이번 포스팅에서는 자연어처리 모델의 디코딩 전략에 관해서 다뤄보려고 합니다. 디코딩이란 말처럼 디코딩은 디코더에서\n수행하는 작업입니다. 즉, BERT와 같은 인코더 모델에서 사용하는게 아니라 GPT…","frontmatter":{"title":"Decoding Strategy (디코딩 전략)","date":"2022-01-15T10:00:00.000Z"},"fields":{"readingTime":{"text":"9 min read"},"slug":"/generate/"}}},{"node":{"id":"db36f120-4fb0-5bf7-af53-16447fe6cdd4","excerpt":"Generation with Retrieval 이번에 딥마인드에서 RETRO(Retrieval-Enhanced Transformer) 라는 모델을 내놓았습니다. 문서 retrieval + GPT 기반 모델인데,\n7B 모델임에도 불구하고 2…","frontmatter":{"title":"Generation with Retrieval","date":"2022-01-04T23:00:00.000Z"},"fields":{"readingTime":{"text":"6 min read"},"slug":"/fid_and_rag/"}}},{"node":{"id":"3b4040eb-d53d-5064-beec-cfbf7a7a0fe2","excerpt":"Fine-grained Post-training for Improving Retrieval-based Dialogue Systems Paper Review Paper: https://aclanthology.org/2021.naacl-main.12…","frontmatter":{"title":"Fine-grained Post-training for Improving Retrieval-based Dialogue Systems Paper Review","date":"2021-12-18T10:00:00.000Z"},"fields":{"readingTime":{"text":"2 min read"},"slug":"/bert_fp/"}}},{"node":{"id":"78976688-33d9-53c4-8489-5099082b9972","excerpt":"GPT (Generative Pre-trained Transformer) 1 gpt1 먼저 알아보고, gpt2에 대해 알아보겠습니다. GPT1 Improving Language Understanding by Generative Pre-Training…","frontmatter":{"title":"GPT (Generative Pre-trained Transformer)","date":"2021-11-23T11:00:00.000Z"},"fields":{"readingTime":{"text":"13 min read"},"slug":"/gpt/"}}},{"node":{"id":"ad5b0c9b-8199-5f10-bfc9-6bb05942e164","excerpt":"Large Scale LM (2) Distributed Programming (작성중) 이 자료는 [해당 link…","frontmatter":{"title":"Large Scale LM (2) Distributed Programming","date":"2021-11-22T11:00:00.000Z"},"fields":{"readingTime":{"text":"17 min read"},"slug":"/big-model2/"}}}]}},"pageContext":{"slug":"/fid_and_rag/","prev":{"excerpt":"Basic Computer System ※ 본 포스팅의 내용은  책을 읽고 공부한 내용을 기록한 포스트입니다. 컴퓨터를 구성하는 3 요소 연산 장치 (CPU) => 초당 얼마나 많이 계산 가능한지 메모리 장치 (RAM, Hard-Drive…","frontmatter":{"title":"Basic Computer System - 연산 장치","tags":["cs"],"date":"2022-01-04T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD4UlEQVQ4y0WU208TBhhHfwXdXFyWKG6Lmi27ODNdxJmZaHQKDmdUGDKxIiBYEMqdttxaoOXSloKlBQpdhTKgWEFFvECMl83p1G26xMy9bNmepi97WrbnPZ2l8WH/wEm+fL9zpCI3MvWiqmFkiZJsiZBU6ERlfSztOIfqhlF9GHkWSLJPodphlF2HjncicwCZg8jYgg6YUY4VJSBqnEAdc8h7hRc6LvBmxxQ60cNaZ4Rk/02S+m+xLHoHueZRaRcyWlHTGLKOIpMPlfahmjCqHEJynEW+RTR0G43eR8N3WX/uERvHr7HSs0jd5VHuP/Nz88+fqY9Xo6xSDJYgKe5pXnF+SYp3luXuWVQXRvntSN2XUOArFP0ORR+yPPYDey7cY+fVnzBevA2/rebffw5w99nv/P3sJIe7S9k8eJEjE/OsDV1hhT2M4YQLlXqRuR/JFkXBG+j0AxR7wvKZJ6Seu4/x8mP812b44/HHdN94QNYt+PGpkxu3jKSNX2ff1CJrnOOobhC1RJFjCjVPIpV0oKLEE05h6JhFga9Jm3uIraGdosFvKJl7yuY4ZHwLv/6yk8eXPqWwf5I9nb1s8YZZ1RzinZYgOlSD9pmQ+uZQ6wRqjrCkdoSlzhnKJs5zyj9Aak434eF6Hs1n8sn5v8gLf097q4vGzh4KwzG2BqZ5r7KL1/YXot1HUXo+UmsUVQdQeYgV/YvkXr3HNl+E0fgZcooa2L41nUDeu2Rml7MlrYKsI4VUNHVx3D+OagMoz4FyLKi4ExW6kHyzyDLCKu8l1sfusGPwLGlDZ8nv9DA0Gid12z42pGbw/rbD5BVX4PT24vP3sKZlGB2ykpRbj8p6UIkX5TYhBRcw1A7xatsk22PXSYvMkzG5QLovTFd/AKc3yHFTBdYWN5VNDvafNLPpRA3pXYO83jOLakcw5LehrCqUUYxU7mNJgYv1rRHKonHKJ8+TO7PILv8EbxVb2VvTRlFVFbsKTHxo7+Mj5yBbXSEyLQ4OOntZVuFH2RZ02IaMzSixnzfcU+wYiLPBM8mL/QukuCZIso4gYyPKqkEFdnb3nGZdYI7UU9O8bBthY8cXbC6u4+1CK4bE/kp6n+soRwy551jZNc1S1yxyX0DVQ6gxgqGki+S6AVQb4rO+06TYx1jRHWedI8RKW4h11W6SM80YsmvRUTs6ljAl4aNnDrUkwBcxNI6icj9KnFLiQSYPqgywqXuMD9rDqGkKgz2GqkOsqg/yktGG9pqeAz9PxKFpArXFUdsZ1DCGGqL/1yPtGCpwocoBZBlldZGd5JN9yDaO7PHnMSh2o4NmlFmJcur5D0BEimXr4LuFAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/701ec19008a764b7dd4bccbc63d2efdc/ef255/computer_architecture.png","srcSet":"/static/701ec19008a764b7dd4bccbc63d2efdc/76a4f/computer_architecture.png 750w,\n/static/701ec19008a764b7dd4bccbc63d2efdc/a902f/computer_architecture.png 1080w,\n/static/701ec19008a764b7dd4bccbc63d2efdc/61156/computer_architecture.png 1366w,\n/static/701ec19008a764b7dd4bccbc63d2efdc/ef255/computer_architecture.png 1592w","sizes":"100vw"},"sources":[{"srcSet":"/static/701ec19008a764b7dd4bccbc63d2efdc/66907/computer_architecture.webp 750w,\n/static/701ec19008a764b7dd4bccbc63d2efdc/27610/computer_architecture.webp 1080w,\n/static/701ec19008a764b7dd4bccbc63d2efdc/90004/computer_architecture.webp 1366w,\n/static/701ec19008a764b7dd4bccbc63d2efdc/0d756/computer_architecture.webp 1592w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.75}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,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"},"images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.2462962962962962}}}}]},"fields":{"readingTime":{"text":"5 min read"},"layout":"","slug":"/cs-basic/"}},"next":{"excerpt":"…","frontmatter":{"title":"광주소프트웨어마이스터고등학교 학생들 튜닙 방문","tags":["record"],"date":"2022-01-11T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAADV0lEQVQozwXB+1MSBgDAcf4ImznAO08ElSQeSaWmQiL4mKIlPkBeXoqiGZgkig90KiJb4pDh47THmrvyct3p1g+V7TaX2utqt6u71e1uXX/Hd5+PoLjKT1PHKLbucazeSSouDDHx/U/8+d8HXv/7jpWfd+m5tsDz9294/vkjR58+EIzdIJK4zdE/f/Hy00c2H+/R6plh//1bBOdMPhQaB5VFdranBhho7iYVHGInMY3FMoLTPsbt6Wlmg1E6e2N0XP4WW1cEu2eW+GSMK75ZPKE43pEFlnZ2EZjMAygUNpwGJ2/Xx3k4F2R/KcR+coxui5/JvhEONyLcjYSZ8IXx9X/NQCBCeDTC/WSMxdk5xuaXCMVS/PLsNwSV9VdRKq3Yde08jQ6ycaWX3x8EuP8kyaXNH0jF47y6t8TrnTU2V5dJJFIEgzMsRud5uH6dGwsxoksrBGdTPPv7JQJjwyAqlRXz2TZWer180z9C8qafy49u4rq+RGI4xHZsile7t5gLTDEf/Y6e7hDD/lFWx8OkojHW7twiFEmx9+YQQVXjINpTdso1behPWzEb3KhLrNTZfCT9wyz6rrIamWHU3c92IkKgb5SQb4yN+AIed4CKyn4m5peZii3z6MUfCGqaApzWtFOqbqbibDtp6dVkHKsiW1iDTN6CtqiT0vN9aKX1hIfGcDf20GDoxGv1I1e5OC5xoKsbJhxN8uvhUwSmpmuolVZys74iJ7uBPFkz4gwT8jwLIlE1SpUNdbGHUzIzpSVuCgraEIsbUCkdnNR2kX3Chfa8j3B8jScHewhsziFycsxki6uQSRvJz2tGKjIiFNYgTDegKfZQWNZHoaweicyCUuXgy4xaCks8qApdZEpaKDP5iK7d4e7sNIIJey9+XR1urYlc2QUkUgsnsoxkCo18cUxHvsbFSfkF1LJahFIrnRc96LWtFOl7KD1jQ5Jrxeed4MXjH9lZiSFY7XKx5ahnprqKrKw6JJJGzuRWoyswIjpeTr6ijbQ0HeJ0HfmKVrqaOqk1Oak0dWE2OpEqXNicYxw8WObdwRaCe816thrLSNUbEIlrKM+rxqoyopfoyc/Uo5Y3IRcZqDhno7XFy8VKB9WlVkxlDi61dKLUOOhwD3G0HuLz/gL/Azr0GHEpMjtZAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/0236317ab6d0ade50e943efd96ed64ee/e38af/soma.png","srcSet":"/static/0236317ab6d0ade50e943efd96ed64ee/e9604/soma.png 750w,\n/static/0236317ab6d0ade50e943efd96ed64ee/e38af/soma.png 847w","sizes":"100vw"},"sources":[{"srcSet":"/static/0236317ab6d0ade50e943efd96ed64ee/64486/soma.webp 750w,\n/static/0236317ab6d0ade50e943efd96ed64ee/ed812/soma.webp 847w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6068476977567887}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder/A.I. engineer at TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,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"},"images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.2462962962962962}}}}]},"fields":{"readingTime":{"text":"2 min read"},"layout":"","slug":"/soma/"}},"primaryTag":"nlp"}},
    "staticQueryHashes": ["3170763342","3229353822"]}